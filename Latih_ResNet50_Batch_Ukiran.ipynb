{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsiimNC482wm",
        "outputId": "133b5af0-9072-4e01-af49-a0ddcd75c142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abPhq0iD83rd",
        "outputId": "b433d55e-ed70-4e1f-ea67-dfd24fceaba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Type: Tesla T4\n",
            "\n",
            "ARCH Value: -gencode arch=compute_75,code=[sm_75,compute_75]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "\n",
        "      }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTwceZZG9gGb",
        "outputId": "a28b5526-7d8c-4f30-8e5b-bf348b804d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 15 21:55:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEvNVT8a9iqW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet import ResNet50\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import itertools\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4gTwybI9tYa",
        "outputId": "a0960ae1-7bc4-4cba-b063-6cbc9c8dedb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Train :\n",
            "['Pa Tangke Lumu', 'Pa Lulun Pao', 'Pa Tumuru', 'Pa Somba']\n",
            "Dataset Validasi\n",
            "['Pa Tangke Lumu', 'Pa Lulun Pao', 'Pa Tumuru', 'Pa Somba']\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset Train :\")\n",
        "print(os.listdir('/content/drive/MyDrive/Colab Notebooks/Dataset_split/train'))\n",
        "print(\"Dataset Validasi\")\n",
        "print(os.listdir('/content/drive/MyDrive/Colab Notebooks/Dataset_split/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47vRq5eh9w8D"
      },
      "outputs": [],
      "source": [
        "train_directory = \"/content/drive/MyDrive/Colab Notebooks/Dataset_split/train\"\n",
        "valid_directory = \"/content/drive/MyDrive/Colab Notebooks/Dataset_split/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X28D3J_RbEra"
      },
      "source": [
        "#1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aue1mrtG-9BY",
        "outputId": "b792407c-6726-4468-d811-2142021fa42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.0001\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 1e-3\n",
        "if epochs > 180:\n",
        "    lr *= 0.5e-3\n",
        "elif epochs > 160:\n",
        "    lr *= 1e-3\n",
        "elif epochs > 120:\n",
        "    lr *= 1e-2\n",
        "elif epochs > 80:\n",
        "    lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZUrxwl_AHu",
        "outputId": "9193e667-65d5-405b-93ac-392b16c38765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bq7QRO__B8p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIT6A2Sp_I0x",
        "outputId": "e72867d2-9c21-4485-8eab-56ec76675104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6P7kBEP_Kvi",
        "outputId": "5deef8c7-4a36-4d88-b960-a0f809aa54cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 19s 304ms/step - loss: 1.0616 - accuracy: 0.5500 - val_loss: 1.2866 - val_accuracy: 0.3151\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6995 - accuracy: 0.7550 - val_loss: 1.2696 - val_accuracy: 0.2656\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5181 - accuracy: 0.8425 - val_loss: 1.2859 - val_accuracy: 0.2708\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4055 - accuracy: 0.8681 - val_loss: 1.1802 - val_accuracy: 0.3203\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3323 - accuracy: 0.8944 - val_loss: 1.0684 - val_accuracy: 0.4089\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2708 - accuracy: 0.9206 - val_loss: 0.7168 - val_accuracy: 0.6510\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2691 - accuracy: 0.9087 - val_loss: 0.7275 - val_accuracy: 0.7214\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.2563 - accuracy: 0.9194 - val_loss: 0.6231 - val_accuracy: 0.7344\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2312 - accuracy: 0.9181 - val_loss: 0.3793 - val_accuracy: 0.8464\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.1639 - accuracy: 0.9538 - val_loss: 0.3135 - val_accuracy: 0.8828\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.1576 - accuracy: 0.9563 - val_loss: 0.2402 - val_accuracy: 0.9167\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.1583 - accuracy: 0.9513 - val_loss: 0.3117 - val_accuracy: 0.8698\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1270 - accuracy: 0.9688 - val_loss: 0.3184 - val_accuracy: 0.8932\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.1537 - accuracy: 0.9525 - val_loss: 0.2270 - val_accuracy: 0.9271\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1082 - accuracy: 0.9656 - val_loss: 0.2277 - val_accuracy: 0.9297\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.2039 - val_accuracy: 0.9245\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.0876 - accuracy: 0.9719 - val_loss: 0.2079 - val_accuracy: 0.9323\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 0.2798 - val_accuracy: 0.9141\n",
            "Epoch 19/100\n",
            "15/50 [========>.....................] - ETA: 7s - loss: 0.0895 - accuracy: 0.9854"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "ktJjbGGC_UPH",
        "outputId": "265eab5b-9180-4385-c2a4-e71441c8ac28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfpJKQkPQ34T",
        "outputId": "c95310c9-3936-46a7-f16c-f44a08734cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model100.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights100.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model100.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4vi1scDREjJ",
        "outputId": "75db12d8-e0af-4868-e94d-60793b85b125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gz1uMfpRKiL"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model100.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQDO66l3RK0Y",
        "outputId": "bc1cdf78-d844-4b2e-fd3c-5560931381f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 852ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00         9\n",
            "           3       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89         9\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.94      0.94      0.93        32\n",
            "weighted avg       0.94      0.94      0.94        32\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VwnluOERS8F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPyE3oIybIRp"
      },
      "source": [
        "#2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqSxRS0EbIRp",
        "outputId": "2950c331-b86c-4961-eb51-812c201741e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  1e-05\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 0.00001\n",
        "# if epochs > 180:\n",
        "#     lr *= 0.5e-3\n",
        "# elif epochs > 160:\n",
        "#     lr *= 1e-3\n",
        "# elif epochs > 120:\n",
        "#     lr *= 1e-2\n",
        "# elif epochs > 80:\n",
        "#     lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mnWmIGkbIRq",
        "outputId": "ac9e595e-8b39-44cc-f62c-a0c4d8dbca19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Csne8ybIRq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3GHSTnVbIRr",
        "outputId": "8cf1c940-7d1d-4950-89c8-904e48a31faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T10BrOqWbIRr",
        "outputId": "0e5dbc4a-5359-45d7-c920-b43c4619faec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 18s 272ms/step - loss: 1.3212 - accuracy: 0.3750 - val_loss: 1.3737 - val_accuracy: 0.3802\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.1536 - accuracy: 0.5138 - val_loss: 1.3310 - val_accuracy: 0.4740\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 13s 270ms/step - loss: 1.0641 - accuracy: 0.5631 - val_loss: 1.2734 - val_accuracy: 0.4297\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.0007 - accuracy: 0.5962 - val_loss: 1.2041 - val_accuracy: 0.4974\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.9392 - accuracy: 0.6494 - val_loss: 1.1005 - val_accuracy: 0.6432\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8848 - accuracy: 0.6938 - val_loss: 1.0038 - val_accuracy: 0.6771\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8349 - accuracy: 0.7150 - val_loss: 0.9094 - val_accuracy: 0.7266\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.7988 - accuracy: 0.7425 - val_loss: 0.8314 - val_accuracy: 0.7604\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7569 - accuracy: 0.7613 - val_loss: 0.7772 - val_accuracy: 0.7656\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.7175 - accuracy: 0.7738 - val_loss: 0.7166 - val_accuracy: 0.7995\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 269ms/step - loss: 0.6920 - accuracy: 0.7919 - val_loss: 0.6935 - val_accuracy: 0.7917\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6600 - accuracy: 0.8025 - val_loss: 0.6624 - val_accuracy: 0.8047\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6338 - accuracy: 0.8244 - val_loss: 0.6259 - val_accuracy: 0.8203\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6046 - accuracy: 0.8238 - val_loss: 0.5995 - val_accuracy: 0.8203\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5765 - accuracy: 0.8438 - val_loss: 0.5853 - val_accuracy: 0.8255\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.5532 - accuracy: 0.8494 - val_loss: 0.5675 - val_accuracy: 0.8438\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5351 - accuracy: 0.8519 - val_loss: 0.5569 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.5169 - accuracy: 0.8512 - val_loss: 0.5306 - val_accuracy: 0.8438\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4884 - accuracy: 0.8619 - val_loss: 0.5153 - val_accuracy: 0.8359\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4757 - accuracy: 0.8756 - val_loss: 0.4857 - val_accuracy: 0.8594\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4578 - accuracy: 0.8737 - val_loss: 0.4846 - val_accuracy: 0.8516\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4408 - accuracy: 0.8794 - val_loss: 0.4693 - val_accuracy: 0.8594\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.4285 - accuracy: 0.8794 - val_loss: 0.4693 - val_accuracy: 0.8646\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4130 - accuracy: 0.8919 - val_loss: 0.4408 - val_accuracy: 0.8854\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.4115 - accuracy: 0.8875 - val_loss: 0.4351 - val_accuracy: 0.8750\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3973 - accuracy: 0.8950 - val_loss: 0.4288 - val_accuracy: 0.8880\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.3740 - accuracy: 0.9025 - val_loss: 0.4109 - val_accuracy: 0.8828\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3715 - accuracy: 0.8969 - val_loss: 0.3969 - val_accuracy: 0.8906\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.3553 - accuracy: 0.9013 - val_loss: 0.4189 - val_accuracy: 0.8672\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3511 - accuracy: 0.9038 - val_loss: 0.3881 - val_accuracy: 0.8880\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3426 - accuracy: 0.9038 - val_loss: 0.3800 - val_accuracy: 0.8958\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3278 - accuracy: 0.9156 - val_loss: 0.3731 - val_accuracy: 0.8932\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.3188 - accuracy: 0.9187 - val_loss: 0.3853 - val_accuracy: 0.8854\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3136 - accuracy: 0.9106 - val_loss: 0.3539 - val_accuracy: 0.8906\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3045 - accuracy: 0.9150 - val_loss: 0.3549 - val_accuracy: 0.9010\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3009 - accuracy: 0.9175 - val_loss: 0.3471 - val_accuracy: 0.9036\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2851 - accuracy: 0.9262 - val_loss: 0.3366 - val_accuracy: 0.9141\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2785 - accuracy: 0.9319 - val_loss: 0.3451 - val_accuracy: 0.9036\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2765 - accuracy: 0.9244 - val_loss: 0.3201 - val_accuracy: 0.9141\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.2736 - accuracy: 0.9262 - val_loss: 0.3185 - val_accuracy: 0.9219\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2605 - accuracy: 0.9306 - val_loss: 0.3172 - val_accuracy: 0.9062\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2591 - accuracy: 0.9350 - val_loss: 0.3356 - val_accuracy: 0.9141\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2529 - accuracy: 0.9369 - val_loss: 0.3202 - val_accuracy: 0.9115\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2463 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.9089\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2354 - accuracy: 0.9481 - val_loss: 0.3229 - val_accuracy: 0.9167\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2381 - accuracy: 0.9419 - val_loss: 0.3141 - val_accuracy: 0.9167\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2301 - accuracy: 0.9388 - val_loss: 0.3200 - val_accuracy: 0.9089\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 13s 270ms/step - loss: 0.2228 - accuracy: 0.9469 - val_loss: 0.3049 - val_accuracy: 0.9089\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.2183 - accuracy: 0.9513 - val_loss: 0.2885 - val_accuracy: 0.9115\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2120 - accuracy: 0.9469 - val_loss: 0.2955 - val_accuracy: 0.9219\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.2083 - accuracy: 0.9525 - val_loss: 0.2926 - val_accuracy: 0.9167\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2014 - accuracy: 0.9519 - val_loss: 0.2803 - val_accuracy: 0.9141\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2062 - accuracy: 0.9550 - val_loss: 0.2629 - val_accuracy: 0.9271\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1924 - accuracy: 0.9550 - val_loss: 0.2760 - val_accuracy: 0.9219\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1904 - accuracy: 0.9544 - val_loss: 0.2760 - val_accuracy: 0.9323\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.1916 - accuracy: 0.9556 - val_loss: 0.2706 - val_accuracy: 0.9219\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1914 - accuracy: 0.9500 - val_loss: 0.2658 - val_accuracy: 0.9219\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1754 - accuracy: 0.9631 - val_loss: 0.2700 - val_accuracy: 0.9245\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1715 - accuracy: 0.9606 - val_loss: 0.2667 - val_accuracy: 0.9245\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1764 - accuracy: 0.9606 - val_loss: 0.2587 - val_accuracy: 0.9141\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1652 - accuracy: 0.9638 - val_loss: 0.2383 - val_accuracy: 0.9297\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1658 - accuracy: 0.9631 - val_loss: 0.2406 - val_accuracy: 0.9245\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.1644 - accuracy: 0.9563 - val_loss: 0.2614 - val_accuracy: 0.9219\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1594 - accuracy: 0.9613 - val_loss: 0.2532 - val_accuracy: 0.9297\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1587 - accuracy: 0.9650 - val_loss: 0.2362 - val_accuracy: 0.9323\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1529 - accuracy: 0.9663 - val_loss: 0.2477 - val_accuracy: 0.9297\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1553 - accuracy: 0.9625 - val_loss: 0.2452 - val_accuracy: 0.9297\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1527 - accuracy: 0.9625 - val_loss: 0.2427 - val_accuracy: 0.9297\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1497 - accuracy: 0.9625 - val_loss: 0.2382 - val_accuracy: 0.9427\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1421 - accuracy: 0.9663 - val_loss: 0.2373 - val_accuracy: 0.9375\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.1417 - accuracy: 0.9712 - val_loss: 0.2369 - val_accuracy: 0.9297\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1427 - accuracy: 0.9669 - val_loss: 0.2381 - val_accuracy: 0.9193\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1343 - accuracy: 0.9725 - val_loss: 0.2404 - val_accuracy: 0.9297\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1361 - accuracy: 0.9681 - val_loss: 0.2451 - val_accuracy: 0.9271\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1267 - accuracy: 0.9775 - val_loss: 0.2260 - val_accuracy: 0.9349\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1329 - accuracy: 0.9669 - val_loss: 0.2219 - val_accuracy: 0.9349\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.1219 - accuracy: 0.9769 - val_loss: 0.2151 - val_accuracy: 0.9297\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1209 - accuracy: 0.9731 - val_loss: 0.2345 - val_accuracy: 0.9271\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 13s 269ms/step - loss: 0.1177 - accuracy: 0.9750 - val_loss: 0.2236 - val_accuracy: 0.9349\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.1211 - accuracy: 0.9756 - val_loss: 0.2117 - val_accuracy: 0.9323\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1161 - accuracy: 0.9762 - val_loss: 0.2210 - val_accuracy: 0.9323\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1130 - accuracy: 0.9769 - val_loss: 0.2265 - val_accuracy: 0.9271\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1136 - accuracy: 0.9731 - val_loss: 0.2189 - val_accuracy: 0.9297\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1094 - accuracy: 0.9775 - val_loss: 0.2325 - val_accuracy: 0.9245\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1143 - accuracy: 0.9706 - val_loss: 0.2204 - val_accuracy: 0.9349\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1071 - accuracy: 0.9806 - val_loss: 0.2095 - val_accuracy: 0.9297\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.2040 - val_accuracy: 0.9297\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1042 - accuracy: 0.9787 - val_loss: 0.2188 - val_accuracy: 0.9349\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0963 - accuracy: 0.9819 - val_loss: 0.2167 - val_accuracy: 0.9323\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0971 - accuracy: 0.9825 - val_loss: 0.2044 - val_accuracy: 0.9245\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1058 - accuracy: 0.9756 - val_loss: 0.2140 - val_accuracy: 0.9245\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1023 - accuracy: 0.9794 - val_loss: 0.2197 - val_accuracy: 0.9271\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0984 - accuracy: 0.9787 - val_loss: 0.2239 - val_accuracy: 0.9323\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 270ms/step - loss: 0.0975 - accuracy: 0.9800 - val_loss: 0.2038 - val_accuracy: 0.9297\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0917 - accuracy: 0.9794 - val_loss: 0.2156 - val_accuracy: 0.9375\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0955 - accuracy: 0.9781 - val_loss: 0.2095 - val_accuracy: 0.9271\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0889 - accuracy: 0.9819 - val_loss: 0.1986 - val_accuracy: 0.9401\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0853 - accuracy: 0.9837 - val_loss: 0.2039 - val_accuracy: 0.9349\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0896 - accuracy: 0.9794 - val_loss: 0.1947 - val_accuracy: 0.9375\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0831 - accuracy: 0.9856 - val_loss: 0.1952 - val_accuracy: 0.9375\n",
            "CPU times: user 20min 19s, sys: 57.3 s, total: 21min 16s\n",
            "Wall time: 22min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "q4kE0PfYbIRr",
        "outputId": "4aab9d6d-710e-411f-c69a-5661ce7df912"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xV9fnA8c+TQQIkQBYzSEARBJFhHBWr4gK0BXFCXWjde1erVar1V622autonTiLYt1FcIFaBxCmsgkEEmYge+fe+/z++N4MQhISyOWS3Of9et0XOfs59+p5zvmuI6qKMcaY0BUW7ACMMcYElyUCY4wJcZYIjDEmxFkiMMaYEGeJwBhjQpwlAmOMCXGWCEy9RGSqiPwpyDH8XkReDPAxDhKRIhEJb8l1WyCuySLyv0AfpzlEJEVEVEQi/NOfisilTVl3H465TERO2pd9mD2zRBDiRGSOiOSKSFSwY6lLVf9PVa+oO19ELvRfkItEpFREfLWmi5p5jI2qGqOq3pZc90AlIitF5PJ65t8sImnN2ZeqjlXVV1suunqPMVhV5wTyGMYSQUgTkRTgl4AC4wJ0jH26I6yPqr7pvyDHAGOBzVXT/nm1jx/wu/dW5lXgknrmX+xfZkKQJYLQdgnwIzAVqPcRH0BEYkVktoj8XUT61n3k9z9VXOH/e7KIfCciT4jITmCKiBwsIl+JyE4R2SEib4pIl1rb/05ENolIoYisEpFT/POniMgbzTkhf5HWcyIyQ0SKgVEicqaILBKRAhHJFJEptdavW9wxR0Qe8p9DoYh8JiKJzV3Xv/wSEdngP+8/iEiGiJzaQNwJIvKRP8Z5wMF1lj/lj71ARBaIyC9rLZsiIu+IyGv+OJaJSGoDX9HrwPEi0qfW9oOAI4B/N/Zd1RNz7d89XEQe9/++64Az66x7mYis8Me3TkSurrUsUUQ+EZE8EckRkW9FJMy/rMHvzLQcSwSh7RLgTf9ntIh0q7uCiCQAXwLfqepNuKeHPTkGWAd0Ax4GBPgz0BM4DOgNTPHvfwBwA3CUqsYCo4GMfTkp4Df+48YC/wOKcefaBXeBulZEztrD9pcBXYF2wB3NXdd/cX0WuBDoAXQGejWyn2eAMv+6l/s/tc0HhgHxwFvAdBGJrrV8HDDNf44fAU/XdxBVzQJm454AqlwMzFDVHTT/u6pyJfArYDiQCpxbZ/l2//JOuO/rCREZ4V92O5AFJOH+m/k9TfvvzLQQSwQhSkSOB/oA76jqAiAdd1GrrSfwNTBdVe9rxu43q+o/VNWjqqWqulZVP1fVclXNBv4GnOhf1wtEAYNEJFJVM1Q1fZ9ODj5U1e9U1aeqZao6R1V/8k8vBf5d6/j1eUVVV6tqKfAO7gLc3HXPBT5W1f+pagVwPw1c3PzFV+cA96tqsar+TJ1iGlV9Q1V3+r/Tv+K+swG1Vvmfqs7w11+8DgxtJOZX8ScC/533hVXH24vvqsr5wJOqmqmqObjEXzv+/6pqujpfA5/hiiUBKnEJsI+qVqrqt2qDoO1XlghC16XAZ/67QHB3mXWLh84E2gP/bOa+M2tPiEg3EZnmL/4pAN4AEgFUdS1wC+4JYbt/vZ7NPN6ejn+Mv2grW0TygWuqjt+ArbX+LgFiGlqxkXV71o5DVUuAnQ3sIwmIqBP3hjrncIe/aCVfRPJwTxi1z6FuHNHScP3Me0APETkWOAnoAPzXf5zmfldVdjnfeuIfKyI/+ot+8oAzau33MWAt8Jm/2OjuJhzPtCBLBCFIRNrj7uBOFJGtIrIVuBUYKiK17yRfAGYCM0Sko39esf/fDrXW617nEHXv5v7PP2+IqnYCLsIVF7mVVd9S1aonFAUe3euTq//4b+GKS3qramdcYpPdtmpZW4Dkqgn/d57QwLrZgAdXZFbloFrb/hK4C/ebxalqFyCfvTwHf1J6F1cEdDEwzf/UAnv/XW1pJP4o4D/A40A3f/wzqvarqoWqeruq9sMVcd1WVU9k9g9LBKHpLFyRzCBcUcYwXNn9t+zeouQGYBXwsYi09xftbAIu8lcQXk6dis16xAJFQL6I9ALurFogIgNE5GT/xaIMKAV8+3qC9Rw/R1XLRORodi8CC4R3gV+LyHEi0g73xFPvBdVfnPMermK9g79+ofbTWSwuUWQDESJyP66sfV+8ClyAK5KqXQy1t9/VO8BNIpIsInFA7bv6driirGzAIyJjgdOrForIr0TkEBERXILz0vL/DZhGWCIITZfiyrY3qurWqg+ugvHC2kUK/rLaq3CVeR/6KyivxF3MdwKDge/3cLw/AiNw/5P/F3fRqxIFPALswBVvdAXu2fdT3MV1wIMiUogrq3+nhfe/G1VdBtyIq8DdgkuE24HyBja5AVestBXXiuuVWstm4Z7MVuOKXMqoU/y1F77B/R5Zqjq/1vy9/a5e8Me5BFhIrd9YVQuBm/z7ysUll49qbdsf+AL3Hf0APKuqs/finMxeEquTMSbwRCQGyAP6q+r6YMdjTG32RGBMgIjIr/1FPR1x5eM/se9NY41pcZYIjAmc8cBm/6c/MNGaRZoDkRUNGWNMiLMnAmOMCXEtPiBYoCUmJmpKSkqwwzDGmFZlwYIFO1Q1qb5lrS4RpKSkkJbWrNFyjTEm5InIhoaWBaxoSEReFpHtIvJzA8tF3GiWa0Vkaa0BqIwxxuxHgawjmAqMaWT5WFxLiv64DkvPBTAWY4wxDQhYIlDVb4CcRlYZD7zmH43wR6CLiPQIVDzGGGPqF8xWQ73YtZt8Fo2P126MMSYAWkXzURG5SkTSRCQtOzs72OEYY0ybEsxEsIldh61N9s/bjao+r6qpqpqalFRv6ydjjDF7KZiJ4CPgEn/roWOBfFXdEsR4jDEmJAWy+ei/cUPKDhCRLBH5rYhcIyLX+FeZgXuv7VrcELbXBSoWY4xpzbzeEtLT76KsrMGuAPskYB3KVHXSHpYrcH2gjm+MMftK1UdhYRplZeuprMzF48mjS5df0rnzyBY7htdbTE7OZxQWplFYuICysvUkJZ1Lr143EhXVnby8r1m58reUlaUTHd2XXr2ubbFjV2l1PYuNMaYlFBcvZ+XKySQkjKN37zsID48GQFUpKPie7dvfITv7P1RU1K26FA466G5SUv5IWFgkPl8lO3f+l9LSNUREdCEiIg7wUlq6nrKydXg8udXzIyMTiY7uS/v2/VD1snXrK2zb9hZebwEiEXToMJjo6IPYuPHPZGb+lS5dfklu7hdER/dj6NDZxMWdFJDvwhKBMWa/qqjIZuXKS4iPH0ty8k3V81WVrKwn8Hjy6N79Mtq371trmZeKiu14PO6u3OPJ9d+h13wqK3MRiaBr14nExZ2MSBgVFdvZtOlpcnO/4qCD7iQxcTwApaXpLFlyKh5PPoWF89m69RX69XuE8vJMtmx5gZKSlYhEER8/hqSkR4iNHUFERBxhYVGsW/c7Nm78M7m5X9Gly4ls3foqlZXb6j3XyMiuREbG4/HkUVmZi+quL6gLC4smKek8une/nE6djq1ORiUla8jM/Cs7drxHr14306/fw4SHd6zvEC2i1Q1DnZqaqjbWkDGtQ0nJaqKiehMe3h6AiortLFlyCsXFbuSZgQNfpXt395rsjIw/kpExxb+lEBd3Kh06DKCwcCFFRYvx+UoaPE54eAwREXF4PAV4vflER/ejU6dj2bHjPXy+cqKielFenkXPnteRnHwLS5achtdbyLBhX1NZuY01a26kpGQFAJ06/YIePa4kKelcIiJi6z3e9u3TWbXqSrzeIhISzqRHjyvp0uUEPJ58PJ5cQIiO7ktERMwu23k8BZSVrae0dH31tpGRcXv/BTeDiCxQ1dR6l1kiMMbsLZ+vnM2bn2f79rdJSPgVPXteQ2RkF0pK1rJ27S3k5PyXyMiuJCffRGLiOSxbdg5lZesZPPg9MjMfIz//G4YM+YTi4mWkp99O9+6TSUmZwtatU9my5SUqK3OIjR1OTMwIOnQYQEREPJGRcURE1P50JiwsEgCvt4wdO95jy5YXKCiYR7duv6F37zuIjk5h3bp7ycr6KxBGeHhHhg79ik6dUv3nUcnOnR/Tvv2hxMQc3qRzr6zMQ7WCdu26BurrbVGWCIwxDfJ6SykryyAsLHqX4pjG+HyVbNv2JhkZUygv30B09MGUlaUTHh5DfPxYduz4kLCwdiQn30Zh4Xxycj4FICysA0ccMYMuXU7E4ylg0aITKC1dhc9XRlLSeRx22FuEhbkSa3dtUkRarnFjTs4sNmx4mL59/48uXY5vsf22Bo0lAqsjMKYVKClZRVRUn+oy5LoqK3eSkzMTn6+CiIguREbGExubWm+5sqqP3NzP2bLlRfLzv6Oioqb7TufOJ9Kz55UkJIwnLCxqt23LytazZctLbN06lcrK7cTGpjJgwAvExZ1KUdESMjMfY8eO9+ja9QL69XuUqCg3fFhR0U9s2fICXbtOpHPn4wCIiOjEEUd8yuLFJ9Kx42AOO+yN6iQAICKA7MvXtpv4+NHEx49u0X22BfZEYMwBbsuWqaxadRlhYdF06jSSuLhR/pYp4POVkpMzi9zcrwDvLttFR/dj0KC36NTpGMC1Rd+06Rk2bXqG8vINREQkkJBwJu3b96d9+76UlWWyZcuLlJWl7yGicH8x0FXEx4/1X7D3nqoXkfB92ofZMysaMqaVKilZTVraCGJihtKp0zHk5n5BcfFPu6wTHX0wXbueR2LiOURGJuLx5FJWtp61a2+lomIzKSkPERHRmQ0bHqKiYgtduoyiZ8+rSUw8a7e7flUfeXlzKCj4Edj92hAe3omkpHOr7/RN62FFQ8YEUXn5FnbseI+iopoLuEiEvwgnDpEIysoyKC1dj89XykEH3UVc3Cn4fOUsXz6JsLAoBg9+h6goNzivx5OPz1fVDDGMyMiEOnflKcTGDqdLl5NZvfoq1q+/B4DOnY9n0KB3Gi0bFwkjLu5k4uJObumvwRzALBEY00yqSn7+t0RGJtGx42HV8ysqssnImEJx8c/VHYjKytaRn/8/QImISECkqiK0Ao8nH/ABEBbWnujofni9+SxZcqq/6WIcRUULOfzwD6qTAEBEROcmxRkZ2YVBg94mO/t8IiJiiYs7fZ+LcUzbZInAhDxXefoVnTv/otFOOz5fBdu3TyMz87HqdvDx8WfSu/cdFBf/TEbGH/B6i4iNPYaysgw8nkVERMSTkjKFpKRz6dhx0G7H9XoL8fkqiIxMRETwekvJzHycjRv/D5+vjJ49r6vuBLU3RISuXc/d6+1NaLA6AhPyMjP/Snr6HURHH8yAAS/W242/uHg5P/00jrKydDp2PJzk5NspL9/Ipk3/oLJyBwBdupxC//5/3+2CvzfKyjawY8eH9OhxZXVnLGP2hVUWG9OAwsIFLFz4Czp3HklZWSZlZen07HkdBx10D9HRyQDk5HzBsmXnEhYWzYABL5KQcGZ1EYvXW8L27e8QGZlAQsKv2nbRy7p18NJLcNVV0KdPsKMxzWSJwJh6eDxFLFgwAp+vlNTUJYSFRbN+/X1kZT0JKJ06HUdsbCqbNz9Lhw4DGTLkE6KjQ/QCWFYGxxwDS5dCVBTcdBPccw/E7Z/hEdq0Zcvg3nvhyivhjDMgQDcTlghMyFJVSkpWUFi4wD/EbwYdOx5GTMwIdu78iG3b3mTYsNl06XJi9TYlJWvIzp5Odva7FBUtIi5uNIMHv0NERKcgnkmQ3XgjPP00vPgi/O9/8OqrLgm8+SaMGdP8/ZWVQUFBzXRiIoTtoQexxwMRLVCtWVEB7do1vk5lJYSH7zmmpvL54KGH4OOP4b334KCD3PziYkhNhZUr3fSoUS4pZGTArFnuuy6vNVDd44/DZZftVQiNJQJUtVV9jjzySDWhy+utVK+3vEnrbd36ps6bN1Rnz0Znz0a//rq9zp07UOfMiayet27dfY3up6IiR30+X0uFv7vKStWMjMDtvzEbNqiuWaO6p/P74ANVUL3llpp5S5aoDh2qGham+te/7nkftX3xhWpCgttn1WfQINWPP65/P1lZqsceqxoVpXrqqap/+YvqV1+pfv21+6xc2fRjv/22amSk6rnnunOvq7BQ9YEHVDt2VO3WTfWii1Rfe021oKDpx8jLczFVnUthoeqECe48IyJUBwxQzc52y664QlVE9dNPVZ9+WjUxseY76dlT9cILVW+4oebz7bdNj6MOIE0buK4G/cLe3I8lgtDk8/l0+/b39IcfUvT77w/SgoK0etfzeIo0M/Pv+v33fXT2bHTu3IGalfWsFhX9rD6fR1VVvd4yLShI0+3b31Ovt3J/nsauKitVx493F4Lp0/d9f3PmqK5f3/g68+er3nij6qGH1lxw+vRRvfJK1eeeU/3Xv3b9PPusany86vDhqmVlu+6rsFD17LPdPiZPVi2vk6B9PtUPP1RdsEDV63XT//iHani46uDB7sL3zDMukVTFc+KJqjNmqJaUuH3Mnavao4dqTIzqVVe57WonkKrP+eerrl1bc9zFi1Xfe2/XmD//3CWBww5zF/qICNXrrqs51z//2V38wZ3Xb36jmpTkpg85RHXFisa/29JS1cceU+3SpeZCPnmy6hFHuIT5xBOq33yjGh2tevTRqi+95Na7556afeTnq771lupPPzUvuTaBJQLTqhUXr9LFi0/X2bPRefMO1++/761z5kTp5s2vqKqqz+fRoqKfdd26+/Xbb+N19mx0wYLjNDv7Q/X5vMENvkpamrsIFhe7aZ9P9fLL3f+CKSmq7dqpfvnl3u//u+/cvtq1U739dtWdO3df57nn3MWvfXvVsWNVn3zSXegnTFDt1Kn+Cyy4RLBqVf3H9XpV77/frfeb37jpKlXzwd3pHn+8+/vXv3YXvNoqKlwsXbu6daKiVEeNcv+mpKguXVqzblaW+66qPn/4g2qHDu4if8YZNRfzqu/2rbdU581zyWTIENXcXNXNm1Wvvtolpdrnevzxqj/+uOv5ffaZi6tTJ5ekavP5XIJ44gmXUMF9t88+65JTfLxqXJzqzJk123z4oUsM4J50Kiqa9BPvK0sEptXKzf1av/mmk37zTWfNzHxKvd5KLS/frosWnexPDEfo1193qC7q+emnszQv77tgh72rrVtrLk69eqm+/LLq3Xe76T/8QTUnx93pxsa6u+cqVXe2f/mLe3IYO9Z9Jkxw86tUVrpiml69VC+7zD1hxMW5opxPP3VFFdde6453xhluuq6KCtVNm+r/VCWvxvzf/7n933xzzZ0/qF56qerrr7silkMOUb3vvl2TRV0lJS7mW29VPfxwlzSqilEas3mze6pJSVGdNEl16lR3wR02zMURFuaWbdq063a5uTXnuXVrw3fhGza4fYmonnaa+x3GjFHt3bsmiaSmumKv2jwe9/vUNXWqe1LY0xNcC7JEYFql7OyP9Ouvo/XHHwdoaemGXZZ5vZW6bt39umjRSbp65U1aePtZ6hl3+n67u6pWUeEuchMnqq5evftyr1d19GhXHPDKK6rHHFNz4bjqqpoLT1aW6kEHuTvbvn3dp3Y5+oABqkcd5T4JCe4OtaqM+6mn3DpVxUtLl6qedZY7Zu273TvvdBemQPD5XBIA1XPOcRfMcePqvwjuT16vK+M/88z6f5/mKCpyv1nV73DUUe5c//Uv1XXrWibeALJEYILO5/NpQcEiTU+/VxcuPF43b365wXVLSzfqxo2P6+zZ4ZqWdpSWlzdyR1hQ4O4aqy52jz++dwGuW+fushcvVl22rPG71iper6vMA1fcEhHhyt83b65Z57HH3PLnnnPTPp/qO++oPvjg7hfl1avdXe3FF7vPFVe4O8e6d7ErVrhk0K+f6sKF7kli9Ojd72ZLSlRnzXJPH//5T/O/k+byel3xUFURS1U5vzkgWCIwQVVSsl7nzh3kL74J0x9+SNHZs9G1a39XXYZfUrJO16y5VX/88dDqYp7Fi0/TysoCVwm4YcPuO163zhWphIe7isdf/cqVA2dm1qxTVORamOTk1B+cx6P6u9/teucM7m62sZYiPp8regFXLLJli+o119SUOQ8f7pJCRISreGzplkdz59ZUeLZrt+93uy2lvNzdgddX/GSCyhKBCRqPp1jnzx+m33zTWTdt+peWl29Xr7dSV626prpMf9myiTp7dpjOmROpS5acoRs3/k0LC5e6ZpuLFrlKusTEXSsss7Jc5VxcXE257Lp1rjjkvPNqpg8/XKvLiI891lVg/u9/rsgiP98lD3B33++95z5/+pO7oB9++O6P/D6faxp42226S5l4lVWrVB9+2LV+iYhwMdZXcdsSZs1ySeDBBwOzf9OmNJYIrEOZCRhVZcWKi9m+/S2GDPmYhIQzd1mWlfUE6el3EB4eQ8+e15CcfPMuo2ySng4jR0JkpOsE1L49fPcddOgAJ5wAGzbAnDkwYkTNNn/6E/zhD/Dgg/DUU+D1wt/+5jrofPYZzJvnOvd06uQ+W7bA3/8O1123a/BffAHnn+86FJ12mpvn8bjtN25005deCi+/3HCno6Ii93wRW/8L0FtEQYE7D2P2IGg9i0VkDPAUEA68qKqP1FneB3gZSAJygItUNauxfVoiaD0yM58kPf1WUlIeIiXlvnrXKS5eQVRUz92HVt661SWBvDzXu7K0FE46yfXI7NwZ0tJg5kzXE7O28nIYMgTWrIGBA+Gjj6B//5rlOTnw1VcuKaxcCVOmwMkNjL2/dq0bV2fTppp5gwfD6NEuOfTr1+zvxJhgCUoiEPfuudXAaUAWMB+YpKrLa60zHfhEVV8VkZOBy1T14sb2a4kgOPLyviUv72uSk2/c5aKt6iUv71tyc78gN/cLCgvTqP3KxMTECQwe/G7TXkCem+su0J99Bv/9LxQWuov2Me5Vi3z1FYwd67r/v/MOnNvA8MppaW7ogylTXNIwxgQtEfwCmKKqo/3T9wCo6p9rrbMMGKOqmeKGbcxX1Uafcy0R7F81RTh3AV4iI7ty8MF/ISnpPLZufY3MzMf977gNp1Ono+nc+XjCwjoA7uXkPXpcRUREzJ4PtGKFK+7ZscONYXPqqXDzze6poLZvvnFFLmec0eLnakxbFqxXVfYCMmtNZwHH1FlnCXA2rvhoAhArIgmqurP2SiJyFXAVwEFVgzWZgPN6i1m16gq2b59GYuIEkpNvZt26u1m5cjKrVl2NajmxsUfRr9/DxMeP3XVQttJS+OAD6L/SleE3NnhXZqYrbgkPdxf6445zf9fnhBNa9iSNMUF/Q9kdwNMiMhn4BthE7XIFP1V9Hnge3BPB/gwwFHi9JYDu8naukpK1LFs2geLi5fTt+2cOOuh3iAjDh3/H1q2vkZ//Ld27X0LnzifsPgb/pk0wYQLMn++mExLg9NPhj3/ctbweYOdOlwTy8+Hrr2HYsMCerDFmN4FMBJuA3rWmk/3zqqnqZtwTASISA5yjqnkBjMnU4fUWs3DhsZSVbaBnz6vp1etmiouXsHz5hYiEc8QRnxIff3r1+iJh9JjbhR6z2sE/Ru4+dvq8eXDWWa58/803XauZzz6DDz+ETz91ZftVrXAWL4YrrnAvPJk1y5KAMUESyEQwH+gvIn1xCWAi8JvaK4hIIpCjqj7gHlwLIrOfqCqrV19LceHPJCSeSWbmE2RlPYWqh5iYYQydcSqRd02BB9TdtVeNqT5litvB6NHuol9l4UJXdNOjh7uwDxni5l94IaxfD+PHu7Hr//Qn12Ln9dehSxeXHE48sW54xpj9JGCJQFU9InIDMAvXfPRlVV0mIg/iOjZ8BJwE/FlEFFc0dH2g4jG727r1ZbZte52jHh1Ix6JcSt9bRFbBS4CPfumnE/7Ar12b/TFjXOVtbCy8/z5ccgl8+SX885+7JoKHH3brz5sHSUm7HqxvX9cH4OKL4fe/d2+5uvNOuPtue8uVMcHWUE+zA/VjPYv3nsdTrKWlmVpamqm5ud/o119H66q3jq4ZVuHkk9347VWjZQ4a5EZnfPJJN5xu7ZeQTJnitklPdztfvdoNNPb73zcehNfrxtqpb8gIY0zAYD2LQ5vPV8nmzc+yfv39eL01rwds164nxzx1NOGffgl//jPccINrm19U5HrszptXU7yTn+964Q4c6KazstwLzO+8Ex55BK691vWy3bABunff/ydpjGlUsJqPmiCorMxh6dIzCAtrR0zMCDp0OJRNm56lpGQZcXGnk5R0LuAqeOMLBhL+n5Pg1lvh+uvde2TvuMPt6Nlna5IAuI5ZtTtnJSfDr3/tLv433ghTp7oiI0sCxrQ6lgjamNWrr6OoaAGxsals2fI8Pl8p0dEpDB78PomJ43dt6vmXW1yrn5tvdtO33+7G5tm2Da65Zs8Hu+Ya1xpo/HiXRG6/PTAnZYwJKEsEbci2bdPIzn6bvn3/RJ8+9+LzeSgrW09UVG/Cw6N3XTk3F158ESZNcnf3Ve66q+kHPP10SEmBBQvc00FVsZExplVpwgAwpjUoL9/EmjXX0qnTsfTu/TsAwsIi6NCh/+5JAFzRT3FxTVHQ3ggLq3lyuPPOvd+PMSao7ImgDVD1sXLl5fh8FQwc+BphYY38rBkZrvnmv//txus54oh9O/htt7m+A7/4xb7txxgTNPZE0Aakp99Jbu5nHHzwX+kQfbBrAfTDD7uu5PG4BDBggBsD6N57Ydq0fT94ZKQlAWNaOXsiaOUyM/9GVtbf6NXrRnr2vNoN1fz737sL9D//CZdf7sbgv+AC97KVSy5xHb9q1wsYY0KaJYJWxOeroKRkBWFh7YmIiCM39zPS028nKelcDjnkCdci6J//hPh4OPJI+O1v4ccfYfZs91atl1+Gyy4L9mkYYw4wlggOcJWVuWzd+jK5uV+Ql/cNPl/JLss7dz6RgQNfRyTcvdXrgw9cc9BHHnEVuE8+CV27umRw3HFBOgtjzIHMEsEBStXLli0vs37976ms3EGHDgPp0eNyOnUaiaoHjycX8NG9++SaVkEvv+zqAq66CiIi4Iknapp19uwZ1PMxxhy4LBEcgMrKNrBs2bkUFqYR7zuWQ3+4mOhbHoKONe8LoLAQ/vEPuCgfDursOoI9/7x7/+6hh9as19D7eI0xxs9aDR2A0j6zpg0AACAASURBVNN/R3HxCg477E2GvHEY0fc9Aeef797VC+4F7RMmuJY/Rx3lRvWcNcuN89OUHsHGGFOLJYIDTEnJGrKzp9Or1w10yzsSee0196rHGTNc5a/H44Zy/vJLN65/p04wapQbL6hrVzfcgzHGNIMlggNMZuZfEIkkOfkWeOABiI52SeChh9yLXIYOhenT4bHH3BPBvHnupS6rV7umou3aBfsUjDGtjNURHEDKyzexdeur9OhxJVErt8Hbb7s+Ad26uYv+tm3w9NOuNVDV0BBxce4VkO+/73oKG2NMM1kiOIBkZv4VVR+9e98JF9zkhn2uuuCLwFNPuXf81h0WIiICzjtv/wdsjGkTLBEEUWVlHgUFPxIR0QmRdmze/C+6dZ1E++nfwMcfux7AtV/jGBbmioaMMaYFWSIIotWrryE7++3q6c4/waGvL4X5b8Dw4XDTTUGMzhgTKiwRBElZWSbtn3qHE18W8Ll5ogo9d8BLL8Gll0J4eHCDNMaEBEsEQZI954+kvKz4ThhJ+PH+Tl/dusHkybt2HDPGmACzRBAEXk8xne5+FV9MOyLe+QASE4MdkjEmhFk/giAoeO4mOi/xUPHHmywJGGOCLqCJQETGiMgqEVkrInfXs/wgEZktIotEZKmItPmG8JqbS8wDr1J0eAfa3/BIsMMxxpjAJQIRCQeeAcYCg4BJIjKozmr3Ae+o6nBgIvBsoOI5UFTcdgkR+V5KH78TscpgY8wBIJBPBEcDa1V1napWANOAugPhKNDJ/3dnYHMA49m/du6EgoJdZnmnv07U1E/YNLED8afu9oBkjDFBEchE0AvIrDWd5Z9X2xTgIhHJAmYAN9a3IxG5SkTSRCQtOzs7ELG2vDPOgP793ciggC9jDfrbyykYCB3+Or3mHQLGGBNkwa4sngRMVdVk4AzgdRHZLSZVfV5VU1U1NSkpab8H2WybN7vB4HJzYdQo9IXnKT3nOPB6qJj6V+K7t/mqEGNMKxLIRLAJ6F1rOtk/r7bfAu8AqOoPQDTQ+pvRzJrl/v38czjxROSqq+m4cAd5f55E4jG3BTc2Y4ypI5CJYD7QX0T6ikg7XGXwR3XW2QicAiAih+ESQSsp+2nEzJnQoweccAJl7/+TDReFkX3tESTc+GawIzPGmN0ErEOZqnpE5AZgFhAOvKyqy0TkQSBNVT8CbgdeEJFbcRXHk1VVAxXTfuH1uieBs84CETKyHmbbFZEcc8x/EZFgR2eMMbsJaM9iVZ2BqwSuPe/+Wn8vB0YGMob9bv58VzcwejTFxSvZuvVVkpNvITo6OdiRGWNMvWyIiZY2c6YbLvrUU8nIuJbw8A4cdJA1FTXGHLiC3Wqo7Zk5E44+msJ2G8jOnk5y8m20a9cKWjoZY0KWJYKWtHMnzJuHjh5NevodRETE07u3tRIyxhzYrGioJX3+OaiyZehm8vJmc+ihLxAR0TnYURljTKPsiaAlzZyJLy6W1Z1eoFu3i+jR47fBjsgYY/bIEkFL2LABLr4YXn2VHcdU0iF2EIce+k9rLmqMaRUsEeyrRx+FAQPQ6dPZNrkPa24SBg+eTni4vWXMGNM6WCLYFzt2wD33wMknkz/vJVZcuoE+Qx6lY8e6o20bY8yByxLBvvBXDusDD7DO8zRRUb3p2fOqYEdljDHNYolgX8ycCQkJ5PTNpqDgR/r0uZewsKhgR2WMMc1iiWBv+XwwaxZ6+ulkZD5IVFQfune/LNhRGWNMs1ki2FtLlsC2bRQd143CwvmkpPyBsLB2wY7KGGOazRLB3vK/c2Bd/6+Iju5Ht26XBDkgY4zZO3tMBCLy6/reGhbyZs7Ee8RAcqOWkpx8K2FhkcGOyBhj9kpTLvAXAGtE5C8iMjDQAbUKBQXw3XcUHBcPhNG16/nBjsgYY/baHhOBql4EDAfSgaki8oP/ZfKxAY/uQPXVV+DxsHnIeuLiTqFdu67BjsgYY/Zak4p8VLUAeBeYBvQAJgALReTGAMZ24Jo1C43pwI7+W+jadVKwozHGmH3SlDqCcSLyPjAHiASOVtWxwFDcqyZDiyrMnEnxsT2gXSSJiROCHZExxuyTpgxDfQ7whKp+U3umqpaISOgNr7l5M2RksP2sTsTHjyUyskuwIzLGmH3SlEQwBdhSNSEi7YFuqpqhql8GKrAD1qJFAOT3K6CnFQsZY9qAptQRTAd8taa9/nmhadEiVKCkf3sSE38d7GiMMWafNSURRKhqRdWE/++Q7UKrCxdQ1iuMuIPG21DTxpg2oSmJIFtExlVNiMh4YEfgQjqweRd8R+EhPrp3vzzYoRhjTItoSh3BNcCbIvI0IEAmEJLjKWhODhGZOygf152kuFODHY4xxrSIPSYCVU0HjhWRGP90UVN3LiJjgKeAcOBFVX2kzvIngFH+yQ5AV1U9YJvhFH77Mp2ADiMvtNdQGmPajKY8ESAiZwKDgeiqC6CqPriHbcKBZ4DTgCxgvoh8pKrLq9ZR1VtrrX8jrgfzAavomxfpBMSdfEuwQzHGmBbTlA5l/8SNN3QjrmjoPKBPE/Z9NLBWVdf5K5inAeMbWX8S8O8m7DcoiouXEb50FZ7unQjrlhzscIwxpsU0pbL4OFW9BMhV1T8CvwAObcJ2vXD1CVWy/PN2IyJ9gL7AVw0sv0pE0kQkLTs7uwmHbnmZmU8Qs1YIG3FsUI5vjDGB0pREUOb/t0REegKVuPGGWtJE4F1V9da3UFWfV9VUVU1NSkpq4UPvmceTT/aG1+mwEcKOPGa/H98YYwKpKXUEH4tIF+AxYCGgwAtN2G4T0LvWdLJ/Xn0mAtc3YZ9BUVAwjw7pFYgPGH5AV2MYY0yzNZoI/C+k+VJV84D/iMgnQLSq5jdh3/OB/iLSF5cAJgK/qecYA4E44IfmBr+/FBbOI3atf8ISgTGmjWm0aEhVfbiWP1XT5U1MAqiqB7gBmAWsAN5R1WUi8mDtDmq4BDFNVbXZ0e8nBQVz6bK+C8TFQZ+m1JMbY0zr0ZSioS9F5BzgveZerFV1BjCjzrz760xPac4+9zdVpaBgLoesDYfhQ8H6Dxhj2pimVBZfjRtkrlxECkSkUEQKAhzXAaOsbAOesu1Er8m3YiFjTJvUlJ7FoftKSqCwcC6xK0HKPXD00cEOxxhjWtweE4GInFDf/LovqmmrCgrmkjA/HA1T5FQbX8gY0/Y0pY7gzlp/R+N6DC8ATg5IRAeYgoJ5DEhrjxx9OMTHBzscY4xpcU0pGtrl7Ssi0ht4MmARHUB8vkrKNqXRYXk5PDAm2OEYY0xANKWyuK4s4LCWDuRAVFz8E13mlyMKjLFEYIxpm5pSR/APXG9icIljGK6HcZtXUDCX+Hmg8V2Q1NRgh2OMMQHRlDqCtFp/e4B/q+p3AYrngFKQ9yMHzxc4bTSEhwc7HGOMCYimJIJ3gbKqAeFEJFxEOqhqSWBDCz7vom9pl6NWLGSMadOaUkfwJdC+1nR74IvAhHPg8Hjyaf/tejcxenRwgzHGmABqSiKIrv16Sv/fHQIX0oGhqGgx8fPAc3g/6NHSo24bY8yBoymJoFhERlRNiMiRQGngQjowFG+dR+efgNFWLGSMaduaUkdwCzBdRDbjXlXZHffqyjatcsUPhHlBjh0V7FCMMSagmtKhbL7/nQED/LNWqWplYMMKvvLtKwCQxMQgR2KMMYHVlJfXXw90VNWfVfVnIEZErgt8aMGj6sOTvc5NdOkS3GCMMSbAmlJHcKX/DWUAqGoucGXgQgq+0tJ1hOdXuIm4uOAGY4wxAdaURBAuUvM2FhEJB9oFLqTgKy7+iYhi/4QlAmNMG9eUyuKZwNsi8i//9NXAp4ELKfiKi5cSWQgaFobExAQ7HGOMCaimJILfAVcB1/inl+JaDrVZRUVLSSrtjHQJh7C9GZfPGGNajz1e5fwvsJ8LZODeRXAy7mX0bVZx8VKiSjtZsZAxJiQ0+EQgIocCk/yfHcDbAKraphvWe73FlJam067kEOjSKdjhGGNMwDVWNLQS+Bb4laquBRCRW/dLVEFUXLwMUCILxZ4IjDEhobGiobOBLcBsEXlBRE7B9Sxu04qKlgIQXuS1RGCMCQkNJgJV/UBVJwIDgdm4oSa6ishzInJ6U3YuImNEZJWIrBWRuxtY53wRWS4iy0Tkrb05iZZUXLyU8PAYJK/IEoExJiQ0pbK4WFXf8r+7OBlYhGtJ1Ch/f4NngLHAIGCSiAyqs05/4B5gpKoOxiWboCou/omOHQYjubnWq9gYExKa1TZSVXNV9XlVPaUJqx8NrFXVdapaAUwDxtdZ50rgGX9vZVR1e3PiaWmqSlHRUmIiBkNFhT0RGGNCQiAbyfcCMmtNZ/nn1XYocKiIfCciP4pIvWM+i8hVIpImImnZ2dkBChcqKjbj8eQQ6+nnZlgiMMaEgGD3looA+gMn4ZqpviAiu5XH+J9CUlU1NSkpKWDB5Of/AEBMZR83w4qGjDEhIJCJYBPQu9Z0sn9ebVnAR6paqarrgdW4xBAUOTmfEh7emY6V/rDticAYEwICmQjmA/1FpK+ItAMmAh/VWecD3NMAIpKIKypaF8CYGqSq5OTMJD7+dMLyC91MSwTGmBAQsESgqh7gBmAWbkiKd1R1mYg8KCLj/KvNAnaKyHJcE9U7VXVnoGJqTHHxUioqNhMfPxZyc91MKxoyxoSApgw6t9dUdQYwo868+2v9rcBt/k9Q7dzpwoyPHwO5091MeyIwxoSAYFcWHzBycj4lJmY4UVE9IM//Hh57IjDGhABLBEBlZR75+d8TH3+Gm5GbCzExEBHQByZjjDkgWCIAcnM/B7wkJIytmmHFQsaYkGGJAFcsFBERR2zsMW5GXp4lAmNMyAj5RKDqIyfnU+LiTicszF8UZOMMGWNCSMgngqKiJVRUbK0pFgIrGjLGhJSQTwQFBd8D0KVLrRevWdGQMSaEhHwiKCxcRGRkIlFRtUbDsCcCY0wICflEUFS0iJiY4Yj4X75WWQlFRVZHYIwJGSGdCHy+CoqLfyYmZnjNzPx89689ERhjQkRIJ4Li4uWoVuyaCKrGGbJEYIwJESGdCIqKFgEQG1tPIrCiIWNMiAj5RBAeHkP79rVegVA1zpA9ERhjQkTIJ4KOHYciUutrsKIhY0yICdlEoOqjqGjxrsVCYEVDxpiQE7KJoLR0LV5v0a4VxWBFQ8aYkBOyiaCqojgmZsSuC3JzISoK2rcPQlTGGLP/hWwiKCxchEgkHTsO2nWBDThnjAkxIZsIXEXx4YSFtdt1gY0zZIwJMSGZCFSVoqKFu9cPgI0zZIwJOSGZCMrLN1FZuaPhRGBFQ8aYEBKSiaCmR/GI3Rda0ZAxJsSEZCIoL98IQPv2h+y+0IqGjDEhJqCJQETGiMgqEVkrInfXs3yyiGSLyGL/54pAxlOlsjIHgIiIOhd8n8+eCIwxISciUDsWkXDgGeA0IAuYLyIfqeryOqu+rao3BCqO+ng8uYSHxxAWFrnrgqIilwysjsAYE0IC+URwNLBWVdepagUwDRgfwOM1WWVlDhER8bsvsHGGjDEhKJCJoBeQWWs6yz+vrnNEZKmIvCsivetZjohcJSJpIpKWnZ29z4F5PDm7FwuBJQJjTEgKdmXxx0CKqh4BfA68Wt9Kqvq8qqaqampSUtI+H9TjySUysp4ngu3b3b+Jift8DGOMaS0CmQg2AbXv8JP986qp6k5VLfdPvggcGcB4qjVYNLR2rfv34IP3RxjGGHNACGQimA/0F5G+ItIOmAh8VHsFEelRa3IcsCKA8VRzTwT1FP+kp7vB5nr02H2ZMca0UQFrNaSqHhG5AZgFhAMvq+oyEXkQSFPVj4CbRGQc4AFygMmBiqe2Rp8IDjkERPZHGMYYc0AIWCIAUNUZwIw68+6v9fc9wD2BjKEur7cU1fL6K4vXroUBA/ZnOMYYE3TBrize7zwe15lst8pin88VDR1ST29jY4xpw0IuEVRWuiaiuz0RbNoE5eWWCIwxISfkEoHHk0PMWog7/xEoLq5ZYC2GjDEhKgQTQS5xCyDy64Xw/fc1C6oSgT0RGGNCTMglgsrKHNrt9E/MnVuzYO1aaNcOkpODEpcxxgRLyCUCj6eBRJCeDv36QXh4UOIyxphgCblEUFmZS9QO/8S8eaDq/q7qQ2CMMSEmoP0IDkQeTw5ROWEuBW7fDhs2QJ8+LhGMGhXs8IxplsrKSrKysigrKwt2KOYAER0dTXJyMpGRkXte2S/0EkFlDu12KPzyBPj6a1c8FB3tWhDZE4FpZbKysoiNjSUlJQWxHvEhT1XZuXMnWVlZ9O3bt8nbhVzRkDd3O+FlCmPGuAQwd661GDKtVllZGQkJCZYEDAAiQkJCQrOfEEMuEYRt9b/PoE8fGDHCEoFp9SwJmNr25r+HkEsEssXfZKhnTzjmGFi4EFasgIgIlxyMMSbEhFwiCN9W4P6oSgRlZfD++5CS4pKBMabJdu7cybBhwxg2bBjdu3enV69e1dMVFRWNbpuWlsZNN920x2Mcd9xxLRWuaUBIXflUfURk+4eV6NHDJQKANWtg9OjgBWZMK5WQkMDixYsBmDJlCjExMdxxxx3Vyz0eDxEN3GClpqaSmpq6x2N8X3sEgFbC6/US3or6JIVUIvB4CojaAb7YaMJiYqBjR0hKguxsqx8wrd6aNbdQVLS4RfcZEzOM/v2fbNY2kydPJjo6mkWLFjFy5EgmTpzIzTffTFlZGe3bt+eVV15hwIABzJkzh8cff5xPPvmEKVOmsHHjRtatW8fGjRu55ZZbqp8WYmJiKCoqYs6cOUyZMoXExER+/vlnjjzySN544w1EhBkzZnDbbbfRsWNHRo4cybp16/jkk092iSsjI4OLL76YYv8YY08//XT108ajjz7KG2+8QVhYGGPHjuWRRx5h7dq1XHPNNWRnZxMeHs706dPJzMysjhnghhtuIDU1lcmTJ5OSksIFF1zA559/zl133UVhYSHPP/88FRUVHHLIIbz++ut06NCBbdu2cc0117Bu3ToAnnvuOWbOnEl8fDy33HILAPfeey9du3bl5ptv3vsfrxlCLBG4XsW+bnGuTEzEPRV88oklAmNaUFZWFt9//z3h4eEUFBTw7bffEhERwRdffMHvf/97/vOf/+y2zcqVK5k9ezaFhYUMGDCAa6+9dre28IsWLWLZsmX07NmTkSNH8t1335GamsrVV1/NN998Q9++fZk0aVK9MXXt2pXPP/+c6Oho1qxZw6RJk0hLS+PTTz/lww8/ZO7cuXTo0IGcHDdU/YUXXsjdd9/NhAkTKCsrw+fzkZmZ2eh5JyQksHDhQsAVm1155ZUA3Hfffbz00kvceOON3HTTTZx44om8//77eL1eioqK6NmzJ2effTa33HILPp+PadOmMW/evGZ/73srxBKB61Xs65FUM9MSgWkjmnvnHkjnnXdeddFIfn4+l156KWvWrEFEqKysrHebM888k6ioKKKioujatSvbtm0juc7YX0cffXT1vGHDhpGRkUFMTAz9+vWrbjc/adIknn/++d32X1lZyQ033MDixYsJDw9n9erVAHzxxRdcdtlldOjQAYD4+HgKCwvZtGkTEyZMAFwnraa44IILqv/++eefue+++8jLy6OoqIjR/uLnr776itdeew2A8PBwOnfuTOfOnUlISGDRokVs27aN4cOHk5CQ0KRjtoSQSgSVlTm0zwEGd6+ZOW4cvPEGHHVU0OIypq3p2LFj9d9/+MMfGDVqFO+//z4ZGRmcdNJJ9W4TFRVV/Xd4eDgej2ev1mnIE088Qbdu3ViyZAk+n6/JF/faIiIi8Pl81dN12+vXPu/JkyfzwQcfMHToUKZOncqcOXMa3fcVV1zB1KlT2bp1K5dffnmzY9sXIdVqyFO5040z1LNXzcwjjoCVK6Fbt6DFZUxblp+fT69e7v+5qVOntvj+BwwYwLp168jIyADg7bffbjCOHj16EBYWxuuvv47X6wXgtNNO45VXXqGkpASAnJwcYmNjSU5O5oMPPgCgvLyckpIS+vTpw/LlyykvLycvL48vv/yywbgKCwvp0aMHlZWVvPnmm9XzTznlFJ577jnAVSrn5+cDMGHCBGbOnMn8+fOrnx72l9BKBNmbCKuEsF4pwQ7FmJBx1113cc899zB8+PBm3cE3Vfv27Xn22WcZM2YMRx55JLGxsXTu3Hm39a677jpeffVVhg4dysqVK6vv3seMGcO4ceNITU1l2LBhPP744wC8/vrr/P3vf+eII47guOOOY+vWrfTu3Zvzzz+fww8/nPPPP5/hw4c3GNdDDz3EMcccw8iRIxk4cGD1/KeeeorZs2czZMgQjjzySJYvXw5Au3btGDVqFOeff/5+b3EkWjX6ZiuRmpqqaWlpe7Xt5s9upufov+P79+uETbyohSMzZv9bsWIFhx12WLDDCLqioiJiYmJQVa6//nr69+/PrbfeGuywmsXn8zFixAimT59O//7992lf9f13ISILVLXe9roh9UTA5s0AhCWnBDcOY0yLeuGFFxg2bBiDBw8mPz+fq6++OtghNcvy5cs55JBDOOWUU/Y5CeyNkKosli3b3B89ewY3EGNMi7r11ltb3RNAbYMGDaruVxAMIfVEELbVP85Qjx7BDcQYYw4gAU0EIjJGRFaJyFoRubuR9c4RERWRPfc33wdhW/PwdIqA9u0DeRhjjGlVApYIRCQceAYYCwwCJonIoHrWiwVuBubWXdbSIrYX4UmyJGCMMbUF8ongaGCtqq5T1QpgGjC+nvUeAh4FAv6uvYjsMrzdYgN9GGOMaVUCmQh6AbUH5sjyz6smIiOA3qr638Z2JCJXiUiaiKRlZ2fvdUCR2ZV4u3XZ6+2NMbsaNWoUs2bN2mXek08+ybXXXtvgNieddBJVTcDPOOMM8vLydltnypQp1e35G/LBBx9Ut8EHuP/++/niiy+aE77xC1plsYiEAX8Dbt/Tuqr6vKqmqmpqUlLSnlavl89TRrudivZI3KvtjTG7mzRpEtOmTdtl3rRp0xoc+K2uGTNm0KXL3t2c1U0EDz74IKeeeupe7StYqno3B1sgE8EmoHet6WT/vCqxwOHAHBHJAI4FPgpUhbFnWzphXtAeNpSEaaNuuQVOOqllP/5hkRty7rnn8t///rf6JTQZGRls3ryZX/7yl1x77bWkpqYyePBgHnjggXq3T0lJYceOHQA8/PDDHHrooRx//PGsWrWqep0XXniBo446iqFDh3LOOedQUlLC999/z0cffcSdd97JsGHDSE9PZ/Lkybz77rsAfPnllwwfPpwhQ4Zw+eWXU15eXn28Bx54gBEjRjBkyBBWrly5W0wZGRn88pe/ZMSIEYwYMWKX9yE8+uijDBkyhKFDh3L33a79y9q1azn11FMZOnQoI0aMID09nTlz5vCrX/2qersbbriheniNlJQUfve731V3Hqvv/AC2bdvGhAkTGDp0KEOHDuX777/n/vvv58knawYXvPfee3nqqaca/Y2aIpCJYD7QX0T6ikg7YCLwUdVCVc1X1URVTVHVFOBHYJyq7l234T3wZrqRBunRq/EVjTFNFh8fz9FHH82nn34KuKeB888/HxHh4YcfJi0tjaVLl/L111+zdOnSBvezYMECpk2bxuLFi5kxYwbz58+vXnb22Wczf/58lixZwmGHHcZLL73Ecccdx7hx43jsscdYvHgxBx98cPX6ZWVlTJ48mbfffpuffvoJj8dTPbYPQGJiIgsXLuTaa6+tt/iparjqhQsX8vbbb1e/F6H2cNVLlizhrrvuAtxw1ddffz1Llizh+++/p0cTmqdXDVc9ceLEes8PqB6uesmSJSxcuJDBgwdz+eWXV49cWjVc9UUX7fsoCQHrUKaqHhG5AZgFhAMvq+oyEXkQSFPVjxrfQ8vyZaUDEJZ80P48rDH7z5PBGYa6qnho/PjxTJs2rfpC9s477/D888/j8XjYsmULy5cv54gjjqh3H99++y0TJkyoHgp63Lhx1csaGs65IatWraJv374ceuihAFx66aU888wz1S99OfvsswE48sgjee+993bbPhSHqw5oz2JVnQHMqDPv/gbWPSmQsfiyNgIgvQ7ew5rGmOYYP348t956KwsXLqSkpIQjjzyS9evX8/jjjzN//nzi4uKYPHnybkM2N1Vzh3Pek6qhrBsaxjoUh6sOmZ7FmpeNhkG4JQJjWlRMTAyjRo3i8ssvr64kLigooGPHjnTu3Jlt27ZVFx015IQTTuCDDz6gtLSUwsJCPv744+plDQ3nHBsbS2Fh4W77GjBgABkZGaxduxZwo4ieeOKJTT6fUByuOmQSQcEVx/LNZxAZY8NLGNPSJk2axJIlS6oTwdChQxk+fDgDBw7kN7/5DSNHjmx0+xEjRnDBBRcwdOhQxo4dy1G1XhTV0HDOEydO5LHHHmP48OGkp6dXz4+OjuaVV17hvPPOY8iQIYSFhXHNNdc0+VxCcbjqkBmGeseOD9m69VUGD56O6/RsTOtnw1CHnqYMV23DUDcgMXE8hx/+niUBY0yrFajhqkNqGGpjjGnNAjVcdcg8ERjTVrW24l0TWHvz34MlAmNasejoaHbu3GnJwAAuCezcubPZTV6taMiYViw5OZmsrCz2ZTBG07ZER0eTnJzcrG0sERjTikVGRtK3b99gh2FaOSsaMsaYEGeJwBhjQpwlAmOMCXGtrmexiGQDG5qxSSKwI0DhHMhC8bxD8ZwhNM87FM8Z9u28+6hqvW/2anWJoLlEJK2hbtVtWSiedyieM4TmeYfiOUPgztuKhowxJsRZIjDGmBAXCong+WAHECSheN6heM4QmucdiucMATrvNl9HYIwxpnGh8ERgjDGmEZYIjDEmxLXpRCAiY0RklYisFZG7gx1PIIhIbxGZLSLLRWSZiNzsnx8vIp+LyBr/v3HBjrWliUi4iCwSkU/8031FZK7/935bRNoFT4DvuAAABTJJREFUO8aWJiJdRORdEVkpIitE5Bch8lvf6v/v+2cR+beIRLe131tEXhaR7SLyc6159f624vzdf+5LRWTEvhy7zSYCca8iewYYCwwCJonIoOBGFRAe4HZVHQQcC1zvP8+7gS9VtT/wpX+6rbkZWFFr+lHgCVU9BMgFfhuUqALrKWCmqg4EhuLOv03/1iLSC7gJSFXVw4FwYCJt7/eeCoypM6+h33Ys0N//uQp4bl8O3GYTAXA0sFZV16lqBTANGB/kmFqcqm5R1YX+vwtxF4ZeuHN91b/aq8BZwYkwMEQkGTgTeNE/LcDJwLv+VdriOXcGTgBeAlDVClXNo43/1n4RQHsRiQA6AFtoY7+3qn4D5NSZ3dBvOx54TZ0fgS4i0mNvj92WE0EvILPWdJZ/XpslIinAcGAu0E1Vt/gXbQW6BSmsQHkSuAvw+acTgDz9//buJ0SrKg7j+PdJTUzBrCAKjSmSFlGptJBqEdbKohYFEkISbnLRn01YtApaRbSwIugPESUFlZm0kGqUCIo0YdL+UVmDKZnjIsMIMXlanDN5U19GY955497nA5f33vO+3DmH38v7u+fcM+faf9XjNsb7UmAMeLkOib0oaTYtj7XtfcCTwB5KAjgE7KD98YbesZ3U37c2J4JOkTQHeBt40Pbvzfdc5gi3Zp6wpFuBA7Z3DLouU2w6sAR4zvZi4A9OGAZqW6wB6rj47ZREeDEwm5OHUFqvn7FtcyLYByxoHM+vZa0jaQYlCay3vaEW/zreVayvBwZVvz64HrhN0ihlyG8ZZez83Dp0AO2M915gr+3P6vFblMTQ5lgD3Az8ZHvM9lFgA+U70PZ4Q+/YTurvW5sTwXZgYZ1ZcDbl5tKmAddp0tWx8ZeAb2w/1XhrE7Cq7q8C3p3quvWL7Udsz7c9RInrFtsrga3AnfVjrWozgO39wM+SrqhFNwFf0+JYV3uApZLOqd/38Xa3Ot5Vr9huAu6us4eWAocaQ0hnznZrN2A58B2wG3h00PXpUxtvoHQXdwIjdVtOGTMfBr4HPgTOG3Rd+9T+G4H36v5lwDbgB+BNYOag69eH9i4CPq/x3gjM60KsgceAb4EvgVeBmW2LN/A65R7IUUrvb3Wv2AKizIrcDeyizKj6z387S0xERHRcm4eGIiLiNCQRRER0XBJBRETHJRFERHRcEkFERMclEURUko5JGmlsk7Z4m6Sh5qqSEf8n0yf+SERn/Gl70aArETHV0iOImICkUUlPSNolaZuky2v5kKQtdT34YUmX1PILJb0j6Yu6XVdPNU3SC3Vd/fclzaqfv78+T2KnpDcG1MzosCSCiONmnTA0tKLx3iHbVwHPUFY+BXgaeMX21cB6YF0tXwd8ZPsaylpAX9XyhcCztq8EfgPuqOUPA4vree7tV+Miesl/FkdUkg7bnnOK8lFgme0f6wJ/+22fL+kgcJHto7X8F9sXSBoD5ts+0jjHEPCBywNGkLQWmGH7cUmbgcOUJSM22j7c56ZG/Et6BBGnxz32z8SRxv4xjt+ju4WybswSYHtjRc2IKZFEEHF6VjReP637n1BWPwVYCXxc94eBNfDPc5Xn9jqppLOABba3AmuBucBJvZKIfsqVR8RxsySNNI432x6fQjpP0k7KVf1dtew+ytPCHqI8OeyeWv4A8Lyk1ZQr/zWUVSVPZRrwWk0WAta5PH4yYsrkHkHEBOo9gmttHxx0XSL6IUNDEREdlx5BRETHpUcQEdFxSQQRER2XRBAR0XFJBBERHZdEEBHRcX8DOtQgplc8L5AAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpQnuB7AbIRr",
        "outputId": "55e2f2a2-a485-4885-9a6b-2ce6b9c38b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model200.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights200.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model200.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg3EguIabIRs",
        "outputId": "0ffd03b9-9180-49b4-c887-c663fe19b834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYO7wiXObIRs"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model200.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVGKLJv3bIRs",
        "outputId": "c7d9c6b0-c937-4041-9e78-526628650045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         7\n",
            "           2       1.00      1.00      1.00         7\n",
            "           3       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTT5iXq2bIRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "037ba3ce-2848-4e7c-d933-f02ef28ee4a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(11, 5))\n",
        "plt.subplot(121)\n",
        "labels = np.unique(y_pred_train_argmax)\n",
        "# cm = confusion_matrix(y_train_argmax, y_pred_train_argmax, labels=labels)\n",
        "# sns.heatmap(cm, annot=True, square=True, cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "# plt.title(f\"Training Accuracy: {accuracy_score(y_train_argmax, y_pred_train_argmax):.3f}\", fontsize=14)\n",
        "# plt.xlabel('Prediction', fontsize=14)\n",
        "# plt.ylabel('Actual', fontsize=14)\n",
        "# plt.yticks(rotation=0, verticalalignment='center')\n",
        "# plt.subplot(122)\n",
        "cm = confusion_matrix(y_test_argmax, y_pred_test_argmax, labels=labels)\n",
        "sns.heatmap(cm, annot=True, cmap='Greens', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "plt.title(f\"Validation Accuracy: {accuracy_score(y_test_argmax, y_pred_test_argmax):.3f}\", fontsize=14)\n",
        "plt.xlabel('Prediction', fontsize=14)\n",
        "plt.ylabel('Actual', fontsize=14)\n",
        "plt.yticks(rotation=0, verticalalignment='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_FfNBWpRLmF"
      },
      "source": [
        "#2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1581b89-7bac-423f-8a1a-236d29802e3f",
        "id": "prPx_jcnRLmF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  1e-05\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 0.00001\n",
        "# if epochs > 180:\n",
        "#     lr *= 0.5e-3\n",
        "# elif epochs > 160:\n",
        "#     lr *= 1e-3\n",
        "# elif epochs > 120:\n",
        "#     lr *= 1e-2\n",
        "# elif epochs > 80:\n",
        "#     lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb19563f-7d40-44bf-c8ee-5eea820d6355",
        "id": "UBMXKuZwRLmF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb_KqOFsRLmF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbfd21e-872b-46c3-c400-77b6dabaed7a",
        "id": "wOdF2WI2RLmG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2426084-8267-44bb-ed69-8d132fb17dcf",
        "id": "N6QBjsEkRLmG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 18s 294ms/step - loss: 1.3461 - accuracy: 0.3594 - val_loss: 1.4300 - val_accuracy: 0.3177\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 1.1692 - accuracy: 0.5056 - val_loss: 1.3899 - val_accuracy: 0.4427\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 1.0824 - accuracy: 0.5556 - val_loss: 1.3271 - val_accuracy: 0.5104\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.0067 - accuracy: 0.5950 - val_loss: 1.2401 - val_accuracy: 0.5182\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.9445 - accuracy: 0.6550 - val_loss: 1.1364 - val_accuracy: 0.5964\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8902 - accuracy: 0.6875 - val_loss: 1.0152 - val_accuracy: 0.6562\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8467 - accuracy: 0.7131 - val_loss: 0.9242 - val_accuracy: 0.6667\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.7915 - accuracy: 0.7519 - val_loss: 0.8354 - val_accuracy: 0.7344\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7542 - accuracy: 0.7638 - val_loss: 0.7566 - val_accuracy: 0.7917\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.7171 - accuracy: 0.7950 - val_loss: 0.7255 - val_accuracy: 0.7917\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.6845 - accuracy: 0.8062 - val_loss: 0.6842 - val_accuracy: 0.8073\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.6556 - accuracy: 0.8006 - val_loss: 0.6454 - val_accuracy: 0.8333\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.6341 - accuracy: 0.8100 - val_loss: 0.6146 - val_accuracy: 0.8411\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5973 - accuracy: 0.8231 - val_loss: 0.5960 - val_accuracy: 0.8411\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.5762 - accuracy: 0.8388 - val_loss: 0.5814 - val_accuracy: 0.8464\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 13s 267ms/step - loss: 0.5455 - accuracy: 0.8494 - val_loss: 0.5443 - val_accuracy: 0.8464\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.5301 - accuracy: 0.8550 - val_loss: 0.5442 - val_accuracy: 0.8333\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5092 - accuracy: 0.8644 - val_loss: 0.5178 - val_accuracy: 0.8620\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.4908 - accuracy: 0.8594 - val_loss: 0.5191 - val_accuracy: 0.8568\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4675 - accuracy: 0.8775 - val_loss: 0.4857 - val_accuracy: 0.8672\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.4591 - accuracy: 0.8763 - val_loss: 0.4754 - val_accuracy: 0.8698\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4405 - accuracy: 0.8869 - val_loss: 0.4560 - val_accuracy: 0.8698\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4289 - accuracy: 0.8763 - val_loss: 0.4530 - val_accuracy: 0.8776\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.4106 - accuracy: 0.8988 - val_loss: 0.4561 - val_accuracy: 0.8620\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3985 - accuracy: 0.8963 - val_loss: 0.4265 - val_accuracy: 0.8802\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.3914 - accuracy: 0.8931 - val_loss: 0.4206 - val_accuracy: 0.8750\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.3776 - accuracy: 0.8913 - val_loss: 0.4097 - val_accuracy: 0.8932\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3729 - accuracy: 0.8981 - val_loss: 0.4035 - val_accuracy: 0.8958\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.3691 - accuracy: 0.8944 - val_loss: 0.3818 - val_accuracy: 0.8906\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3465 - accuracy: 0.8994 - val_loss: 0.3919 - val_accuracy: 0.8750\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 13s 269ms/step - loss: 0.3372 - accuracy: 0.9094 - val_loss: 0.3808 - val_accuracy: 0.8958\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3268 - accuracy: 0.9106 - val_loss: 0.3713 - val_accuracy: 0.8984\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3061 - accuracy: 0.9212 - val_loss: 0.3633 - val_accuracy: 0.8984\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3067 - accuracy: 0.9200 - val_loss: 0.3532 - val_accuracy: 0.9089\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3032 - accuracy: 0.9075 - val_loss: 0.3655 - val_accuracy: 0.8958\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2965 - accuracy: 0.9181 - val_loss: 0.3466 - val_accuracy: 0.8958\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2901 - accuracy: 0.9175 - val_loss: 0.3402 - val_accuracy: 0.9141\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2776 - accuracy: 0.9225 - val_loss: 0.3383 - val_accuracy: 0.8958\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.2807 - accuracy: 0.9237 - val_loss: 0.3222 - val_accuracy: 0.9141\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2670 - accuracy: 0.9319 - val_loss: 0.3204 - val_accuracy: 0.9141\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2567 - accuracy: 0.9331 - val_loss: 0.3194 - val_accuracy: 0.9010\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2491 - accuracy: 0.9312 - val_loss: 0.3182 - val_accuracy: 0.9167\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2456 - accuracy: 0.9375 - val_loss: 0.3140 - val_accuracy: 0.9036\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.2445 - accuracy: 0.9369 - val_loss: 0.3276 - val_accuracy: 0.9036\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2390 - accuracy: 0.9356 - val_loss: 0.3038 - val_accuracy: 0.9167\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2290 - accuracy: 0.9413 - val_loss: 0.3043 - val_accuracy: 0.9141\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.2245 - accuracy: 0.9394 - val_loss: 0.3033 - val_accuracy: 0.9193\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2283 - accuracy: 0.9388 - val_loss: 0.3497 - val_accuracy: 0.8802\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2216 - accuracy: 0.9369 - val_loss: 0.2932 - val_accuracy: 0.9219\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2223 - accuracy: 0.9419 - val_loss: 0.2843 - val_accuracy: 0.9271\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2125 - accuracy: 0.9438 - val_loss: 0.2844 - val_accuracy: 0.9193\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.2081 - accuracy: 0.9438 - val_loss: 0.2906 - val_accuracy: 0.9167\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2009 - accuracy: 0.9463 - val_loss: 0.2734 - val_accuracy: 0.9167\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.2022 - accuracy: 0.9469 - val_loss: 0.2830 - val_accuracy: 0.9193\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1846 - accuracy: 0.9575 - val_loss: 0.2793 - val_accuracy: 0.9193\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1874 - accuracy: 0.9600 - val_loss: 0.2683 - val_accuracy: 0.9271\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1898 - accuracy: 0.9544 - val_loss: 0.2617 - val_accuracy: 0.9297\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1771 - accuracy: 0.9569 - val_loss: 0.2642 - val_accuracy: 0.9271\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1789 - accuracy: 0.9531 - val_loss: 0.2620 - val_accuracy: 0.9245\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1792 - accuracy: 0.9631 - val_loss: 0.2558 - val_accuracy: 0.9297\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 13s 269ms/step - loss: 0.1802 - accuracy: 0.9525 - val_loss: 0.2618 - val_accuracy: 0.9271\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.1657 - accuracy: 0.9625 - val_loss: 0.2585 - val_accuracy: 0.9193\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1695 - accuracy: 0.9575 - val_loss: 0.2369 - val_accuracy: 0.9245\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1626 - accuracy: 0.9544 - val_loss: 0.2475 - val_accuracy: 0.9271\n",
            "Epoch 65/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1580 - accuracy: 0.9650 - val_loss: 0.2559 - val_accuracy: 0.9219\n",
            "Epoch 66/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1645 - accuracy: 0.9606 - val_loss: 0.2312 - val_accuracy: 0.9375\n",
            "Epoch 67/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1526 - accuracy: 0.9619 - val_loss: 0.2480 - val_accuracy: 0.9219\n",
            "Epoch 68/200\n",
            "50/50 [==============================] - 13s 268ms/step - loss: 0.1483 - accuracy: 0.9725 - val_loss: 0.2404 - val_accuracy: 0.9271\n",
            "Epoch 69/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1495 - accuracy: 0.9650 - val_loss: 0.2421 - val_accuracy: 0.9271\n",
            "Epoch 70/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1504 - accuracy: 0.9638 - val_loss: 0.2343 - val_accuracy: 0.9323\n",
            "Epoch 71/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1360 - accuracy: 0.9712 - val_loss: 0.2281 - val_accuracy: 0.9245\n",
            "Epoch 72/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1426 - accuracy: 0.9694 - val_loss: 0.2288 - val_accuracy: 0.9349\n",
            "Epoch 73/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1300 - accuracy: 0.9737 - val_loss: 0.2361 - val_accuracy: 0.9297\n",
            "Epoch 74/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1372 - accuracy: 0.9650 - val_loss: 0.2311 - val_accuracy: 0.9297\n",
            "Epoch 75/200\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.1369 - accuracy: 0.9688 - val_loss: 0.2220 - val_accuracy: 0.9297\n",
            "Epoch 76/200\n",
            "50/50 [==============================] - 13s 268ms/step - loss: 0.1253 - accuracy: 0.9744 - val_loss: 0.2302 - val_accuracy: 0.9271\n",
            "Epoch 77/200\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1256 - accuracy: 0.9725 - val_loss: 0.2245 - val_accuracy: 0.9245\n",
            "Epoch 78/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1249 - accuracy: 0.9719 - val_loss: 0.2218 - val_accuracy: 0.9323\n",
            "Epoch 79/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1148 - accuracy: 0.9775 - val_loss: 0.2126 - val_accuracy: 0.9349\n",
            "Epoch 80/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1214 - accuracy: 0.9731 - val_loss: 0.2069 - val_accuracy: 0.9349\n",
            "Epoch 81/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1171 - accuracy: 0.9725 - val_loss: 0.2148 - val_accuracy: 0.9349\n",
            "Epoch 82/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1124 - accuracy: 0.9812 - val_loss: 0.2231 - val_accuracy: 0.9219\n",
            "Epoch 83/200\n",
            "50/50 [==============================] - 14s 269ms/step - loss: 0.1206 - accuracy: 0.9756 - val_loss: 0.2239 - val_accuracy: 0.9297\n",
            "Epoch 84/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1075 - accuracy: 0.9794 - val_loss: 0.2111 - val_accuracy: 0.9401\n",
            "Epoch 85/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.1086 - accuracy: 0.9781 - val_loss: 0.2039 - val_accuracy: 0.9297\n",
            "Epoch 86/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1104 - accuracy: 0.9787 - val_loss: 0.2258 - val_accuracy: 0.9271\n",
            "Epoch 87/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.1068 - accuracy: 0.9806 - val_loss: 0.2076 - val_accuracy: 0.9323\n",
            "Epoch 88/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.1071 - accuracy: 0.9781 - val_loss: 0.2119 - val_accuracy: 0.9323\n",
            "Epoch 89/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.1048 - accuracy: 0.9744 - val_loss: 0.2185 - val_accuracy: 0.9375\n",
            "Epoch 90/200\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.1023 - accuracy: 0.9775 - val_loss: 0.2195 - val_accuracy: 0.9323\n",
            "Epoch 91/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0909 - accuracy: 0.9825 - val_loss: 0.2151 - val_accuracy: 0.9323\n",
            "Epoch 92/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0918 - accuracy: 0.9819 - val_loss: 0.2154 - val_accuracy: 0.9401\n",
            "Epoch 93/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0978 - accuracy: 0.9819 - val_loss: 0.2064 - val_accuracy: 0.9375\n",
            "Epoch 94/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0906 - accuracy: 0.9825 - val_loss: 0.2094 - val_accuracy: 0.9323\n",
            "Epoch 95/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0926 - accuracy: 0.9806 - val_loss: 0.2103 - val_accuracy: 0.9323\n",
            "Epoch 96/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.0949 - accuracy: 0.9775 - val_loss: 0.2029 - val_accuracy: 0.9375\n",
            "Epoch 97/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0958 - accuracy: 0.9794 - val_loss: 0.1944 - val_accuracy: 0.9401\n",
            "Epoch 98/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0829 - accuracy: 0.9837 - val_loss: 0.2075 - val_accuracy: 0.9375\n",
            "Epoch 99/200\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.0834 - accuracy: 0.9812 - val_loss: 0.1924 - val_accuracy: 0.9427\n",
            "Epoch 100/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0827 - accuracy: 0.9862 - val_loss: 0.2073 - val_accuracy: 0.9375\n",
            "Epoch 101/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0866 - accuracy: 0.9869 - val_loss: 0.1997 - val_accuracy: 0.9349\n",
            "Epoch 102/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0815 - accuracy: 0.9837 - val_loss: 0.1961 - val_accuracy: 0.9427\n",
            "Epoch 103/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0833 - accuracy: 0.9825 - val_loss: 0.1961 - val_accuracy: 0.9427\n",
            "Epoch 104/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0807 - accuracy: 0.9856 - val_loss: 0.1860 - val_accuracy: 0.9427\n",
            "Epoch 105/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0773 - accuracy: 0.9825 - val_loss: 0.2020 - val_accuracy: 0.9401\n",
            "Epoch 106/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0749 - accuracy: 0.9875 - val_loss: 0.1971 - val_accuracy: 0.9375\n",
            "Epoch 107/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0763 - accuracy: 0.9819 - val_loss: 0.1900 - val_accuracy: 0.9401\n",
            "Epoch 108/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0750 - accuracy: 0.9837 - val_loss: 0.1955 - val_accuracy: 0.9375\n",
            "Epoch 109/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0693 - accuracy: 0.9906 - val_loss: 0.1894 - val_accuracy: 0.9401\n",
            "Epoch 110/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0705 - accuracy: 0.9900 - val_loss: 0.1909 - val_accuracy: 0.9401\n",
            "Epoch 111/200\n",
            "50/50 [==============================] - 14s 271ms/step - loss: 0.0754 - accuracy: 0.9875 - val_loss: 0.2024 - val_accuracy: 0.9427\n",
            "Epoch 112/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0732 - accuracy: 0.9831 - val_loss: 0.2001 - val_accuracy: 0.9453\n",
            "Epoch 113/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0679 - accuracy: 0.9856 - val_loss: 0.1751 - val_accuracy: 0.9401\n",
            "Epoch 114/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0611 - accuracy: 0.9906 - val_loss: 0.1891 - val_accuracy: 0.9349\n",
            "Epoch 115/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0628 - accuracy: 0.9894 - val_loss: 0.1837 - val_accuracy: 0.9401\n",
            "Epoch 116/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0723 - accuracy: 0.9875 - val_loss: 0.1809 - val_accuracy: 0.9401\n",
            "Epoch 117/200\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.0678 - accuracy: 0.9869 - val_loss: 0.1895 - val_accuracy: 0.9401\n",
            "Epoch 118/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0660 - accuracy: 0.9875 - val_loss: 0.1917 - val_accuracy: 0.9375\n",
            "Epoch 119/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0637 - accuracy: 0.9869 - val_loss: 0.1840 - val_accuracy: 0.9375\n",
            "Epoch 120/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0594 - accuracy: 0.9919 - val_loss: 0.1768 - val_accuracy: 0.9453\n",
            "Epoch 121/200\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.0580 - accuracy: 0.9912 - val_loss: 0.1854 - val_accuracy: 0.9427\n",
            "Epoch 122/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0550 - accuracy: 0.9931 - val_loss: 0.1782 - val_accuracy: 0.9505\n",
            "Epoch 123/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0589 - accuracy: 0.9900 - val_loss: 0.1853 - val_accuracy: 0.9401\n",
            "Epoch 124/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0550 - accuracy: 0.9900 - val_loss: 0.1795 - val_accuracy: 0.9375\n",
            "Epoch 125/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0559 - accuracy: 0.9919 - val_loss: 0.1814 - val_accuracy: 0.9401\n",
            "Epoch 126/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0582 - accuracy: 0.9906 - val_loss: 0.1922 - val_accuracy: 0.9349\n",
            "Epoch 127/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0564 - accuracy: 0.9881 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
            "Epoch 128/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0600 - accuracy: 0.9875 - val_loss: 0.1694 - val_accuracy: 0.9479\n",
            "Epoch 129/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0492 - accuracy: 0.9912 - val_loss: 0.1771 - val_accuracy: 0.9349\n",
            "Epoch 130/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0593 - accuracy: 0.9881 - val_loss: 0.1836 - val_accuracy: 0.9349\n",
            "Epoch 131/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0548 - accuracy: 0.9887 - val_loss: 0.1752 - val_accuracy: 0.9505\n",
            "Epoch 132/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0536 - accuracy: 0.9887 - val_loss: 0.1823 - val_accuracy: 0.9427\n",
            "Epoch 133/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.0525 - accuracy: 0.9900 - val_loss: 0.1819 - val_accuracy: 0.9427\n",
            "Epoch 134/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0497 - accuracy: 0.9919 - val_loss: 0.1723 - val_accuracy: 0.9479\n",
            "Epoch 135/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0548 - accuracy: 0.9906 - val_loss: 0.1770 - val_accuracy: 0.9349\n",
            "Epoch 136/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0435 - accuracy: 0.9962 - val_loss: 0.1568 - val_accuracy: 0.9427\n",
            "Epoch 137/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0456 - accuracy: 0.9925 - val_loss: 0.1786 - val_accuracy: 0.9453\n",
            "Epoch 138/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0444 - accuracy: 0.9950 - val_loss: 0.1730 - val_accuracy: 0.9427\n",
            "Epoch 139/200\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.0432 - accuracy: 0.9937 - val_loss: 0.1629 - val_accuracy: 0.9505\n",
            "Epoch 140/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0416 - accuracy: 0.9944 - val_loss: 0.1800 - val_accuracy: 0.9401\n",
            "Epoch 141/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0365 - accuracy: 0.9969 - val_loss: 0.1560 - val_accuracy: 0.9479\n",
            "Epoch 142/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0416 - accuracy: 0.9950 - val_loss: 0.1749 - val_accuracy: 0.9375\n",
            "Epoch 143/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.1758 - val_accuracy: 0.9323\n",
            "Epoch 144/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0455 - accuracy: 0.9912 - val_loss: 0.1759 - val_accuracy: 0.9427\n",
            "Epoch 145/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0375 - accuracy: 0.9937 - val_loss: 0.1592 - val_accuracy: 0.9453\n",
            "Epoch 146/200\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.0358 - accuracy: 0.9962 - val_loss: 0.1646 - val_accuracy: 0.9479\n",
            "Epoch 147/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0357 - accuracy: 0.9962 - val_loss: 0.1706 - val_accuracy: 0.9427\n",
            "Epoch 148/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0391 - accuracy: 0.9944 - val_loss: 0.1478 - val_accuracy: 0.9531\n",
            "Epoch 149/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.0407 - accuracy: 0.9937 - val_loss: 0.1523 - val_accuracy: 0.9453\n",
            "Epoch 150/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0436 - accuracy: 0.9906 - val_loss: 0.1727 - val_accuracy: 0.9427\n",
            "Epoch 151/200\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.0341 - accuracy: 0.9962 - val_loss: 0.1649 - val_accuracy: 0.9453\n",
            "Epoch 152/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0362 - accuracy: 0.9937 - val_loss: 0.1646 - val_accuracy: 0.9453\n",
            "Epoch 153/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0395 - accuracy: 0.9919 - val_loss: 0.1682 - val_accuracy: 0.9479\n",
            "Epoch 154/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0348 - accuracy: 0.9937 - val_loss: 0.1608 - val_accuracy: 0.9505\n",
            "Epoch 155/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0332 - accuracy: 0.9969 - val_loss: 0.1579 - val_accuracy: 0.9479\n",
            "Epoch 156/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0336 - accuracy: 0.9969 - val_loss: 0.1536 - val_accuracy: 0.9557\n",
            "Epoch 157/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0295 - accuracy: 0.9981 - val_loss: 0.1554 - val_accuracy: 0.9505\n",
            "Epoch 158/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0374 - accuracy: 0.9950 - val_loss: 0.1606 - val_accuracy: 0.9479\n",
            "Epoch 159/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0337 - accuracy: 0.9931 - val_loss: 0.1647 - val_accuracy: 0.9453\n",
            "Epoch 160/200\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.0310 - accuracy: 0.9950 - val_loss: 0.1659 - val_accuracy: 0.9479\n",
            "Epoch 161/200\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.0302 - accuracy: 0.9962 - val_loss: 0.1667 - val_accuracy: 0.9427\n",
            "Epoch 162/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0291 - accuracy: 0.9969 - val_loss: 0.1700 - val_accuracy: 0.9453\n",
            "Epoch 163/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0318 - accuracy: 0.9956 - val_loss: 0.1668 - val_accuracy: 0.9479\n",
            "Epoch 164/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0302 - accuracy: 0.9962 - val_loss: 0.1656 - val_accuracy: 0.9427\n",
            "Epoch 165/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0272 - accuracy: 0.9981 - val_loss: 0.1574 - val_accuracy: 0.9427\n",
            "Epoch 166/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0261 - accuracy: 0.9987 - val_loss: 0.1612 - val_accuracy: 0.9505\n",
            "Epoch 167/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0248 - accuracy: 0.9981 - val_loss: 0.1693 - val_accuracy: 0.9479\n",
            "Epoch 168/200\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0266 - accuracy: 0.9962 - val_loss: 0.1620 - val_accuracy: 0.9479\n",
            "Epoch 169/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0273 - accuracy: 0.9975 - val_loss: 0.1496 - val_accuracy: 0.9531\n",
            "Epoch 170/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.1844 - val_accuracy: 0.9401\n",
            "Epoch 171/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0293 - accuracy: 0.9962 - val_loss: 0.1698 - val_accuracy: 0.9427\n",
            "Epoch 172/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0306 - accuracy: 0.9962 - val_loss: 0.1679 - val_accuracy: 0.9505\n",
            "Epoch 173/200\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.0242 - accuracy: 0.9994 - val_loss: 0.1588 - val_accuracy: 0.9453\n",
            "Epoch 174/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0259 - accuracy: 0.9981 - val_loss: 0.1497 - val_accuracy: 0.9557\n",
            "Epoch 175/200\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.0232 - accuracy: 0.9969 - val_loss: 0.1545 - val_accuracy: 0.9453\n",
            "Epoch 176/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0306 - accuracy: 0.9937 - val_loss: 0.1609 - val_accuracy: 0.9427\n",
            "Epoch 177/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0231 - accuracy: 0.9962 - val_loss: 0.1606 - val_accuracy: 0.9479\n",
            "Epoch 178/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0216 - accuracy: 0.9987 - val_loss: 0.1556 - val_accuracy: 0.9453\n",
            "Epoch 179/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0226 - accuracy: 0.9969 - val_loss: 0.1577 - val_accuracy: 0.9479\n",
            "Epoch 180/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.1764 - val_accuracy: 0.9427\n",
            "Epoch 181/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0237 - accuracy: 0.9987 - val_loss: 0.1680 - val_accuracy: 0.9453\n",
            "Epoch 182/200\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.1676 - val_accuracy: 0.9427\n",
            "Epoch 183/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0226 - accuracy: 0.9962 - val_loss: 0.1540 - val_accuracy: 0.9505\n",
            "Epoch 184/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0247 - accuracy: 0.9950 - val_loss: 0.1751 - val_accuracy: 0.9453\n",
            "Epoch 185/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0195 - accuracy: 0.9994 - val_loss: 0.1511 - val_accuracy: 0.9453\n",
            "Epoch 186/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0198 - accuracy: 0.9994 - val_loss: 0.1554 - val_accuracy: 0.9453\n",
            "Epoch 187/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0208 - accuracy: 0.9987 - val_loss: 0.1465 - val_accuracy: 0.9557\n",
            "Epoch 188/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.1619 - val_accuracy: 0.9479\n",
            "Epoch 189/200\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 0.1595 - val_accuracy: 0.9479\n",
            "Epoch 190/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0170 - accuracy: 0.9981 - val_loss: 0.1368 - val_accuracy: 0.9583\n",
            "Epoch 191/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0196 - accuracy: 0.9981 - val_loss: 0.1513 - val_accuracy: 0.9531\n",
            "Epoch 192/200\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0179 - accuracy: 0.9987 - val_loss: 0.1413 - val_accuracy: 0.9453\n",
            "Epoch 193/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0246 - accuracy: 0.9962 - val_loss: 0.1554 - val_accuracy: 0.9479\n",
            "Epoch 194/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0178 - accuracy: 0.9987 - val_loss: 0.1575 - val_accuracy: 0.9453\n",
            "Epoch 195/200\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.0200 - accuracy: 0.9975 - val_loss: 0.1550 - val_accuracy: 0.9427\n",
            "Epoch 196/200\n",
            "50/50 [==============================] - 13s 265ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9505\n",
            "Epoch 197/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0188 - accuracy: 0.9975 - val_loss: 0.1567 - val_accuracy: 0.9427\n",
            "Epoch 198/200\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 0.1680 - val_accuracy: 0.9453\n",
            "Epoch 199/200\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0175 - accuracy: 0.9994 - val_loss: 0.1604 - val_accuracy: 0.9531\n",
            "Epoch 200/200\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9531\n",
            "CPU times: user 40min 22s, sys: 1min 57s, total: 42min 20s\n",
            "Wall time: 45min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "4a6c65b0-72c9-4602-c0d5-d0dc55c0b5cb",
        "id": "2wUcJVSJRLmG"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42205dd7-213e-4e11-c4d2-e5c6663ac357",
        "id": "xUqityVWRLmG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model1200.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights1200.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model1200.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3aef69-1c89-436a-dfba-7b09a78dc8bb",
        "id": "bTEOr1KtRLmG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inBu1rdrRLmG"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model1200.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfa5425-3a0a-4dcb-c839-d5377760ef7f",
        "id": "2kWc1QWcRLmG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 796ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         6\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        14\n",
            "           1       1.00      1.00      1.00         6\n",
            "           2       1.00      1.00      1.00         8\n",
            "           3       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.95      0.98      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "7D0yI5taRLmG",
        "outputId": "c64016ff-db34-41a4-a19e-fbe2be70b765"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(11, 5))\n",
        "plt.subplot(121)\n",
        "labels = np.unique(y_pred_train_argmax)\n",
        "# cm = confusion_matrix(y_train_argmax, y_pred_train_argmax, labels=labels)\n",
        "# sns.heatmap(cm, annot=True, square=True, cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "# plt.title(f\"Training Accuracy: {accuracy_score(y_train_argmax, y_pred_train_argmax):.3f}\", fontsize=14)\n",
        "# plt.xlabel('Prediction', fontsize=14)\n",
        "# plt.ylabel('Actual', fontsize=14)\n",
        "# plt.yticks(rotation=0, verticalalignment='center')\n",
        "# plt.subplot(122)\n",
        "cm = confusion_matrix(y_test_argmax, y_pred_test_argmax, labels=labels)\n",
        "sns.heatmap(cm, annot=True, cmap='Greens', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "plt.title(f\"Validation Accuracy: {accuracy_score(y_test_argmax, y_pred_test_argmax):.3f}\", fontsize=14)\n",
        "plt.xlabel('Prediction', fontsize=14)\n",
        "plt.ylabel('Actual', fontsize=14)\n",
        "plt.yticks(rotation=0, verticalalignment='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFfmbGN9ZCC3"
      },
      "source": [
        "#2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b087b3-3423-4e45-f6bd-8df23666ed41",
        "id": "87eTzSe2ZCC8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  1e-05\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 300\n",
        "batch_size = 16\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 0.00001\n",
        "# if epochs > 180:\n",
        "#     lr *= 0.5e-3\n",
        "# elif epochs > 160:\n",
        "#     lr *= 1e-3\n",
        "# elif epochs > 120:\n",
        "#     lr *= 1e-2\n",
        "# elif epochs > 80:\n",
        "#     lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f807c54-731d-4f65-e4ac-f17ec2df60b6",
        "id": "6j9I0cDYZCC8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUF_FxkHZCC8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594f22b0-3d82-499c-a184-6f7e70bd8533",
        "id": "AL1-ckNqZCC9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b36bfd-1e99-4d9a-eb52-3d08660ff941",
        "id": "o1EZKalNZCC9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "100/100 [==============================] - 18s 143ms/step - loss: 1.2615 - accuracy: 0.4150 - val_loss: 1.3285 - val_accuracy: 0.4325\n",
            "Epoch 2/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 1.0975 - accuracy: 0.5450 - val_loss: 1.2224 - val_accuracy: 0.5075\n",
            "Epoch 3/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.9993 - accuracy: 0.6256 - val_loss: 1.0637 - val_accuracy: 0.6200\n",
            "Epoch 4/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.9107 - accuracy: 0.6681 - val_loss: 0.8972 - val_accuracy: 0.7275\n",
            "Epoch 5/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.8444 - accuracy: 0.7094 - val_loss: 0.8054 - val_accuracy: 0.7775\n",
            "Epoch 6/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.7868 - accuracy: 0.7350 - val_loss: 0.7408 - val_accuracy: 0.7775\n",
            "Epoch 7/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.7368 - accuracy: 0.7713 - val_loss: 0.6825 - val_accuracy: 0.8025\n",
            "Epoch 8/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.6987 - accuracy: 0.7756 - val_loss: 0.6522 - val_accuracy: 0.8100\n",
            "Epoch 9/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.6527 - accuracy: 0.8025 - val_loss: 0.6227 - val_accuracy: 0.8100\n",
            "Epoch 10/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.6244 - accuracy: 0.8119 - val_loss: 0.5808 - val_accuracy: 0.8575\n",
            "Epoch 11/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.5830 - accuracy: 0.8288 - val_loss: 0.5612 - val_accuracy: 0.8475\n",
            "Epoch 12/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.5525 - accuracy: 0.8256 - val_loss: 0.5326 - val_accuracy: 0.8475\n",
            "Epoch 13/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.5252 - accuracy: 0.8494 - val_loss: 0.5189 - val_accuracy: 0.8650\n",
            "Epoch 14/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.5073 - accuracy: 0.8562 - val_loss: 0.4911 - val_accuracy: 0.8675\n",
            "Epoch 15/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4726 - accuracy: 0.8700 - val_loss: 0.4871 - val_accuracy: 0.8625\n",
            "Epoch 16/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4572 - accuracy: 0.8712 - val_loss: 0.4545 - val_accuracy: 0.8675\n",
            "Epoch 17/300\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4431 - accuracy: 0.8700 - val_loss: 0.4458 - val_accuracy: 0.8775\n",
            "Epoch 18/300\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4335 - accuracy: 0.8706 - val_loss: 0.4501 - val_accuracy: 0.8825\n",
            "Epoch 19/300\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4056 - accuracy: 0.8788 - val_loss: 0.4215 - val_accuracy: 0.8875\n",
            "Epoch 20/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4020 - accuracy: 0.8869 - val_loss: 0.4104 - val_accuracy: 0.8825\n",
            "Epoch 21/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3800 - accuracy: 0.8888 - val_loss: 0.3873 - val_accuracy: 0.9025\n",
            "Epoch 22/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3670 - accuracy: 0.8906 - val_loss: 0.3788 - val_accuracy: 0.8950\n",
            "Epoch 23/300\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3522 - accuracy: 0.9000 - val_loss: 0.3657 - val_accuracy: 0.9025\n",
            "Epoch 24/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3439 - accuracy: 0.9106 - val_loss: 0.3525 - val_accuracy: 0.9075\n",
            "Epoch 25/300\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.3273 - accuracy: 0.9056 - val_loss: 0.3520 - val_accuracy: 0.9000\n",
            "Epoch 26/300\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3201 - accuracy: 0.9087 - val_loss: 0.3401 - val_accuracy: 0.9125\n",
            "Epoch 27/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3040 - accuracy: 0.9187 - val_loss: 0.3426 - val_accuracy: 0.8850\n",
            "Epoch 28/300\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.2973 - accuracy: 0.9144 - val_loss: 0.3433 - val_accuracy: 0.9050\n",
            "Epoch 29/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.2804 - accuracy: 0.9156 - val_loss: 0.3323 - val_accuracy: 0.9100\n",
            "Epoch 30/300\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.2792 - accuracy: 0.9169 - val_loss: 0.3190 - val_accuracy: 0.9150\n",
            "Epoch 31/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.2737 - accuracy: 0.9306 - val_loss: 0.3154 - val_accuracy: 0.9150\n",
            "Epoch 32/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.2651 - accuracy: 0.9281 - val_loss: 0.3014 - val_accuracy: 0.9125\n",
            "Epoch 33/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.2476 - accuracy: 0.9319 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
            "Epoch 34/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.2518 - accuracy: 0.9325 - val_loss: 0.2995 - val_accuracy: 0.9150\n",
            "Epoch 35/300\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.2404 - accuracy: 0.9306 - val_loss: 0.2800 - val_accuracy: 0.9200\n",
            "Epoch 36/300\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2337 - accuracy: 0.9331 - val_loss: 0.2820 - val_accuracy: 0.9200\n",
            "Epoch 37/300\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2246 - accuracy: 0.9469 - val_loss: 0.2937 - val_accuracy: 0.9200\n",
            "Epoch 38/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.2180 - accuracy: 0.9475 - val_loss: 0.2705 - val_accuracy: 0.9200\n",
            "Epoch 39/300\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2199 - accuracy: 0.9400 - val_loss: 0.2732 - val_accuracy: 0.9150\n",
            "Epoch 40/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.2218 - accuracy: 0.9331 - val_loss: 0.2726 - val_accuracy: 0.9225\n",
            "Epoch 41/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.2026 - accuracy: 0.9494 - val_loss: 0.2590 - val_accuracy: 0.9275\n",
            "Epoch 42/300\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2035 - accuracy: 0.9531 - val_loss: 0.2560 - val_accuracy: 0.9275\n",
            "Epoch 43/300\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1974 - accuracy: 0.9456 - val_loss: 0.2466 - val_accuracy: 0.9200\n",
            "Epoch 44/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.1870 - accuracy: 0.9500 - val_loss: 0.2545 - val_accuracy: 0.9325\n",
            "Epoch 45/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.1864 - accuracy: 0.9488 - val_loss: 0.2420 - val_accuracy: 0.9325\n",
            "Epoch 46/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.1904 - accuracy: 0.9494 - val_loss: 0.2440 - val_accuracy: 0.9275\n",
            "Epoch 47/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.1816 - accuracy: 0.9469 - val_loss: 0.2339 - val_accuracy: 0.9200\n",
            "Epoch 48/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.1825 - accuracy: 0.9519 - val_loss: 0.2352 - val_accuracy: 0.9250\n",
            "Epoch 49/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.1703 - accuracy: 0.9556 - val_loss: 0.2321 - val_accuracy: 0.9225\n",
            "Epoch 50/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.1496 - accuracy: 0.9694 - val_loss: 0.2392 - val_accuracy: 0.9325\n",
            "Epoch 51/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.1760 - accuracy: 0.9550 - val_loss: 0.2250 - val_accuracy: 0.9350\n",
            "Epoch 52/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.1488 - accuracy: 0.9675 - val_loss: 0.2262 - val_accuracy: 0.9200\n",
            "Epoch 53/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.1514 - accuracy: 0.9631 - val_loss: 0.2385 - val_accuracy: 0.9175\n",
            "Epoch 54/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.1524 - accuracy: 0.9644 - val_loss: 0.2191 - val_accuracy: 0.9350\n",
            "Epoch 55/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.1477 - accuracy: 0.9644 - val_loss: 0.2164 - val_accuracy: 0.9275\n",
            "Epoch 56/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.1495 - accuracy: 0.9606 - val_loss: 0.2187 - val_accuracy: 0.9225\n",
            "Epoch 57/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.1434 - accuracy: 0.9644 - val_loss: 0.2173 - val_accuracy: 0.9400\n",
            "Epoch 58/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.1291 - accuracy: 0.9737 - val_loss: 0.2084 - val_accuracy: 0.9375\n",
            "Epoch 59/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.1344 - accuracy: 0.9638 - val_loss: 0.2210 - val_accuracy: 0.9300\n",
            "Epoch 60/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.1364 - accuracy: 0.9613 - val_loss: 0.2017 - val_accuracy: 0.9350\n",
            "Epoch 61/300\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.1340 - accuracy: 0.9688 - val_loss: 0.2076 - val_accuracy: 0.9375\n",
            "Epoch 62/300\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.1239 - accuracy: 0.9737 - val_loss: 0.2041 - val_accuracy: 0.9350\n",
            "Epoch 63/300\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.1208 - accuracy: 0.9694 - val_loss: 0.2067 - val_accuracy: 0.9350\n",
            "Epoch 64/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.1197 - accuracy: 0.9681 - val_loss: 0.2105 - val_accuracy: 0.9350\n",
            "Epoch 65/300\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.1099 - accuracy: 0.9737 - val_loss: 0.1897 - val_accuracy: 0.9375\n",
            "Epoch 66/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.1188 - accuracy: 0.9688 - val_loss: 0.1966 - val_accuracy: 0.9400\n",
            "Epoch 67/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.1998 - val_accuracy: 0.9375\n",
            "Epoch 68/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.1157 - accuracy: 0.9719 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 69/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.1083 - accuracy: 0.9762 - val_loss: 0.1880 - val_accuracy: 0.9375\n",
            "Epoch 70/300\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1008 - accuracy: 0.9806 - val_loss: 0.1864 - val_accuracy: 0.9400\n",
            "Epoch 71/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.1009 - accuracy: 0.9800 - val_loss: 0.1924 - val_accuracy: 0.9350\n",
            "Epoch 72/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.1077 - accuracy: 0.9744 - val_loss: 0.1911 - val_accuracy: 0.9425\n",
            "Epoch 73/300\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.0948 - accuracy: 0.9806 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 74/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.1012 - accuracy: 0.9756 - val_loss: 0.1888 - val_accuracy: 0.9350\n",
            "Epoch 75/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.1107 - accuracy: 0.9688 - val_loss: 0.1829 - val_accuracy: 0.9400\n",
            "Epoch 76/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0919 - accuracy: 0.9775 - val_loss: 0.1754 - val_accuracy: 0.9450\n",
            "Epoch 77/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0932 - accuracy: 0.9762 - val_loss: 0.1720 - val_accuracy: 0.9425\n",
            "Epoch 78/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0849 - accuracy: 0.9819 - val_loss: 0.1711 - val_accuracy: 0.9425\n",
            "Epoch 79/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0865 - accuracy: 0.9806 - val_loss: 0.1917 - val_accuracy: 0.9350\n",
            "Epoch 80/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0810 - accuracy: 0.9831 - val_loss: 0.1714 - val_accuracy: 0.9450\n",
            "Epoch 81/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0804 - accuracy: 0.9837 - val_loss: 0.1771 - val_accuracy: 0.9400\n",
            "Epoch 82/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0787 - accuracy: 0.9850 - val_loss: 0.1736 - val_accuracy: 0.9475\n",
            "Epoch 83/300\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.0812 - accuracy: 0.9825 - val_loss: 0.1809 - val_accuracy: 0.9400\n",
            "Epoch 84/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0839 - accuracy: 0.9781 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
            "Epoch 85/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0741 - accuracy: 0.9850 - val_loss: 0.1690 - val_accuracy: 0.9475\n",
            "Epoch 86/300\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0678 - accuracy: 0.9862 - val_loss: 0.1889 - val_accuracy: 0.9400\n",
            "Epoch 87/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0740 - accuracy: 0.9869 - val_loss: 0.1643 - val_accuracy: 0.9475\n",
            "Epoch 88/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0680 - accuracy: 0.9875 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
            "Epoch 89/300\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.0693 - accuracy: 0.9869 - val_loss: 0.1650 - val_accuracy: 0.9525\n",
            "Epoch 90/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0623 - accuracy: 0.9887 - val_loss: 0.1707 - val_accuracy: 0.9550\n",
            "Epoch 91/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0694 - accuracy: 0.9850 - val_loss: 0.1706 - val_accuracy: 0.9450\n",
            "Epoch 92/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0636 - accuracy: 0.9856 - val_loss: 0.1616 - val_accuracy: 0.9475\n",
            "Epoch 93/300\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.1614 - val_accuracy: 0.9475\n",
            "Epoch 94/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0592 - accuracy: 0.9881 - val_loss: 0.1634 - val_accuracy: 0.9375\n",
            "Epoch 95/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0626 - accuracy: 0.9856 - val_loss: 0.1549 - val_accuracy: 0.9525\n",
            "Epoch 96/300\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0603 - accuracy: 0.9862 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 97/300\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.1659 - val_accuracy: 0.9475\n",
            "Epoch 98/300\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.1727 - val_accuracy: 0.9350\n",
            "Epoch 99/300\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0534 - accuracy: 0.9937 - val_loss: 0.1598 - val_accuracy: 0.9425\n",
            "Epoch 100/300\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.0533 - accuracy: 0.9894 - val_loss: 0.1580 - val_accuracy: 0.9575\n",
            "Epoch 101/300\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.0520 - accuracy: 0.9894 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
            "Epoch 102/300\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.1611 - val_accuracy: 0.9550\n",
            "Epoch 103/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0609 - accuracy: 0.9850 - val_loss: 0.1606 - val_accuracy: 0.9475\n",
            "Epoch 104/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0501 - accuracy: 0.9894 - val_loss: 0.1554 - val_accuracy: 0.9475\n",
            "Epoch 105/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0533 - accuracy: 0.9875 - val_loss: 0.1528 - val_accuracy: 0.9475\n",
            "Epoch 106/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0488 - accuracy: 0.9925 - val_loss: 0.1559 - val_accuracy: 0.9500\n",
            "Epoch 107/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0509 - accuracy: 0.9875 - val_loss: 0.1536 - val_accuracy: 0.9500\n",
            "Epoch 108/300\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 0.1507 - val_accuracy: 0.9475\n",
            "Epoch 109/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1534 - val_accuracy: 0.9525\n",
            "Epoch 110/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0434 - accuracy: 0.9937 - val_loss: 0.1459 - val_accuracy: 0.9550\n",
            "Epoch 111/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0451 - accuracy: 0.9925 - val_loss: 0.1483 - val_accuracy: 0.9575\n",
            "Epoch 112/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0441 - accuracy: 0.9919 - val_loss: 0.1563 - val_accuracy: 0.9400\n",
            "Epoch 113/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0465 - accuracy: 0.9931 - val_loss: 0.1489 - val_accuracy: 0.9450\n",
            "Epoch 114/300\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.0365 - accuracy: 0.9969 - val_loss: 0.1527 - val_accuracy: 0.9500\n",
            "Epoch 115/300\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0352 - accuracy: 0.9937 - val_loss: 0.1529 - val_accuracy: 0.9475\n",
            "Epoch 116/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0365 - accuracy: 0.9962 - val_loss: 0.1528 - val_accuracy: 0.9400\n",
            "Epoch 117/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0389 - accuracy: 0.9962 - val_loss: 0.1455 - val_accuracy: 0.9525\n",
            "Epoch 118/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.1456 - val_accuracy: 0.9550\n",
            "Epoch 119/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0436 - accuracy: 0.9906 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 120/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 0.1586 - val_accuracy: 0.9450\n",
            "Epoch 121/300\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.0333 - accuracy: 0.9981 - val_loss: 0.1508 - val_accuracy: 0.9525\n",
            "Epoch 122/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0350 - accuracy: 0.9937 - val_loss: 0.1531 - val_accuracy: 0.9500\n",
            "Epoch 123/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0287 - accuracy: 0.9969 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 124/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0315 - accuracy: 0.9962 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
            "Epoch 125/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0310 - accuracy: 0.9956 - val_loss: 0.1503 - val_accuracy: 0.9475\n",
            "Epoch 126/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0292 - accuracy: 0.9962 - val_loss: 0.1646 - val_accuracy: 0.9425\n",
            "Epoch 127/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0374 - accuracy: 0.9925 - val_loss: 0.1474 - val_accuracy: 0.9525\n",
            "Epoch 128/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0279 - accuracy: 0.9975 - val_loss: 0.1444 - val_accuracy: 0.9525\n",
            "Epoch 129/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.1764 - val_accuracy: 0.9400\n",
            "Epoch 130/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0314 - accuracy: 0.9962 - val_loss: 0.1419 - val_accuracy: 0.9475\n",
            "Epoch 131/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.1421 - val_accuracy: 0.9525\n",
            "Epoch 132/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0297 - accuracy: 0.9956 - val_loss: 0.1473 - val_accuracy: 0.9475\n",
            "Epoch 133/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.1409 - val_accuracy: 0.9550\n",
            "Epoch 134/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0243 - accuracy: 0.9981 - val_loss: 0.1467 - val_accuracy: 0.9450\n",
            "Epoch 135/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0247 - accuracy: 0.9962 - val_loss: 0.1441 - val_accuracy: 0.9525\n",
            "Epoch 136/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0224 - accuracy: 0.9981 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 137/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0245 - accuracy: 0.9975 - val_loss: 0.1409 - val_accuracy: 0.9475\n",
            "Epoch 138/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0235 - accuracy: 0.9975 - val_loss: 0.1476 - val_accuracy: 0.9550\n",
            "Epoch 139/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.0245 - accuracy: 0.9962 - val_loss: 0.1457 - val_accuracy: 0.9550\n",
            "Epoch 140/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
            "Epoch 141/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0243 - accuracy: 0.9975 - val_loss: 0.1379 - val_accuracy: 0.9525\n",
            "Epoch 142/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0224 - accuracy: 0.9981 - val_loss: 0.1536 - val_accuracy: 0.9400\n",
            "Epoch 143/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0218 - accuracy: 0.9975 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 144/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0217 - accuracy: 0.9962 - val_loss: 0.1503 - val_accuracy: 0.9500\n",
            "Epoch 145/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
            "Epoch 146/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.0216 - accuracy: 0.9969 - val_loss: 0.1506 - val_accuracy: 0.9525\n",
            "Epoch 147/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.1516 - val_accuracy: 0.9475\n",
            "Epoch 148/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0213 - accuracy: 0.9975 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
            "Epoch 149/300\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.1532 - val_accuracy: 0.9475\n",
            "Epoch 150/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0247 - accuracy: 0.9956 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
            "Epoch 151/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0244 - accuracy: 0.9962 - val_loss: 0.1517 - val_accuracy: 0.9450\n",
            "Epoch 152/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0180 - accuracy: 0.9987 - val_loss: 0.1400 - val_accuracy: 0.9550\n",
            "Epoch 153/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0184 - accuracy: 0.9981 - val_loss: 0.1469 - val_accuracy: 0.9525\n",
            "Epoch 154/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.1403 - val_accuracy: 0.9525\n",
            "Epoch 155/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0159 - accuracy: 0.9994 - val_loss: 0.1498 - val_accuracy: 0.9550\n",
            "Epoch 156/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0186 - accuracy: 0.9994 - val_loss: 0.1416 - val_accuracy: 0.9525\n",
            "Epoch 157/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
            "Epoch 158/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1459 - val_accuracy: 0.9450\n",
            "Epoch 159/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
            "Epoch 160/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.1498 - val_accuracy: 0.9525\n",
            "Epoch 161/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0142 - accuracy: 0.9994 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
            "Epoch 162/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0164 - accuracy: 0.9981 - val_loss: 0.1475 - val_accuracy: 0.9450\n",
            "Epoch 163/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 0.1512 - val_accuracy: 0.9525\n",
            "Epoch 164/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9575\n",
            "Epoch 165/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0133 - accuracy: 0.9987 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
            "Epoch 166/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0154 - accuracy: 0.9981 - val_loss: 0.1462 - val_accuracy: 0.9575\n",
            "Epoch 167/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 0.1435 - val_accuracy: 0.9525\n",
            "Epoch 168/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9575\n",
            "Epoch 169/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: 0.1364 - val_accuracy: 0.9500\n",
            "Epoch 170/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
            "Epoch 171/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.1437 - val_accuracy: 0.9550\n",
            "Epoch 172/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.1606 - val_accuracy: 0.9525\n",
            "Epoch 173/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.1472 - val_accuracy: 0.9450\n",
            "Epoch 174/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 0.1484 - val_accuracy: 0.9475\n",
            "Epoch 175/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0131 - accuracy: 0.9994 - val_loss: 0.1469 - val_accuracy: 0.9525\n",
            "Epoch 176/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.1416 - val_accuracy: 0.9525\n",
            "Epoch 177/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0161 - accuracy: 0.9975 - val_loss: 0.1271 - val_accuracy: 0.9525\n",
            "Epoch 178/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.1449 - val_accuracy: 0.9450\n",
            "Epoch 179/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.1332 - val_accuracy: 0.9475\n",
            "Epoch 180/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0112 - accuracy: 0.9987 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
            "Epoch 181/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9525\n",
            "Epoch 182/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.1450 - val_accuracy: 0.9525\n",
            "Epoch 183/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.1313 - val_accuracy: 0.9525\n",
            "Epoch 184/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0104 - accuracy: 0.9994 - val_loss: 0.1348 - val_accuracy: 0.9550\n",
            "Epoch 185/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.1500 - val_accuracy: 0.9450\n",
            "Epoch 186/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9450\n",
            "Epoch 187/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.1586 - val_accuracy: 0.9525\n",
            "Epoch 188/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9525\n",
            "Epoch 189/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.1554 - val_accuracy: 0.9525\n",
            "Epoch 190/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.1378 - val_accuracy: 0.9525\n",
            "Epoch 191/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.1419 - val_accuracy: 0.9475\n",
            "Epoch 192/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9525\n",
            "Epoch 193/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.1391 - val_accuracy: 0.9550\n",
            "Epoch 194/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.1462 - val_accuracy: 0.9450\n",
            "Epoch 195/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.1403 - val_accuracy: 0.9475\n",
            "Epoch 196/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.1401 - val_accuracy: 0.9525\n",
            "Epoch 197/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 198/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
            "Epoch 199/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.1744 - val_accuracy: 0.9425\n",
            "Epoch 200/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.1438 - val_accuracy: 0.9525\n",
            "Epoch 201/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.1407 - val_accuracy: 0.9525\n",
            "Epoch 202/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.1374 - val_accuracy: 0.9550\n",
            "Epoch 203/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.1422 - val_accuracy: 0.9475\n",
            "Epoch 204/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.1398 - val_accuracy: 0.9525\n",
            "Epoch 205/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.1367 - val_accuracy: 0.9575\n",
            "Epoch 206/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.1537 - val_accuracy: 0.9450\n",
            "Epoch 207/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.1583 - val_accuracy: 0.9525\n",
            "Epoch 208/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.1355 - val_accuracy: 0.9525\n",
            "Epoch 209/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9425\n",
            "Epoch 210/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.1387 - val_accuracy: 0.9525\n",
            "Epoch 211/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9525\n",
            "Epoch 212/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9575\n",
            "Epoch 213/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.1396 - val_accuracy: 0.9525\n",
            "Epoch 214/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.1300 - val_accuracy: 0.9550\n",
            "Epoch 215/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.1310 - val_accuracy: 0.9575\n",
            "Epoch 216/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.1498 - val_accuracy: 0.9525\n",
            "Epoch 217/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9550\n",
            "Epoch 218/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 219/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9525\n",
            "Epoch 220/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9450\n",
            "Epoch 221/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.1676 - val_accuracy: 0.9400\n",
            "Epoch 222/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 223/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9550\n",
            "Epoch 224/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.1531 - val_accuracy: 0.9475\n",
            "Epoch 225/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9475\n",
            "Epoch 226/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9500\n",
            "Epoch 227/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9550\n",
            "Epoch 228/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9525\n",
            "Epoch 229/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.1577 - val_accuracy: 0.9500\n",
            "Epoch 230/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9450\n",
            "Epoch 231/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 232/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.1467 - val_accuracy: 0.9475\n",
            "Epoch 233/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.1463 - val_accuracy: 0.9475\n",
            "Epoch 234/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.1672 - val_accuracy: 0.9525\n",
            "Epoch 235/300\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
            "Epoch 236/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.1446 - val_accuracy: 0.9475\n",
            "Epoch 237/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
            "Epoch 238/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.1405 - val_accuracy: 0.9475\n",
            "Epoch 239/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1345 - val_accuracy: 0.9500\n",
            "Epoch 240/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9550\n",
            "Epoch 241/300\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
            "Epoch 242/300\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.1740 - val_accuracy: 0.9525\n",
            "Epoch 243/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9425\n",
            "Epoch 244/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
            "Epoch 245/300\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 246/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9550\n",
            "Epoch 247/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9450\n",
            "Epoch 248/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9525\n",
            "Epoch 249/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9450\n",
            "Epoch 250/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9425\n",
            "Epoch 251/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9525\n",
            "Epoch 252/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.1444 - val_accuracy: 0.9450\n",
            "Epoch 253/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 254/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.1462 - val_accuracy: 0.9575\n",
            "Epoch 255/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1516 - val_accuracy: 0.9525\n",
            "Epoch 256/300\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.1577 - val_accuracy: 0.9550\n",
            "Epoch 257/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.1602 - val_accuracy: 0.9550\n",
            "Epoch 258/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.1580 - val_accuracy: 0.9475\n",
            "Epoch 259/300\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1360 - val_accuracy: 0.9525\n",
            "Epoch 260/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9550\n",
            "Epoch 261/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.1365 - val_accuracy: 0.9500\n",
            "Epoch 262/300\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9550\n",
            "Epoch 263/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9575\n",
            "Epoch 264/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9525\n",
            "Epoch 265/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1537 - val_accuracy: 0.9575\n",
            "Epoch 266/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 267/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.1733 - val_accuracy: 0.9475\n",
            "Epoch 268/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1438 - val_accuracy: 0.9500\n",
            "Epoch 269/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 270/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1474 - val_accuracy: 0.9550\n",
            "Epoch 271/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1504 - val_accuracy: 0.9500\n",
            "Epoch 272/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
            "Epoch 273/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9550\n",
            "Epoch 274/300\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9500\n",
            "Epoch 275/300\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9475\n",
            "Epoch 276/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1685 - val_accuracy: 0.9450\n",
            "Epoch 277/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 278/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9525\n",
            "Epoch 279/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.1701 - val_accuracy: 0.9450\n",
            "Epoch 280/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.1434 - val_accuracy: 0.9550\n",
            "Epoch 281/300\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.1433 - val_accuracy: 0.9600\n",
            "Epoch 282/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9550\n",
            "Epoch 283/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9550\n",
            "Epoch 284/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1510 - val_accuracy: 0.9525\n",
            "Epoch 285/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
            "Epoch 286/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9600\n",
            "Epoch 287/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9475\n",
            "Epoch 288/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1488 - val_accuracy: 0.9500\n",
            "Epoch 289/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9550\n",
            "Epoch 290/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9550\n",
            "Epoch 291/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
            "Epoch 292/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9550\n",
            "Epoch 293/300\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1566 - val_accuracy: 0.9425\n",
            "Epoch 294/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1693 - val_accuracy: 0.9575\n",
            "Epoch 295/300\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.2923 - val_accuracy: 0.9325\n",
            "Epoch 296/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9450\n",
            "Epoch 297/300\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9450\n",
            "Epoch 298/300\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9475\n",
            "Epoch 299/300\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1787 - val_accuracy: 0.9475\n",
            "Epoch 300/300\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
            "CPU times: user 1h 6min 5s, sys: 3min 14s, total: 1h 9min 19s\n",
            "Wall time: 1h 13min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "6ddcc189-4f37-47fc-f986-71cb5325a797",
        "id": "RvQ_z4wuZCC9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc489003-378e-428e-8196-0ba41a5b3854",
        "id": "RnV1_gtnZCC9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model2200.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights2200.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model2200.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff13ea1e-2888-43d2-a01e-890da877e7ed",
        "id": "Ub-mXixzZCC9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBDl8BeWZCC9"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model2200.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f46e73d-a096-47ab-c5c8-069031506cf0",
        "id": "07Pp93YbZCC9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         4\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         4\n",
            "           1       0.83      1.00      0.91         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.88      0.88      0.84        16\n",
            "weighted avg       0.91      0.88      0.86        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "zooLZG55ZCC9",
        "outputId": "265d0cfa-95dc-4224-a4c8-a8434d0e6c4e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(11, 5))\n",
        "plt.subplot(121)\n",
        "labels = np.unique(y_pred_train_argmax)\n",
        "# cm = confusion_matrix(y_train_argmax, y_pred_train_argmax, labels=labels)\n",
        "# sns.heatmap(cm, annot=True, square=True, cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "# plt.title(f\"Training Accuracy: {accuracy_score(y_train_argmax, y_pred_train_argmax):.3f}\", fontsize=14)\n",
        "# plt.xlabel('Prediction', fontsize=14)\n",
        "# plt.ylabel('Actual', fontsize=14)\n",
        "# plt.yticks(rotation=0, verticalalignment='center')\n",
        "# plt.subplot(122)\n",
        "cm = confusion_matrix(y_test_argmax, y_pred_test_argmax, labels=labels)\n",
        "sns.heatmap(cm, annot=True, cmap='Greens', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "plt.title(f\"Validation Accuracy: {accuracy_score(y_test_argmax, y_pred_test_argmax):.3f}\", fontsize=14)\n",
        "plt.xlabel('Prediction', fontsize=14)\n",
        "plt.ylabel('Actual', fontsize=14)\n",
        "plt.yticks(rotation=0, verticalalignment='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71DkHKgZxs_1"
      },
      "source": [
        "#2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35080d36-f834-4100-917d-b02938d4156e",
        "id": "-qf2Hdepxs_6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  1e-06\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 400\n",
        "batch_size = 32\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 0.000001\n",
        "# if epochs > 180:\n",
        "#     lr *= 0.5e-3\n",
        "# elif epochs > 160:\n",
        "#     lr *= 1e-3\n",
        "# elif epochs > 120:\n",
        "#     lr *= 1e-2\n",
        "# elif epochs > 80:\n",
        "#     lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963872b1-081c-4fea-9d66-6729f712c63f",
        "id": "8tTIP_HLxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcm8FTIcxs_7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21efa87-3cf2-45eb-e038-1a5f4d1c762a",
        "id": "neWVLKnOxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5f5c99-8183-452c-885e-f3bd65ce4cbe",
        "id": "ldinqBoQxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "50/50 [==============================] - 17s 277ms/step - loss: 1.3544 - accuracy: 0.3094 - val_loss: 1.3681 - val_accuracy: 0.3255\n",
            "Epoch 2/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 1.3184 - accuracy: 0.3781 - val_loss: 1.3515 - val_accuracy: 0.3750\n",
            "Epoch 3/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 1.2924 - accuracy: 0.4069 - val_loss: 1.3350 - val_accuracy: 0.4115\n",
            "Epoch 4/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 1.2716 - accuracy: 0.4194 - val_loss: 1.3138 - val_accuracy: 0.4323\n",
            "Epoch 5/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.2547 - accuracy: 0.4444 - val_loss: 1.2872 - val_accuracy: 0.4974\n",
            "Epoch 6/400\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 1.2395 - accuracy: 0.4569 - val_loss: 1.2652 - val_accuracy: 0.4714\n",
            "Epoch 7/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.2276 - accuracy: 0.4600 - val_loss: 1.2389 - val_accuracy: 0.4740\n",
            "Epoch 8/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.2147 - accuracy: 0.4681 - val_loss: 1.2085 - val_accuracy: 0.4870\n",
            "Epoch 9/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 1.1985 - accuracy: 0.4775 - val_loss: 1.1897 - val_accuracy: 0.5026\n",
            "Epoch 10/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.1858 - accuracy: 0.4931 - val_loss: 1.1712 - val_accuracy: 0.5104\n",
            "Epoch 11/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.1768 - accuracy: 0.5000 - val_loss: 1.1587 - val_accuracy: 0.5052\n",
            "Epoch 12/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.1659 - accuracy: 0.5138 - val_loss: 1.1472 - val_accuracy: 0.5182\n",
            "Epoch 13/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.1555 - accuracy: 0.5156 - val_loss: 1.1303 - val_accuracy: 0.5339\n",
            "Epoch 14/400\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 1.1428 - accuracy: 0.5238 - val_loss: 1.1158 - val_accuracy: 0.5443\n",
            "Epoch 15/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.1357 - accuracy: 0.5225 - val_loss: 1.1081 - val_accuracy: 0.5521\n",
            "Epoch 16/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 1.1222 - accuracy: 0.5412 - val_loss: 1.0953 - val_accuracy: 0.5677\n",
            "Epoch 17/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 1.1143 - accuracy: 0.5394 - val_loss: 1.0886 - val_accuracy: 0.5625\n",
            "Epoch 18/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.1040 - accuracy: 0.5481 - val_loss: 1.0785 - val_accuracy: 0.5625\n",
            "Epoch 19/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 1.0945 - accuracy: 0.5612 - val_loss: 1.0590 - val_accuracy: 0.5911\n",
            "Epoch 20/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 1.0864 - accuracy: 0.5638 - val_loss: 1.0605 - val_accuracy: 0.5833\n",
            "Epoch 21/400\n",
            "50/50 [==============================] - 13s 265ms/step - loss: 1.0759 - accuracy: 0.5606 - val_loss: 1.0479 - val_accuracy: 0.5964\n",
            "Epoch 22/400\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.0703 - accuracy: 0.5688 - val_loss: 1.0445 - val_accuracy: 0.5964\n",
            "Epoch 23/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.0588 - accuracy: 0.5744 - val_loss: 1.0345 - val_accuracy: 0.5990\n",
            "Epoch 24/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 1.0534 - accuracy: 0.5813 - val_loss: 1.0169 - val_accuracy: 0.6172\n",
            "Epoch 25/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.0457 - accuracy: 0.5825 - val_loss: 1.0185 - val_accuracy: 0.6094\n",
            "Epoch 26/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 1.0379 - accuracy: 0.5894 - val_loss: 1.0039 - val_accuracy: 0.6146\n",
            "Epoch 27/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.0285 - accuracy: 0.5975 - val_loss: 0.9986 - val_accuracy: 0.6198\n",
            "Epoch 28/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 1.0210 - accuracy: 0.6019 - val_loss: 0.9878 - val_accuracy: 0.6354\n",
            "Epoch 29/400\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 1.0147 - accuracy: 0.6062 - val_loss: 0.9911 - val_accuracy: 0.6146\n",
            "Epoch 30/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 1.0071 - accuracy: 0.6194 - val_loss: 0.9744 - val_accuracy: 0.6354\n",
            "Epoch 31/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9977 - accuracy: 0.6244 - val_loss: 0.9732 - val_accuracy: 0.6302\n",
            "Epoch 32/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9949 - accuracy: 0.6200 - val_loss: 0.9574 - val_accuracy: 0.6484\n",
            "Epoch 33/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.9862 - accuracy: 0.6225 - val_loss: 0.9507 - val_accuracy: 0.6458\n",
            "Epoch 34/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.9806 - accuracy: 0.6394 - val_loss: 0.9463 - val_accuracy: 0.6641\n",
            "Epoch 35/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9751 - accuracy: 0.6394 - val_loss: 0.9442 - val_accuracy: 0.6536\n",
            "Epoch 36/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.9673 - accuracy: 0.6419 - val_loss: 0.9418 - val_accuracy: 0.6641\n",
            "Epoch 37/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.9592 - accuracy: 0.6556 - val_loss: 0.9285 - val_accuracy: 0.6693\n",
            "Epoch 38/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.9553 - accuracy: 0.6513 - val_loss: 0.9252 - val_accuracy: 0.6745\n",
            "Epoch 39/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9449 - accuracy: 0.6719 - val_loss: 0.9182 - val_accuracy: 0.6849\n",
            "Epoch 40/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.9421 - accuracy: 0.6669 - val_loss: 0.9109 - val_accuracy: 0.6823\n",
            "Epoch 41/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9322 - accuracy: 0.6681 - val_loss: 0.9041 - val_accuracy: 0.6849\n",
            "Epoch 42/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.9283 - accuracy: 0.6687 - val_loss: 0.8942 - val_accuracy: 0.6953\n",
            "Epoch 43/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.9218 - accuracy: 0.6756 - val_loss: 0.8949 - val_accuracy: 0.7005\n",
            "Epoch 44/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.9169 - accuracy: 0.6862 - val_loss: 0.8850 - val_accuracy: 0.7031\n",
            "Epoch 45/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.9086 - accuracy: 0.6800 - val_loss: 0.8769 - val_accuracy: 0.7057\n",
            "Epoch 46/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9069 - accuracy: 0.6787 - val_loss: 0.8743 - val_accuracy: 0.7005\n",
            "Epoch 47/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.9008 - accuracy: 0.7006 - val_loss: 0.8701 - val_accuracy: 0.7083\n",
            "Epoch 48/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.8947 - accuracy: 0.7019 - val_loss: 0.8665 - val_accuracy: 0.7109\n",
            "Epoch 49/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.8924 - accuracy: 0.6975 - val_loss: 0.8573 - val_accuracy: 0.7109\n",
            "Epoch 50/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.8809 - accuracy: 0.7069 - val_loss: 0.8589 - val_accuracy: 0.7188\n",
            "Epoch 51/400\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.8750 - accuracy: 0.7075 - val_loss: 0.8531 - val_accuracy: 0.7188\n",
            "Epoch 52/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.8670 - accuracy: 0.7175 - val_loss: 0.8385 - val_accuracy: 0.7318\n",
            "Epoch 53/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.8670 - accuracy: 0.7175 - val_loss: 0.8383 - val_accuracy: 0.7318\n",
            "Epoch 54/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8562 - accuracy: 0.7212 - val_loss: 0.8332 - val_accuracy: 0.7370\n",
            "Epoch 55/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8568 - accuracy: 0.7231 - val_loss: 0.8295 - val_accuracy: 0.7292\n",
            "Epoch 56/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8500 - accuracy: 0.7194 - val_loss: 0.8208 - val_accuracy: 0.7422\n",
            "Epoch 57/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.8474 - accuracy: 0.7256 - val_loss: 0.8224 - val_accuracy: 0.7500\n",
            "Epoch 58/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8400 - accuracy: 0.7269 - val_loss: 0.8210 - val_accuracy: 0.7396\n",
            "Epoch 59/400\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.8350 - accuracy: 0.7319 - val_loss: 0.8102 - val_accuracy: 0.7448\n",
            "Epoch 60/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8329 - accuracy: 0.7481 - val_loss: 0.8100 - val_accuracy: 0.7578\n",
            "Epoch 61/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8222 - accuracy: 0.7487 - val_loss: 0.8059 - val_accuracy: 0.7500\n",
            "Epoch 62/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8191 - accuracy: 0.7456 - val_loss: 0.8003 - val_accuracy: 0.7604\n",
            "Epoch 63/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8179 - accuracy: 0.7481 - val_loss: 0.7993 - val_accuracy: 0.7604\n",
            "Epoch 64/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.8125 - accuracy: 0.7494 - val_loss: 0.7848 - val_accuracy: 0.7630\n",
            "Epoch 65/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.8067 - accuracy: 0.7450 - val_loss: 0.7821 - val_accuracy: 0.7734\n",
            "Epoch 66/400\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.8044 - accuracy: 0.7494 - val_loss: 0.7774 - val_accuracy: 0.7734\n",
            "Epoch 67/400\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.7988 - accuracy: 0.7481 - val_loss: 0.7805 - val_accuracy: 0.7708\n",
            "Epoch 68/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7925 - accuracy: 0.7638 - val_loss: 0.7697 - val_accuracy: 0.7812\n",
            "Epoch 69/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.7940 - accuracy: 0.7506 - val_loss: 0.7763 - val_accuracy: 0.7734\n",
            "Epoch 70/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7854 - accuracy: 0.7594 - val_loss: 0.7723 - val_accuracy: 0.7760\n",
            "Epoch 71/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.7828 - accuracy: 0.7631 - val_loss: 0.7563 - val_accuracy: 0.7943\n",
            "Epoch 72/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7739 - accuracy: 0.7631 - val_loss: 0.7543 - val_accuracy: 0.7812\n",
            "Epoch 73/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.7740 - accuracy: 0.7594 - val_loss: 0.7491 - val_accuracy: 0.7917\n",
            "Epoch 74/400\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.7655 - accuracy: 0.7756 - val_loss: 0.7463 - val_accuracy: 0.7917\n",
            "Epoch 75/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.7566 - accuracy: 0.7694 - val_loss: 0.7442 - val_accuracy: 0.7917\n",
            "Epoch 76/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7552 - accuracy: 0.7725 - val_loss: 0.7454 - val_accuracy: 0.7891\n",
            "Epoch 77/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.7558 - accuracy: 0.7744 - val_loss: 0.7338 - val_accuracy: 0.7969\n",
            "Epoch 78/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7496 - accuracy: 0.7763 - val_loss: 0.7365 - val_accuracy: 0.7943\n",
            "Epoch 79/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.7515 - accuracy: 0.7794 - val_loss: 0.7341 - val_accuracy: 0.7969\n",
            "Epoch 80/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7425 - accuracy: 0.7950 - val_loss: 0.7258 - val_accuracy: 0.7943\n",
            "Epoch 81/400\n",
            "50/50 [==============================] - 13s 266ms/step - loss: 0.7353 - accuracy: 0.7856 - val_loss: 0.7282 - val_accuracy: 0.7995\n",
            "Epoch 82/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.7388 - accuracy: 0.7856 - val_loss: 0.7199 - val_accuracy: 0.7969\n",
            "Epoch 83/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7322 - accuracy: 0.7812 - val_loss: 0.7111 - val_accuracy: 0.7995\n",
            "Epoch 84/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.7271 - accuracy: 0.7769 - val_loss: 0.7112 - val_accuracy: 0.7917\n",
            "Epoch 85/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.7252 - accuracy: 0.7937 - val_loss: 0.7201 - val_accuracy: 0.7865\n",
            "Epoch 86/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7192 - accuracy: 0.7931 - val_loss: 0.6988 - val_accuracy: 0.8047\n",
            "Epoch 87/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7194 - accuracy: 0.7844 - val_loss: 0.7092 - val_accuracy: 0.7943\n",
            "Epoch 88/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.7098 - accuracy: 0.7894 - val_loss: 0.6954 - val_accuracy: 0.8021\n",
            "Epoch 89/400\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.7106 - accuracy: 0.7994 - val_loss: 0.6977 - val_accuracy: 0.7995\n",
            "Epoch 90/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.7049 - accuracy: 0.8119 - val_loss: 0.6917 - val_accuracy: 0.7995\n",
            "Epoch 91/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.7094 - accuracy: 0.7825 - val_loss: 0.6799 - val_accuracy: 0.8047\n",
            "Epoch 92/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6968 - accuracy: 0.7981 - val_loss: 0.6909 - val_accuracy: 0.7969\n",
            "Epoch 93/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6982 - accuracy: 0.7987 - val_loss: 0.6938 - val_accuracy: 0.7943\n",
            "Epoch 94/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6875 - accuracy: 0.8119 - val_loss: 0.6782 - val_accuracy: 0.8047\n",
            "Epoch 95/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.6863 - accuracy: 0.8031 - val_loss: 0.6838 - val_accuracy: 0.7969\n",
            "Epoch 96/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.6891 - accuracy: 0.8012 - val_loss: 0.6712 - val_accuracy: 0.8047\n",
            "Epoch 97/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6812 - accuracy: 0.7994 - val_loss: 0.6713 - val_accuracy: 0.8047\n",
            "Epoch 98/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6787 - accuracy: 0.8125 - val_loss: 0.6802 - val_accuracy: 0.8047\n",
            "Epoch 99/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6771 - accuracy: 0.8062 - val_loss: 0.6660 - val_accuracy: 0.8177\n",
            "Epoch 100/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6754 - accuracy: 0.8106 - val_loss: 0.6611 - val_accuracy: 0.8125\n",
            "Epoch 101/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6726 - accuracy: 0.8100 - val_loss: 0.6619 - val_accuracy: 0.8151\n",
            "Epoch 102/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6696 - accuracy: 0.8056 - val_loss: 0.6572 - val_accuracy: 0.8047\n",
            "Epoch 103/400\n",
            "50/50 [==============================] - 13s 269ms/step - loss: 0.6586 - accuracy: 0.8119 - val_loss: 0.6489 - val_accuracy: 0.8203\n",
            "Epoch 104/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6610 - accuracy: 0.8150 - val_loss: 0.6605 - val_accuracy: 0.8177\n",
            "Epoch 105/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6550 - accuracy: 0.8244 - val_loss: 0.6545 - val_accuracy: 0.8125\n",
            "Epoch 106/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6537 - accuracy: 0.8213 - val_loss: 0.6451 - val_accuracy: 0.8203\n",
            "Epoch 107/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6488 - accuracy: 0.8175 - val_loss: 0.6418 - val_accuracy: 0.8177\n",
            "Epoch 108/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6462 - accuracy: 0.8144 - val_loss: 0.6454 - val_accuracy: 0.8151\n",
            "Epoch 109/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6475 - accuracy: 0.8150 - val_loss: 0.6359 - val_accuracy: 0.8229\n",
            "Epoch 110/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6393 - accuracy: 0.8150 - val_loss: 0.6323 - val_accuracy: 0.8281\n",
            "Epoch 111/400\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.6427 - accuracy: 0.8300 - val_loss: 0.6399 - val_accuracy: 0.8229\n",
            "Epoch 112/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6417 - accuracy: 0.8131 - val_loss: 0.6309 - val_accuracy: 0.8255\n",
            "Epoch 113/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.6282 - accuracy: 0.8294 - val_loss: 0.6238 - val_accuracy: 0.8359\n",
            "Epoch 114/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6288 - accuracy: 0.8250 - val_loss: 0.6360 - val_accuracy: 0.8203\n",
            "Epoch 115/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6268 - accuracy: 0.8306 - val_loss: 0.6140 - val_accuracy: 0.8229\n",
            "Epoch 116/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6289 - accuracy: 0.8175 - val_loss: 0.6246 - val_accuracy: 0.8229\n",
            "Epoch 117/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6229 - accuracy: 0.8369 - val_loss: 0.6222 - val_accuracy: 0.8203\n",
            "Epoch 118/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.6180 - accuracy: 0.8325 - val_loss: 0.6237 - val_accuracy: 0.8229\n",
            "Epoch 119/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.6131 - accuracy: 0.8350 - val_loss: 0.6210 - val_accuracy: 0.8203\n",
            "Epoch 120/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6088 - accuracy: 0.8319 - val_loss: 0.6163 - val_accuracy: 0.8203\n",
            "Epoch 121/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.6083 - accuracy: 0.8300 - val_loss: 0.6021 - val_accuracy: 0.8281\n",
            "Epoch 122/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6138 - accuracy: 0.8269 - val_loss: 0.6035 - val_accuracy: 0.8281\n",
            "Epoch 123/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6051 - accuracy: 0.8369 - val_loss: 0.6056 - val_accuracy: 0.8203\n",
            "Epoch 124/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.6103 - accuracy: 0.8313 - val_loss: 0.6069 - val_accuracy: 0.8229\n",
            "Epoch 125/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.6031 - accuracy: 0.8319 - val_loss: 0.6021 - val_accuracy: 0.8255\n",
            "Epoch 126/400\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.5946 - accuracy: 0.8431 - val_loss: 0.5952 - val_accuracy: 0.8281\n",
            "Epoch 127/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.6029 - accuracy: 0.8319 - val_loss: 0.6015 - val_accuracy: 0.8255\n",
            "Epoch 128/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.5886 - accuracy: 0.8456 - val_loss: 0.6022 - val_accuracy: 0.8255\n",
            "Epoch 129/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5920 - accuracy: 0.8306 - val_loss: 0.5981 - val_accuracy: 0.8281\n",
            "Epoch 130/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5862 - accuracy: 0.8394 - val_loss: 0.5811 - val_accuracy: 0.8333\n",
            "Epoch 131/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5878 - accuracy: 0.8338 - val_loss: 0.5925 - val_accuracy: 0.8281\n",
            "Epoch 132/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5856 - accuracy: 0.8419 - val_loss: 0.5857 - val_accuracy: 0.8307\n",
            "Epoch 133/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.5824 - accuracy: 0.8388 - val_loss: 0.5853 - val_accuracy: 0.8307\n",
            "Epoch 134/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5728 - accuracy: 0.8469 - val_loss: 0.5874 - val_accuracy: 0.8229\n",
            "Epoch 135/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5701 - accuracy: 0.8413 - val_loss: 0.5780 - val_accuracy: 0.8385\n",
            "Epoch 136/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.5780 - accuracy: 0.8338 - val_loss: 0.5672 - val_accuracy: 0.8411\n",
            "Epoch 137/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5693 - accuracy: 0.8375 - val_loss: 0.5789 - val_accuracy: 0.8281\n",
            "Epoch 138/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5673 - accuracy: 0.8469 - val_loss: 0.5764 - val_accuracy: 0.8333\n",
            "Epoch 139/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5667 - accuracy: 0.8469 - val_loss: 0.5732 - val_accuracy: 0.8281\n",
            "Epoch 140/400\n",
            "50/50 [==============================] - 14s 271ms/step - loss: 0.5634 - accuracy: 0.8481 - val_loss: 0.5650 - val_accuracy: 0.8385\n",
            "Epoch 141/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.5586 - accuracy: 0.8456 - val_loss: 0.5688 - val_accuracy: 0.8333\n",
            "Epoch 142/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.5574 - accuracy: 0.8475 - val_loss: 0.5710 - val_accuracy: 0.8359\n",
            "Epoch 143/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5506 - accuracy: 0.8556 - val_loss: 0.5632 - val_accuracy: 0.8359\n",
            "Epoch 144/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5481 - accuracy: 0.8456 - val_loss: 0.5593 - val_accuracy: 0.8385\n",
            "Epoch 145/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.5490 - accuracy: 0.8562 - val_loss: 0.5605 - val_accuracy: 0.8438\n",
            "Epoch 146/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5502 - accuracy: 0.8506 - val_loss: 0.5577 - val_accuracy: 0.8359\n",
            "Epoch 147/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5478 - accuracy: 0.8556 - val_loss: 0.5640 - val_accuracy: 0.8333\n",
            "Epoch 148/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.5479 - accuracy: 0.8569 - val_loss: 0.5500 - val_accuracy: 0.8464\n",
            "Epoch 149/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5430 - accuracy: 0.8500 - val_loss: 0.5529 - val_accuracy: 0.8490\n",
            "Epoch 150/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5410 - accuracy: 0.8494 - val_loss: 0.5511 - val_accuracy: 0.8385\n",
            "Epoch 151/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5315 - accuracy: 0.8556 - val_loss: 0.5449 - val_accuracy: 0.8385\n",
            "Epoch 152/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5314 - accuracy: 0.8525 - val_loss: 0.5536 - val_accuracy: 0.8385\n",
            "Epoch 153/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5318 - accuracy: 0.8637 - val_loss: 0.5453 - val_accuracy: 0.8464\n",
            "Epoch 154/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.5356 - accuracy: 0.8494 - val_loss: 0.5437 - val_accuracy: 0.8438\n",
            "Epoch 155/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.5348 - accuracy: 0.8550 - val_loss: 0.5391 - val_accuracy: 0.8385\n",
            "Epoch 156/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5307 - accuracy: 0.8550 - val_loss: 0.5450 - val_accuracy: 0.8438\n",
            "Epoch 157/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.5255 - accuracy: 0.8575 - val_loss: 0.5346 - val_accuracy: 0.8464\n",
            "Epoch 158/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.5193 - accuracy: 0.8581 - val_loss: 0.5320 - val_accuracy: 0.8438\n",
            "Epoch 159/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.5222 - accuracy: 0.8531 - val_loss: 0.5362 - val_accuracy: 0.8516\n",
            "Epoch 160/400\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.5197 - accuracy: 0.8619 - val_loss: 0.5420 - val_accuracy: 0.8385\n",
            "Epoch 161/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5165 - accuracy: 0.8556 - val_loss: 0.5337 - val_accuracy: 0.8438\n",
            "Epoch 162/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.5083 - accuracy: 0.8694 - val_loss: 0.5218 - val_accuracy: 0.8542\n",
            "Epoch 163/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5093 - accuracy: 0.8631 - val_loss: 0.5177 - val_accuracy: 0.8516\n",
            "Epoch 164/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.5097 - accuracy: 0.8625 - val_loss: 0.5249 - val_accuracy: 0.8516\n",
            "Epoch 165/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.5074 - accuracy: 0.8662 - val_loss: 0.5248 - val_accuracy: 0.8516\n",
            "Epoch 166/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.5106 - accuracy: 0.8612 - val_loss: 0.5146 - val_accuracy: 0.8594\n",
            "Epoch 167/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5033 - accuracy: 0.8731 - val_loss: 0.5158 - val_accuracy: 0.8542\n",
            "Epoch 168/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.4984 - accuracy: 0.8744 - val_loss: 0.5113 - val_accuracy: 0.8542\n",
            "Epoch 169/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4969 - accuracy: 0.8700 - val_loss: 0.5183 - val_accuracy: 0.8516\n",
            "Epoch 170/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.5020 - accuracy: 0.8650 - val_loss: 0.5146 - val_accuracy: 0.8568\n",
            "Epoch 171/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4982 - accuracy: 0.8669 - val_loss: 0.5068 - val_accuracy: 0.8516\n",
            "Epoch 172/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4928 - accuracy: 0.8662 - val_loss: 0.5128 - val_accuracy: 0.8542\n",
            "Epoch 173/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.4883 - accuracy: 0.8744 - val_loss: 0.5043 - val_accuracy: 0.8542\n",
            "Epoch 174/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4969 - accuracy: 0.8675 - val_loss: 0.5038 - val_accuracy: 0.8490\n",
            "Epoch 175/400\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.4860 - accuracy: 0.8687 - val_loss: 0.5136 - val_accuracy: 0.8490\n",
            "Epoch 176/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4879 - accuracy: 0.8763 - val_loss: 0.5076 - val_accuracy: 0.8490\n",
            "Epoch 177/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4849 - accuracy: 0.8737 - val_loss: 0.4985 - val_accuracy: 0.8672\n",
            "Epoch 178/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.4861 - accuracy: 0.8694 - val_loss: 0.5086 - val_accuracy: 0.8516\n",
            "Epoch 179/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4793 - accuracy: 0.8769 - val_loss: 0.5002 - val_accuracy: 0.8542\n",
            "Epoch 180/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4715 - accuracy: 0.8775 - val_loss: 0.5053 - val_accuracy: 0.8542\n",
            "Epoch 181/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4850 - accuracy: 0.8694 - val_loss: 0.5031 - val_accuracy: 0.8542\n",
            "Epoch 182/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.4758 - accuracy: 0.8669 - val_loss: 0.4977 - val_accuracy: 0.8542\n",
            "Epoch 183/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4769 - accuracy: 0.8744 - val_loss: 0.5023 - val_accuracy: 0.8542\n",
            "Epoch 184/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.4707 - accuracy: 0.8794 - val_loss: 0.4886 - val_accuracy: 0.8594\n",
            "Epoch 185/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4699 - accuracy: 0.8756 - val_loss: 0.4797 - val_accuracy: 0.8672\n",
            "Epoch 186/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4723 - accuracy: 0.8763 - val_loss: 0.4900 - val_accuracy: 0.8594\n",
            "Epoch 187/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4667 - accuracy: 0.8744 - val_loss: 0.4879 - val_accuracy: 0.8594\n",
            "Epoch 188/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4611 - accuracy: 0.8819 - val_loss: 0.4981 - val_accuracy: 0.8490\n",
            "Epoch 189/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.4588 - accuracy: 0.8813 - val_loss: 0.4882 - val_accuracy: 0.8594\n",
            "Epoch 190/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4616 - accuracy: 0.8725 - val_loss: 0.4898 - val_accuracy: 0.8568\n",
            "Epoch 191/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4669 - accuracy: 0.8706 - val_loss: 0.4834 - val_accuracy: 0.8672\n",
            "Epoch 192/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.4609 - accuracy: 0.8794 - val_loss: 0.4750 - val_accuracy: 0.8672\n",
            "Epoch 193/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4577 - accuracy: 0.8744 - val_loss: 0.4859 - val_accuracy: 0.8542\n",
            "Epoch 194/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4598 - accuracy: 0.8725 - val_loss: 0.4816 - val_accuracy: 0.8568\n",
            "Epoch 195/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.4600 - accuracy: 0.8781 - val_loss: 0.4587 - val_accuracy: 0.8724\n",
            "Epoch 196/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.4486 - accuracy: 0.8819 - val_loss: 0.4772 - val_accuracy: 0.8672\n",
            "Epoch 197/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.4548 - accuracy: 0.8794 - val_loss: 0.4729 - val_accuracy: 0.8620\n",
            "Epoch 198/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4453 - accuracy: 0.8925 - val_loss: 0.4731 - val_accuracy: 0.8646\n",
            "Epoch 199/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.4472 - accuracy: 0.8800 - val_loss: 0.4751 - val_accuracy: 0.8542\n",
            "Epoch 200/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4435 - accuracy: 0.8825 - val_loss: 0.4733 - val_accuracy: 0.8620\n",
            "Epoch 201/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4402 - accuracy: 0.8800 - val_loss: 0.4630 - val_accuracy: 0.8698\n",
            "Epoch 202/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4365 - accuracy: 0.8894 - val_loss: 0.4701 - val_accuracy: 0.8620\n",
            "Epoch 203/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4427 - accuracy: 0.8800 - val_loss: 0.4688 - val_accuracy: 0.8646\n",
            "Epoch 204/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.4408 - accuracy: 0.8838 - val_loss: 0.4585 - val_accuracy: 0.8724\n",
            "Epoch 205/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4445 - accuracy: 0.8794 - val_loss: 0.4629 - val_accuracy: 0.8724\n",
            "Epoch 206/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4326 - accuracy: 0.8875 - val_loss: 0.4636 - val_accuracy: 0.8672\n",
            "Epoch 207/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4344 - accuracy: 0.8856 - val_loss: 0.4538 - val_accuracy: 0.8646\n",
            "Epoch 208/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4251 - accuracy: 0.8969 - val_loss: 0.4535 - val_accuracy: 0.8620\n",
            "Epoch 209/400\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4272 - accuracy: 0.8975 - val_loss: 0.4656 - val_accuracy: 0.8698\n",
            "Epoch 210/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4307 - accuracy: 0.8875 - val_loss: 0.4467 - val_accuracy: 0.8750\n",
            "Epoch 211/400\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.4335 - accuracy: 0.8806 - val_loss: 0.4612 - val_accuracy: 0.8724\n",
            "Epoch 212/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4282 - accuracy: 0.8956 - val_loss: 0.4616 - val_accuracy: 0.8646\n",
            "Epoch 213/400\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4242 - accuracy: 0.8925 - val_loss: 0.4619 - val_accuracy: 0.8646\n",
            "Epoch 214/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4283 - accuracy: 0.8831 - val_loss: 0.4494 - val_accuracy: 0.8698\n",
            "Epoch 215/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4155 - accuracy: 0.8981 - val_loss: 0.4511 - val_accuracy: 0.8698\n",
            "Epoch 216/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4219 - accuracy: 0.8925 - val_loss: 0.4403 - val_accuracy: 0.8750\n",
            "Epoch 217/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4176 - accuracy: 0.8975 - val_loss: 0.4496 - val_accuracy: 0.8698\n",
            "Epoch 218/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4177 - accuracy: 0.8906 - val_loss: 0.4405 - val_accuracy: 0.8672\n",
            "Epoch 219/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.4166 - accuracy: 0.8875 - val_loss: 0.4535 - val_accuracy: 0.8672\n",
            "Epoch 220/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4136 - accuracy: 0.8919 - val_loss: 0.4552 - val_accuracy: 0.8698\n",
            "Epoch 221/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4163 - accuracy: 0.8925 - val_loss: 0.4556 - val_accuracy: 0.8698\n",
            "Epoch 222/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4191 - accuracy: 0.8925 - val_loss: 0.4347 - val_accuracy: 0.8776\n",
            "Epoch 223/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4037 - accuracy: 0.8950 - val_loss: 0.4444 - val_accuracy: 0.8750\n",
            "Epoch 224/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4074 - accuracy: 0.8931 - val_loss: 0.4412 - val_accuracy: 0.8698\n",
            "Epoch 225/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.4164 - accuracy: 0.8906 - val_loss: 0.4303 - val_accuracy: 0.8776\n",
            "Epoch 226/400\n",
            "50/50 [==============================] - 14s 271ms/step - loss: 0.4030 - accuracy: 0.9013 - val_loss: 0.4456 - val_accuracy: 0.8724\n",
            "Epoch 227/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4073 - accuracy: 0.8869 - val_loss: 0.4447 - val_accuracy: 0.8750\n",
            "Epoch 228/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.4063 - accuracy: 0.8963 - val_loss: 0.4412 - val_accuracy: 0.8776\n",
            "Epoch 229/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3993 - accuracy: 0.8919 - val_loss: 0.4351 - val_accuracy: 0.8776\n",
            "Epoch 230/400\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.3981 - accuracy: 0.8969 - val_loss: 0.4392 - val_accuracy: 0.8698\n",
            "Epoch 231/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.4053 - accuracy: 0.8938 - val_loss: 0.4379 - val_accuracy: 0.8750\n",
            "Epoch 232/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3942 - accuracy: 0.9031 - val_loss: 0.4308 - val_accuracy: 0.8776\n",
            "Epoch 233/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3943 - accuracy: 0.8950 - val_loss: 0.4385 - val_accuracy: 0.8776\n",
            "Epoch 234/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.3945 - accuracy: 0.9000 - val_loss: 0.4339 - val_accuracy: 0.8750\n",
            "Epoch 235/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3926 - accuracy: 0.9031 - val_loss: 0.4302 - val_accuracy: 0.8828\n",
            "Epoch 236/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3894 - accuracy: 0.8988 - val_loss: 0.4349 - val_accuracy: 0.8724\n",
            "Epoch 237/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3953 - accuracy: 0.8894 - val_loss: 0.4234 - val_accuracy: 0.8802\n",
            "Epoch 238/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.4012 - accuracy: 0.8850 - val_loss: 0.4189 - val_accuracy: 0.8828\n",
            "Epoch 239/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3898 - accuracy: 0.9031 - val_loss: 0.4286 - val_accuracy: 0.8776\n",
            "Epoch 240/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3868 - accuracy: 0.8956 - val_loss: 0.4194 - val_accuracy: 0.8802\n",
            "Epoch 241/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.3834 - accuracy: 0.8981 - val_loss: 0.4253 - val_accuracy: 0.8802\n",
            "Epoch 242/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3890 - accuracy: 0.8988 - val_loss: 0.4250 - val_accuracy: 0.8802\n",
            "Epoch 243/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3795 - accuracy: 0.9013 - val_loss: 0.4254 - val_accuracy: 0.8828\n",
            "Epoch 244/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3822 - accuracy: 0.9025 - val_loss: 0.4188 - val_accuracy: 0.8854\n",
            "Epoch 245/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3801 - accuracy: 0.8963 - val_loss: 0.4240 - val_accuracy: 0.8802\n",
            "Epoch 246/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3735 - accuracy: 0.9025 - val_loss: 0.4132 - val_accuracy: 0.8854\n",
            "Epoch 247/400\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.3781 - accuracy: 0.8994 - val_loss: 0.4134 - val_accuracy: 0.8880\n",
            "Epoch 248/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.3758 - accuracy: 0.9025 - val_loss: 0.4194 - val_accuracy: 0.8802\n",
            "Epoch 249/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3741 - accuracy: 0.9081 - val_loss: 0.4164 - val_accuracy: 0.8802\n",
            "Epoch 250/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3686 - accuracy: 0.9006 - val_loss: 0.4089 - val_accuracy: 0.8932\n",
            "Epoch 251/400\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3750 - accuracy: 0.9069 - val_loss: 0.4157 - val_accuracy: 0.8828\n",
            "Epoch 252/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3773 - accuracy: 0.8981 - val_loss: 0.3977 - val_accuracy: 0.8906\n",
            "Epoch 253/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3653 - accuracy: 0.9050 - val_loss: 0.4109 - val_accuracy: 0.8854\n",
            "Epoch 254/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3642 - accuracy: 0.9075 - val_loss: 0.4062 - val_accuracy: 0.8854\n",
            "Epoch 255/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3671 - accuracy: 0.8994 - val_loss: 0.4142 - val_accuracy: 0.8802\n",
            "Epoch 256/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.3674 - accuracy: 0.9050 - val_loss: 0.3985 - val_accuracy: 0.8906\n",
            "Epoch 257/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3599 - accuracy: 0.9062 - val_loss: 0.4018 - val_accuracy: 0.8932\n",
            "Epoch 258/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3679 - accuracy: 0.8981 - val_loss: 0.4099 - val_accuracy: 0.8880\n",
            "Epoch 259/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3661 - accuracy: 0.9025 - val_loss: 0.4069 - val_accuracy: 0.8932\n",
            "Epoch 260/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3621 - accuracy: 0.9087 - val_loss: 0.4068 - val_accuracy: 0.8854\n",
            "Epoch 261/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3683 - accuracy: 0.9013 - val_loss: 0.3885 - val_accuracy: 0.8984\n",
            "Epoch 262/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3611 - accuracy: 0.9056 - val_loss: 0.4102 - val_accuracy: 0.8880\n",
            "Epoch 263/400\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.3649 - accuracy: 0.9025 - val_loss: 0.4024 - val_accuracy: 0.8906\n",
            "Epoch 264/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3602 - accuracy: 0.8956 - val_loss: 0.3987 - val_accuracy: 0.8932\n",
            "Epoch 265/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3588 - accuracy: 0.9087 - val_loss: 0.3926 - val_accuracy: 0.8906\n",
            "Epoch 266/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3543 - accuracy: 0.9131 - val_loss: 0.3955 - val_accuracy: 0.8932\n",
            "Epoch 267/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3628 - accuracy: 0.9044 - val_loss: 0.3955 - val_accuracy: 0.8880\n",
            "Epoch 268/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3509 - accuracy: 0.9131 - val_loss: 0.3963 - val_accuracy: 0.8958\n",
            "Epoch 269/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3523 - accuracy: 0.9069 - val_loss: 0.4028 - val_accuracy: 0.8906\n",
            "Epoch 270/400\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3449 - accuracy: 0.9131 - val_loss: 0.3936 - val_accuracy: 0.8932\n",
            "Epoch 271/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3498 - accuracy: 0.9125 - val_loss: 0.3963 - val_accuracy: 0.8906\n",
            "Epoch 272/400\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3496 - accuracy: 0.9100 - val_loss: 0.3948 - val_accuracy: 0.8880\n",
            "Epoch 273/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3459 - accuracy: 0.9119 - val_loss: 0.3929 - val_accuracy: 0.8906\n",
            "Epoch 274/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3488 - accuracy: 0.9094 - val_loss: 0.3976 - val_accuracy: 0.8854\n",
            "Epoch 275/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3417 - accuracy: 0.9131 - val_loss: 0.3814 - val_accuracy: 0.9010\n",
            "Epoch 276/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3437 - accuracy: 0.9162 - val_loss: 0.3959 - val_accuracy: 0.8880\n",
            "Epoch 277/400\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.3418 - accuracy: 0.9156 - val_loss: 0.3885 - val_accuracy: 0.8906\n",
            "Epoch 278/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3418 - accuracy: 0.9094 - val_loss: 0.3911 - val_accuracy: 0.8932\n",
            "Epoch 279/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3410 - accuracy: 0.9081 - val_loss: 0.3829 - val_accuracy: 0.8984\n",
            "Epoch 280/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3432 - accuracy: 0.9100 - val_loss: 0.3875 - val_accuracy: 0.8932\n",
            "Epoch 281/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3385 - accuracy: 0.9056 - val_loss: 0.3896 - val_accuracy: 0.8932\n",
            "Epoch 282/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3441 - accuracy: 0.9119 - val_loss: 0.3844 - val_accuracy: 0.8932\n",
            "Epoch 283/400\n",
            "50/50 [==============================] - 14s 272ms/step - loss: 0.3323 - accuracy: 0.9169 - val_loss: 0.3797 - val_accuracy: 0.8958\n",
            "Epoch 284/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3334 - accuracy: 0.9150 - val_loss: 0.3840 - val_accuracy: 0.8932\n",
            "Epoch 285/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3367 - accuracy: 0.9056 - val_loss: 0.3870 - val_accuracy: 0.8906\n",
            "Epoch 286/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3283 - accuracy: 0.9125 - val_loss: 0.3815 - val_accuracy: 0.8932\n",
            "Epoch 287/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3324 - accuracy: 0.9087 - val_loss: 0.3747 - val_accuracy: 0.9010\n",
            "Epoch 288/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3364 - accuracy: 0.9087 - val_loss: 0.3771 - val_accuracy: 0.8932\n",
            "Epoch 289/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3343 - accuracy: 0.9100 - val_loss: 0.3773 - val_accuracy: 0.8984\n",
            "Epoch 290/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3327 - accuracy: 0.9125 - val_loss: 0.3790 - val_accuracy: 0.8958\n",
            "Epoch 291/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3348 - accuracy: 0.9094 - val_loss: 0.3725 - val_accuracy: 0.9010\n",
            "Epoch 292/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3306 - accuracy: 0.9169 - val_loss: 0.3693 - val_accuracy: 0.8984\n",
            "Epoch 293/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3315 - accuracy: 0.9131 - val_loss: 0.3772 - val_accuracy: 0.8958\n",
            "Epoch 294/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3298 - accuracy: 0.9106 - val_loss: 0.3770 - val_accuracy: 0.8932\n",
            "Epoch 295/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3340 - accuracy: 0.9075 - val_loss: 0.3676 - val_accuracy: 0.8958\n",
            "Epoch 296/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3330 - accuracy: 0.9075 - val_loss: 0.3801 - val_accuracy: 0.8906\n",
            "Epoch 297/400\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.3273 - accuracy: 0.9187 - val_loss: 0.3816 - val_accuracy: 0.8880\n",
            "Epoch 298/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3282 - accuracy: 0.9150 - val_loss: 0.3733 - val_accuracy: 0.9010\n",
            "Epoch 299/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3273 - accuracy: 0.9194 - val_loss: 0.3582 - val_accuracy: 0.9036\n",
            "Epoch 300/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3304 - accuracy: 0.9181 - val_loss: 0.3714 - val_accuracy: 0.8958\n",
            "Epoch 301/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3286 - accuracy: 0.9144 - val_loss: 0.3691 - val_accuracy: 0.8906\n",
            "Epoch 302/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3176 - accuracy: 0.9175 - val_loss: 0.3757 - val_accuracy: 0.8958\n",
            "Epoch 303/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3172 - accuracy: 0.9144 - val_loss: 0.3676 - val_accuracy: 0.8984\n",
            "Epoch 304/400\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.3204 - accuracy: 0.9206 - val_loss: 0.3714 - val_accuracy: 0.8932\n",
            "Epoch 305/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3120 - accuracy: 0.9237 - val_loss: 0.3701 - val_accuracy: 0.8932\n",
            "Epoch 306/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3213 - accuracy: 0.9131 - val_loss: 0.3693 - val_accuracy: 0.8932\n",
            "Epoch 307/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3147 - accuracy: 0.9125 - val_loss: 0.3555 - val_accuracy: 0.9010\n",
            "Epoch 308/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.3093 - accuracy: 0.9256 - val_loss: 0.3657 - val_accuracy: 0.8958\n",
            "Epoch 309/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3161 - accuracy: 0.9137 - val_loss: 0.3650 - val_accuracy: 0.8932\n",
            "Epoch 310/400\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.3177 - accuracy: 0.9162 - val_loss: 0.3656 - val_accuracy: 0.8906\n",
            "Epoch 311/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3072 - accuracy: 0.9275 - val_loss: 0.3716 - val_accuracy: 0.8932\n",
            "Epoch 312/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3050 - accuracy: 0.9231 - val_loss: 0.3627 - val_accuracy: 0.8958\n",
            "Epoch 313/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3123 - accuracy: 0.9225 - val_loss: 0.3590 - val_accuracy: 0.8958\n",
            "Epoch 314/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3050 - accuracy: 0.9212 - val_loss: 0.3651 - val_accuracy: 0.8932\n",
            "Epoch 315/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.3172 - accuracy: 0.9094 - val_loss: 0.3511 - val_accuracy: 0.9010\n",
            "Epoch 316/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3094 - accuracy: 0.9169 - val_loss: 0.3477 - val_accuracy: 0.9010\n",
            "Epoch 317/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3104 - accuracy: 0.9144 - val_loss: 0.3541 - val_accuracy: 0.8932\n",
            "Epoch 318/400\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.3011 - accuracy: 0.9237 - val_loss: 0.3477 - val_accuracy: 0.9010\n",
            "Epoch 319/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3075 - accuracy: 0.9156 - val_loss: 0.3433 - val_accuracy: 0.8958\n",
            "Epoch 320/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3038 - accuracy: 0.9200 - val_loss: 0.3640 - val_accuracy: 0.8958\n",
            "Epoch 321/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3033 - accuracy: 0.9244 - val_loss: 0.3571 - val_accuracy: 0.8932\n",
            "Epoch 322/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.3038 - accuracy: 0.9175 - val_loss: 0.3511 - val_accuracy: 0.8958\n",
            "Epoch 323/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.3043 - accuracy: 0.9250 - val_loss: 0.3368 - val_accuracy: 0.9036\n",
            "Epoch 324/400\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.3010 - accuracy: 0.9181 - val_loss: 0.3490 - val_accuracy: 0.9036\n",
            "Epoch 325/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.3028 - accuracy: 0.9200 - val_loss: 0.3593 - val_accuracy: 0.8958\n",
            "Epoch 326/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2962 - accuracy: 0.9244 - val_loss: 0.3539 - val_accuracy: 0.8932\n",
            "Epoch 327/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2994 - accuracy: 0.9206 - val_loss: 0.3544 - val_accuracy: 0.8932\n",
            "Epoch 328/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2982 - accuracy: 0.9250 - val_loss: 0.3433 - val_accuracy: 0.9036\n",
            "Epoch 329/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.3020 - accuracy: 0.9250 - val_loss: 0.3436 - val_accuracy: 0.9010\n",
            "Epoch 330/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2839 - accuracy: 0.9337 - val_loss: 0.3569 - val_accuracy: 0.8958\n",
            "Epoch 331/400\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.2920 - accuracy: 0.9350 - val_loss: 0.3372 - val_accuracy: 0.9036\n",
            "Epoch 332/400\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.2923 - accuracy: 0.9231 - val_loss: 0.3554 - val_accuracy: 0.8932\n",
            "Epoch 333/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2936 - accuracy: 0.9256 - val_loss: 0.3494 - val_accuracy: 0.8958\n",
            "Epoch 334/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2924 - accuracy: 0.9206 - val_loss: 0.3506 - val_accuracy: 0.8958\n",
            "Epoch 335/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2938 - accuracy: 0.9169 - val_loss: 0.3483 - val_accuracy: 0.8958\n",
            "Epoch 336/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2871 - accuracy: 0.9281 - val_loss: 0.3526 - val_accuracy: 0.8958\n",
            "Epoch 337/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2960 - accuracy: 0.9200 - val_loss: 0.3457 - val_accuracy: 0.8958\n",
            "Epoch 338/400\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.2904 - accuracy: 0.9319 - val_loss: 0.3453 - val_accuracy: 0.8984\n",
            "Epoch 339/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2919 - accuracy: 0.9244 - val_loss: 0.3458 - val_accuracy: 0.8984\n",
            "Epoch 340/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2875 - accuracy: 0.9256 - val_loss: 0.3466 - val_accuracy: 0.9010\n",
            "Epoch 341/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2861 - accuracy: 0.9262 - val_loss: 0.3342 - val_accuracy: 0.9010\n",
            "Epoch 342/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2972 - accuracy: 0.9237 - val_loss: 0.3410 - val_accuracy: 0.9010\n",
            "Epoch 343/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.2835 - accuracy: 0.9225 - val_loss: 0.3336 - val_accuracy: 0.9036\n",
            "Epoch 344/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2839 - accuracy: 0.9306 - val_loss: 0.3366 - val_accuracy: 0.9010\n",
            "Epoch 345/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2860 - accuracy: 0.9212 - val_loss: 0.3413 - val_accuracy: 0.8958\n",
            "Epoch 346/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2852 - accuracy: 0.9219 - val_loss: 0.3277 - val_accuracy: 0.9036\n",
            "Epoch 347/400\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.2840 - accuracy: 0.9244 - val_loss: 0.3417 - val_accuracy: 0.8984\n",
            "Epoch 348/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2854 - accuracy: 0.9206 - val_loss: 0.3411 - val_accuracy: 0.8984\n",
            "Epoch 349/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2853 - accuracy: 0.9275 - val_loss: 0.3375 - val_accuracy: 0.9010\n",
            "Epoch 350/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2787 - accuracy: 0.9300 - val_loss: 0.3254 - val_accuracy: 0.9010\n",
            "Epoch 351/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2857 - accuracy: 0.9200 - val_loss: 0.3370 - val_accuracy: 0.8984\n",
            "Epoch 352/400\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.2826 - accuracy: 0.9287 - val_loss: 0.3309 - val_accuracy: 0.9036\n",
            "Epoch 353/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2757 - accuracy: 0.9300 - val_loss: 0.3372 - val_accuracy: 0.9036\n",
            "Epoch 354/400\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2848 - accuracy: 0.9231 - val_loss: 0.3304 - val_accuracy: 0.9062\n",
            "Epoch 355/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2745 - accuracy: 0.9287 - val_loss: 0.3383 - val_accuracy: 0.8984\n",
            "Epoch 356/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2730 - accuracy: 0.9350 - val_loss: 0.3311 - val_accuracy: 0.8984\n",
            "Epoch 357/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2738 - accuracy: 0.9362 - val_loss: 0.3311 - val_accuracy: 0.9010\n",
            "Epoch 358/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2808 - accuracy: 0.9231 - val_loss: 0.3370 - val_accuracy: 0.8984\n",
            "Epoch 359/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2768 - accuracy: 0.9331 - val_loss: 0.3200 - val_accuracy: 0.9062\n",
            "Epoch 360/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2755 - accuracy: 0.9269 - val_loss: 0.3369 - val_accuracy: 0.9062\n",
            "Epoch 361/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2677 - accuracy: 0.9369 - val_loss: 0.3331 - val_accuracy: 0.9010\n",
            "Epoch 362/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2685 - accuracy: 0.9294 - val_loss: 0.3226 - val_accuracy: 0.9062\n",
            "Epoch 363/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2714 - accuracy: 0.9319 - val_loss: 0.3313 - val_accuracy: 0.9036\n",
            "Epoch 364/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2709 - accuracy: 0.9306 - val_loss: 0.3329 - val_accuracy: 0.9036\n",
            "Epoch 365/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2666 - accuracy: 0.9337 - val_loss: 0.3309 - val_accuracy: 0.9010\n",
            "Epoch 366/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2708 - accuracy: 0.9337 - val_loss: 0.3283 - val_accuracy: 0.9010\n",
            "Epoch 367/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2636 - accuracy: 0.9356 - val_loss: 0.3310 - val_accuracy: 0.9036\n",
            "Epoch 368/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2653 - accuracy: 0.9237 - val_loss: 0.3098 - val_accuracy: 0.9115\n",
            "Epoch 369/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2721 - accuracy: 0.9275 - val_loss: 0.3275 - val_accuracy: 0.9036\n",
            "Epoch 370/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2680 - accuracy: 0.9281 - val_loss: 0.3234 - val_accuracy: 0.9062\n",
            "Epoch 371/400\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2668 - accuracy: 0.9325 - val_loss: 0.3207 - val_accuracy: 0.9062\n",
            "Epoch 372/400\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.2671 - accuracy: 0.9306 - val_loss: 0.3204 - val_accuracy: 0.9115\n",
            "Epoch 373/400\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.2619 - accuracy: 0.9388 - val_loss: 0.3216 - val_accuracy: 0.9062\n",
            "Epoch 374/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2573 - accuracy: 0.9394 - val_loss: 0.3316 - val_accuracy: 0.8984\n",
            "Epoch 375/400\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2568 - accuracy: 0.9388 - val_loss: 0.3028 - val_accuracy: 0.9089\n",
            "Epoch 376/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2591 - accuracy: 0.9325 - val_loss: 0.3208 - val_accuracy: 0.9062\n",
            "Epoch 377/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2566 - accuracy: 0.9350 - val_loss: 0.3303 - val_accuracy: 0.9036\n",
            "Epoch 378/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2607 - accuracy: 0.9337 - val_loss: 0.3117 - val_accuracy: 0.9089\n",
            "Epoch 379/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2608 - accuracy: 0.9275 - val_loss: 0.3149 - val_accuracy: 0.9089\n",
            "Epoch 380/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2548 - accuracy: 0.9388 - val_loss: 0.3201 - val_accuracy: 0.9089\n",
            "Epoch 381/400\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.2600 - accuracy: 0.9350 - val_loss: 0.3209 - val_accuracy: 0.9089\n",
            "Epoch 382/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2603 - accuracy: 0.9344 - val_loss: 0.3202 - val_accuracy: 0.9036\n",
            "Epoch 383/400\n",
            "50/50 [==============================] - 13s 256ms/step - loss: 0.2527 - accuracy: 0.9375 - val_loss: 0.3168 - val_accuracy: 0.9062\n",
            "Epoch 384/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2579 - accuracy: 0.9369 - val_loss: 0.3203 - val_accuracy: 0.9089\n",
            "Epoch 385/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2532 - accuracy: 0.9400 - val_loss: 0.3205 - val_accuracy: 0.9062\n",
            "Epoch 386/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2519 - accuracy: 0.9456 - val_loss: 0.3201 - val_accuracy: 0.9010\n",
            "Epoch 387/400\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.2509 - accuracy: 0.9381 - val_loss: 0.3224 - val_accuracy: 0.9089\n",
            "Epoch 388/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2454 - accuracy: 0.9413 - val_loss: 0.3127 - val_accuracy: 0.9062\n",
            "Epoch 389/400\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.2585 - accuracy: 0.9331 - val_loss: 0.3210 - val_accuracy: 0.9062\n",
            "Epoch 390/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2502 - accuracy: 0.9369 - val_loss: 0.3128 - val_accuracy: 0.9089\n",
            "Epoch 391/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2507 - accuracy: 0.9406 - val_loss: 0.3146 - val_accuracy: 0.9115\n",
            "Epoch 392/400\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.2495 - accuracy: 0.9375 - val_loss: 0.3127 - val_accuracy: 0.9089\n",
            "Epoch 393/400\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.2444 - accuracy: 0.9325 - val_loss: 0.3195 - val_accuracy: 0.9036\n",
            "Epoch 394/400\n",
            "50/50 [==============================] - 13s 258ms/step - loss: 0.2452 - accuracy: 0.9456 - val_loss: 0.3160 - val_accuracy: 0.9062\n",
            "Epoch 395/400\n",
            "50/50 [==============================] - 13s 257ms/step - loss: 0.2433 - accuracy: 0.9413 - val_loss: 0.3184 - val_accuracy: 0.9062\n",
            "Epoch 396/400\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.2544 - accuracy: 0.9369 - val_loss: 0.3061 - val_accuracy: 0.9089\n",
            "Epoch 397/400\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.2442 - accuracy: 0.9425 - val_loss: 0.3155 - val_accuracy: 0.9089\n",
            "Epoch 398/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2416 - accuracy: 0.9388 - val_loss: 0.3136 - val_accuracy: 0.9089\n",
            "Epoch 399/400\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.2369 - accuracy: 0.9481 - val_loss: 0.3185 - val_accuracy: 0.9062\n",
            "Epoch 400/400\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.2487 - accuracy: 0.9419 - val_loss: 0.3102 - val_accuracy: 0.9115\n",
            "CPU times: user 1h 21min 7s, sys: 3min 59s, total: 1h 25min 6s\n",
            "Wall time: 1h 35min 56s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "61d0c0d0-e581-4466-fb34-67ae658bf602",
        "id": "Hei8hgjfxs_7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337e3b68-04e7-474d-acd9-c09cf24e2c48",
        "id": "vMWNSHeHxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model3200.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights3200.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model3200.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3e959b-52e3-40a3-d29d-13e5f1b04bbb",
        "id": "T-dKHmLaxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99nfg0KQxs_7"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model3200.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0543177-ff8b-41b5-e868-e491dbdc82d6",
        "id": "GQWVkp5nxs_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7198f5d5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 842ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91         5\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00         9\n",
            "           3       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.96      0.97      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86         8\n",
            "           1       0.88      1.00      0.93         7\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.93      0.94      0.93        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ahGhiq9gxs_7",
        "outputId": "7c4ebf0a-964b-4caa-837d-3fbb13fbea6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(11, 5))\n",
        "plt.subplot(121)\n",
        "labels = np.unique(y_pred_train_argmax)\n",
        "# cm = confusion_matrix(y_train_argmax, y_pred_train_argmax, labels=labels)\n",
        "# sns.heatmap(cm, annot=True, square=True, cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "# plt.title(f\"Training Accuracy: {accuracy_score(y_train_argmax, y_pred_train_argmax):.3f}\", fontsize=14)\n",
        "# plt.xlabel('Prediction', fontsize=14)\n",
        "# plt.ylabel('Actual', fontsize=14)\n",
        "# plt.yticks(rotation=0, verticalalignment='center')\n",
        "# plt.subplot(122)\n",
        "cm = confusion_matrix(y_test_argmax, y_pred_test_argmax, labels=labels)\n",
        "sns.heatmap(cm, annot=True, cmap='Greens', cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot_kws={\"fontsize\":15})\n",
        "plt.title(f\"Validation Accuracy: {accuracy_score(y_test_argmax, y_pred_test_argmax):.3f}\", fontsize=14)\n",
        "plt.xlabel('Prediction', fontsize=14)\n",
        "plt.ylabel('Actual', fontsize=14)\n",
        "plt.yticks(rotation=0, verticalalignment='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj8Jt5GHoChz"
      },
      "source": [
        "#3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOFjfgAzoCh5",
        "outputId": "6ae3433e-1c04-44a0-f785-3fcbefe120c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.0001\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 100\n",
        "batch_size = 8\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 1e-3\n",
        "if epochs > 180:\n",
        "    lr *= 0.5e-3\n",
        "elif epochs > 160:\n",
        "    lr *= 1e-3\n",
        "elif epochs > 120:\n",
        "    lr *= 1e-2\n",
        "elif epochs > 80:\n",
        "    lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_IURYehoCh5",
        "outputId": "b8d7dc96-b249-4b23-cb92-0f0d5d815891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooo1h3-XoCh5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3V37teZoCh6",
        "outputId": "95592aa1-c099-4a68-bd2d-593c5d3a36b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-hTORNOoCh6",
        "outputId": "e5222c8f-4016-49fb-97db-3c17050850d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 19s 79ms/step - loss: 0.9855 - accuracy: 0.5788 - val_loss: 1.1768 - val_accuracy: 0.3725\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.6298 - accuracy: 0.7606 - val_loss: 0.6142 - val_accuracy: 0.7475\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.5073 - accuracy: 0.8150 - val_loss: 0.4744 - val_accuracy: 0.8250\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.3995 - accuracy: 0.8500 - val_loss: 0.4153 - val_accuracy: 0.8500\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.3515 - accuracy: 0.8712 - val_loss: 0.3162 - val_accuracy: 0.8875\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.3117 - accuracy: 0.8856 - val_loss: 0.3346 - val_accuracy: 0.8875\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.2683 - accuracy: 0.9025 - val_loss: 0.7057 - val_accuracy: 0.7700\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.2538 - accuracy: 0.9081 - val_loss: 0.3316 - val_accuracy: 0.8675\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.2257 - accuracy: 0.9137 - val_loss: 0.4622 - val_accuracy: 0.8425\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.1992 - accuracy: 0.9300 - val_loss: 0.2613 - val_accuracy: 0.9175\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1624 - accuracy: 0.9444 - val_loss: 0.2105 - val_accuracy: 0.9350\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.1612 - accuracy: 0.9456 - val_loss: 0.2441 - val_accuracy: 0.9150\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1512 - accuracy: 0.9481 - val_loss: 0.2733 - val_accuracy: 0.9175\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.1717 - accuracy: 0.9419 - val_loss: 0.2750 - val_accuracy: 0.9125\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.1394 - accuracy: 0.9481 - val_loss: 0.2115 - val_accuracy: 0.9300\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1594 - accuracy: 0.9394 - val_loss: 0.4243 - val_accuracy: 0.8725\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1452 - accuracy: 0.9525 - val_loss: 0.2471 - val_accuracy: 0.9300\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1327 - accuracy: 0.9525 - val_loss: 0.3728 - val_accuracy: 0.8875\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.2411 - val_accuracy: 0.9250\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.1033 - accuracy: 0.9681 - val_loss: 0.2019 - val_accuracy: 0.9350\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 0.3512 - val_accuracy: 0.8875\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.1205 - accuracy: 0.9531 - val_loss: 0.1691 - val_accuracy: 0.9400\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.3866 - val_accuracy: 0.8525\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0759 - accuracy: 0.9744 - val_loss: 0.1784 - val_accuracy: 0.9400\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0955 - accuracy: 0.9688 - val_loss: 0.2495 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0880 - accuracy: 0.9656 - val_loss: 0.2740 - val_accuracy: 0.8950\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0912 - accuracy: 0.9656 - val_loss: 0.2052 - val_accuracy: 0.9450\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.1871 - val_accuracy: 0.9425\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0779 - accuracy: 0.9688 - val_loss: 0.2426 - val_accuracy: 0.9000\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 0.3185 - val_accuracy: 0.9075\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 0.2116 - val_accuracy: 0.9350\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.0773 - accuracy: 0.9725 - val_loss: 0.1699 - val_accuracy: 0.9475\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 0.2855 - val_accuracy: 0.9125\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.0397 - accuracy: 0.9894 - val_loss: 0.3038 - val_accuracy: 0.8925\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.2499 - val_accuracy: 0.9150\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.1779 - val_accuracy: 0.9475\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.2120 - val_accuracy: 0.9450\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.1356 - accuracy: 0.9500 - val_loss: 0.3375 - val_accuracy: 0.9150\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.5647 - val_accuracy: 0.8575\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.1819 - val_accuracy: 0.9475\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.0651 - accuracy: 0.9750 - val_loss: 0.2155 - val_accuracy: 0.9350\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0333 - accuracy: 0.9919 - val_loss: 0.2044 - val_accuracy: 0.9325\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1869 - val_accuracy: 0.9375\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1995 - val_accuracy: 0.9400\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.2171 - val_accuracy: 0.9425\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.2296 - val_accuracy: 0.9400\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0750 - accuracy: 0.9756 - val_loss: 0.5044 - val_accuracy: 0.8725\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.1592 - val_accuracy: 0.9450\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 0.1389 - val_accuracy: 0.9550\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.4075 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0791 - accuracy: 0.9744 - val_loss: 0.3464 - val_accuracy: 0.9100\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0842 - accuracy: 0.9719 - val_loss: 0.5563 - val_accuracy: 0.8675\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0796 - accuracy: 0.9737 - val_loss: 0.2117 - val_accuracy: 0.9350\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.1987 - val_accuracy: 0.9425\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.2480 - val_accuracy: 0.9225\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 0.2162 - val_accuracy: 0.9475\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.1874 - val_accuracy: 0.9500\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.1726 - val_accuracy: 0.9375\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.2648 - val_accuracy: 0.9225\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0876 - accuracy: 0.9694 - val_loss: 0.4521 - val_accuracy: 0.8975\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.2419 - val_accuracy: 0.9400\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0505 - accuracy: 0.9800 - val_loss: 0.2603 - val_accuracy: 0.9400\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1417 - val_accuracy: 0.9625\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.0638 - accuracy: 0.9762 - val_loss: 0.2131 - val_accuracy: 0.9400\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0583 - accuracy: 0.9819 - val_loss: 0.1878 - val_accuracy: 0.9400\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.1885 - val_accuracy: 0.9475\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.1625 - val_accuracy: 0.9500\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.2130 - val_accuracy: 0.9325\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.2962 - val_accuracy: 0.9225\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0794 - accuracy: 0.9700 - val_loss: 0.2552 - val_accuracy: 0.9375\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 0.2420 - val_accuracy: 0.9325\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.1976 - val_accuracy: 0.9475\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.2233 - val_accuracy: 0.9275\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.1906 - val_accuracy: 0.9500\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.1555 - val_accuracy: 0.9500\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.1661 - val_accuracy: 0.9525\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.2551 - val_accuracy: 0.9225\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.7463 - val_accuracy: 0.8475\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.2448 - val_accuracy: 0.9375\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.2822 - val_accuracy: 0.9325\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9525\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 0.4251 - val_accuracy: 0.9125\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0531 - accuracy: 0.9787 - val_loss: 0.2487 - val_accuracy: 0.9350\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1281 - val_accuracy: 0.9525\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0333 - accuracy: 0.9881 - val_loss: 0.1522 - val_accuracy: 0.9550\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 0.2034 - val_accuracy: 0.9450\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.3206 - val_accuracy: 0.9150\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0374 - accuracy: 0.9869 - val_loss: 0.2151 - val_accuracy: 0.9475\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.1875 - val_accuracy: 0.9500\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1514 - val_accuracy: 0.9500\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.2106 - val_accuracy: 0.9500\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 0.2782 - val_accuracy: 0.9125\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.1981 - val_accuracy: 0.9400\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 15s 72ms/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 0.2202 - val_accuracy: 0.9525\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.1549 - val_accuracy: 0.9525\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.1782 - val_accuracy: 0.9500\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 0.3764 - val_accuracy: 0.8925\n",
            "CPU times: user 25min 7s, sys: 1min 13s, total: 26min 21s\n",
            "Wall time: 25min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "_fl6n4VToCh6",
        "outputId": "613fee1e-95f4-4da9-a72b-38fb628e9e24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_q42DW1oCh6",
        "outputId": "aafa6750-85af-4bbc-ac6a-c141dd32841e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model300.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights300.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model300.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuGyBbE-oCh6",
        "outputId": "bd283b3b-84f9-4b1e-9eb4-0d59ca565fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp9fT0jzoCh7"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model300.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR_BtFZ3oCh7",
        "outputId": "258b74f4-e950-427e-d1c5-0f2f30587bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Tqt5B_oCh8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqBILCXU6xwT"
      },
      "source": [
        "#4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrrUDE6J6xwZ",
        "outputId": "fac60dc3-3ccd-46ed-a1b9-b1f65b0b98cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  5e-07\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 5e-07\n",
        "# if epochs > 180:\n",
        "#     lr *= 0.5e-3\n",
        "# elif epochs > 160:\n",
        "#     lr *= 1e-3\n",
        "# elif epochs > 120:\n",
        "#     lr *= 1e-2\n",
        "# elif epochs > 80:\n",
        "#     lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHpiSzYB6xwZ",
        "outputId": "1b11edc9-d0af-4c50-f718-ce5fcace741f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "# Load data validasi\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ollD-HmR6xwZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev5-FvuU6xwZ",
        "outputId": "6fe4a49a-6367-4af4-d595-ebb65ab8cf2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMS_X9K66xwa",
        "outputId": "af361638-63d9-4dd4-9e31-49c5c060d08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "400/400 [==============================] - 22s 43ms/step - loss: 1.4757 - accuracy: 0.2906 - val_loss: 1.3987 - val_accuracy: 0.3375\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.3552 - accuracy: 0.3481 - val_loss: 1.2902 - val_accuracy: 0.3575\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 17s 42ms/step - loss: 1.3070 - accuracy: 0.3850 - val_loss: 1.2485 - val_accuracy: 0.4500\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.2879 - accuracy: 0.4444 - val_loss: 1.2169 - val_accuracy: 0.5150\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 1.2591 - accuracy: 0.4794 - val_loss: 1.1954 - val_accuracy: 0.5150\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.2408 - accuracy: 0.4806 - val_loss: 1.1738 - val_accuracy: 0.5275\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.2199 - accuracy: 0.5194 - val_loss: 1.1554 - val_accuracy: 0.5350\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.2161 - accuracy: 0.5081 - val_loss: 1.1386 - val_accuracy: 0.5450\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1963 - accuracy: 0.5075 - val_loss: 1.1254 - val_accuracy: 0.5525\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1878 - accuracy: 0.5125 - val_loss: 1.1107 - val_accuracy: 0.5450\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1774 - accuracy: 0.5131 - val_loss: 1.0966 - val_accuracy: 0.5600\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1668 - accuracy: 0.5312 - val_loss: 1.0823 - val_accuracy: 0.5700\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1469 - accuracy: 0.5481 - val_loss: 1.0695 - val_accuracy: 0.5775\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1434 - accuracy: 0.5450 - val_loss: 1.0575 - val_accuracy: 0.5700\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.1332 - accuracy: 0.5419 - val_loss: 1.0463 - val_accuracy: 0.5950\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - 17s 42ms/step - loss: 1.1196 - accuracy: 0.5619 - val_loss: 1.0334 - val_accuracy: 0.5925\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.1215 - accuracy: 0.5469 - val_loss: 1.0235 - val_accuracy: 0.6125\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.1056 - accuracy: 0.5569 - val_loss: 1.0136 - val_accuracy: 0.6225\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.0953 - accuracy: 0.5775 - val_loss: 1.0030 - val_accuracy: 0.6150\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.0887 - accuracy: 0.5719 - val_loss: 0.9932 - val_accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.0823 - accuracy: 0.5788 - val_loss: 0.9832 - val_accuracy: 0.6275\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.0788 - accuracy: 0.5719 - val_loss: 0.9749 - val_accuracy: 0.6400\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.0681 - accuracy: 0.5938 - val_loss: 0.9653 - val_accuracy: 0.6450\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.0488 - accuracy: 0.5962 - val_loss: 0.9550 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.0449 - accuracy: 0.6119 - val_loss: 0.9480 - val_accuracy: 0.6475\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 1.0468 - accuracy: 0.5950 - val_loss: 0.9399 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.0384 - accuracy: 0.5975 - val_loss: 0.9328 - val_accuracy: 0.6550\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - 17s 41ms/step - loss: 1.0314 - accuracy: 0.6031 - val_loss: 0.9257 - val_accuracy: 0.6600\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 1.0300 - accuracy: 0.6125 - val_loss: 0.9205 - val_accuracy: 0.6675\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 1.0183 - accuracy: 0.6150 - val_loss: 0.9077 - val_accuracy: 0.6650\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 1.0028 - accuracy: 0.6263 - val_loss: 0.9047 - val_accuracy: 0.6750\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 1.0119 - accuracy: 0.6169 - val_loss: 0.8950 - val_accuracy: 0.6875\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9997 - accuracy: 0.6325 - val_loss: 0.8911 - val_accuracy: 0.6875\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9912 - accuracy: 0.6363 - val_loss: 0.8823 - val_accuracy: 0.6925\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9825 - accuracy: 0.6425 - val_loss: 0.8761 - val_accuracy: 0.6900\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - 17s 42ms/step - loss: 0.9855 - accuracy: 0.6256 - val_loss: 0.8702 - val_accuracy: 0.7025\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9647 - accuracy: 0.6425 - val_loss: 0.8602 - val_accuracy: 0.6925\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9582 - accuracy: 0.6544 - val_loss: 0.8553 - val_accuracy: 0.7050\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9652 - accuracy: 0.6494 - val_loss: 0.8500 - val_accuracy: 0.7100\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9511 - accuracy: 0.6531 - val_loss: 0.8436 - val_accuracy: 0.7125\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9362 - accuracy: 0.6687 - val_loss: 0.8406 - val_accuracy: 0.7075\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9414 - accuracy: 0.6637 - val_loss: 0.8318 - val_accuracy: 0.7150\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9298 - accuracy: 0.6606 - val_loss: 0.8244 - val_accuracy: 0.7225\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9339 - accuracy: 0.6562 - val_loss: 0.8208 - val_accuracy: 0.7300\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9385 - accuracy: 0.6488 - val_loss: 0.8135 - val_accuracy: 0.7400\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9171 - accuracy: 0.6706 - val_loss: 0.8116 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 0.9096 - accuracy: 0.6806 - val_loss: 0.8048 - val_accuracy: 0.7425\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9066 - accuracy: 0.6725 - val_loss: 0.7996 - val_accuracy: 0.7425\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.9102 - accuracy: 0.6744 - val_loss: 0.7961 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.9039 - accuracy: 0.6731 - val_loss: 0.7911 - val_accuracy: 0.7525\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8948 - accuracy: 0.6881 - val_loss: 0.7842 - val_accuracy: 0.7475\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8840 - accuracy: 0.6938 - val_loss: 0.7824 - val_accuracy: 0.7650\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8773 - accuracy: 0.6994 - val_loss: 0.7769 - val_accuracy: 0.7600\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8784 - accuracy: 0.6825 - val_loss: 0.7690 - val_accuracy: 0.7650\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8707 - accuracy: 0.6988 - val_loss: 0.7688 - val_accuracy: 0.7675\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8670 - accuracy: 0.7025 - val_loss: 0.7640 - val_accuracy: 0.7650\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 0.8746 - accuracy: 0.6862 - val_loss: 0.7569 - val_accuracy: 0.7725\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8619 - accuracy: 0.6938 - val_loss: 0.7537 - val_accuracy: 0.7700\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8648 - accuracy: 0.6913 - val_loss: 0.7507 - val_accuracy: 0.7750\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8519 - accuracy: 0.7000 - val_loss: 0.7467 - val_accuracy: 0.7775\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8549 - accuracy: 0.6938 - val_loss: 0.7397 - val_accuracy: 0.7775\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8417 - accuracy: 0.7050 - val_loss: 0.7335 - val_accuracy: 0.7825\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8440 - accuracy: 0.7038 - val_loss: 0.7306 - val_accuracy: 0.7875\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8378 - accuracy: 0.7088 - val_loss: 0.7258 - val_accuracy: 0.7850\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8344 - accuracy: 0.7169 - val_loss: 0.7246 - val_accuracy: 0.7875\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8227 - accuracy: 0.7256 - val_loss: 0.7190 - val_accuracy: 0.7950\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.8221 - accuracy: 0.7131 - val_loss: 0.7166 - val_accuracy: 0.7975\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 0.8166 - accuracy: 0.7219 - val_loss: 0.7144 - val_accuracy: 0.7925\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.8175 - accuracy: 0.7219 - val_loss: 0.7090 - val_accuracy: 0.7950\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.8152 - accuracy: 0.7200 - val_loss: 0.7058 - val_accuracy: 0.7950\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.8050 - accuracy: 0.7275 - val_loss: 0.7013 - val_accuracy: 0.7950\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8066 - accuracy: 0.7269 - val_loss: 0.6946 - val_accuracy: 0.7975\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7991 - accuracy: 0.7287 - val_loss: 0.6969 - val_accuracy: 0.8025\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7936 - accuracy: 0.7331 - val_loss: 0.6941 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7869 - accuracy: 0.7294 - val_loss: 0.6892 - val_accuracy: 0.7950\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7964 - accuracy: 0.7269 - val_loss: 0.6858 - val_accuracy: 0.7975\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7906 - accuracy: 0.7262 - val_loss: 0.6851 - val_accuracy: 0.7975\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7881 - accuracy: 0.7319 - val_loss: 0.6786 - val_accuracy: 0.8025\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 0.7872 - accuracy: 0.7337 - val_loss: 0.6768 - val_accuracy: 0.7975\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7761 - accuracy: 0.7406 - val_loss: 0.6723 - val_accuracy: 0.8075\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7772 - accuracy: 0.7362 - val_loss: 0.6674 - val_accuracy: 0.8050\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7827 - accuracy: 0.7244 - val_loss: 0.6664 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7670 - accuracy: 0.7331 - val_loss: 0.6616 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7616 - accuracy: 0.7425 - val_loss: 0.6589 - val_accuracy: 0.8050\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.7647 - accuracy: 0.7312 - val_loss: 0.6550 - val_accuracy: 0.8025\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7719 - accuracy: 0.7306 - val_loss: 0.6540 - val_accuracy: 0.8075\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7602 - accuracy: 0.7306 - val_loss: 0.6499 - val_accuracy: 0.8100\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7500 - accuracy: 0.7437 - val_loss: 0.6458 - val_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - 16s 41ms/step - loss: 0.7468 - accuracy: 0.7613 - val_loss: 0.6447 - val_accuracy: 0.8050\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7464 - accuracy: 0.7487 - val_loss: 0.6421 - val_accuracy: 0.8075\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7528 - accuracy: 0.7444 - val_loss: 0.6378 - val_accuracy: 0.8125\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7434 - accuracy: 0.7444 - val_loss: 0.6380 - val_accuracy: 0.8100\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7262 - accuracy: 0.7550 - val_loss: 0.6366 - val_accuracy: 0.8100\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7350 - accuracy: 0.7563 - val_loss: 0.6353 - val_accuracy: 0.8150\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7321 - accuracy: 0.7669 - val_loss: 0.6309 - val_accuracy: 0.8175\n",
            "Epoch 96/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7327 - accuracy: 0.7556 - val_loss: 0.6247 - val_accuracy: 0.8175\n",
            "Epoch 97/100\n",
            "400/400 [==============================] - 16s 39ms/step - loss: 0.7086 - accuracy: 0.7731 - val_loss: 0.6237 - val_accuracy: 0.8250\n",
            "Epoch 98/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7188 - accuracy: 0.7631 - val_loss: 0.6224 - val_accuracy: 0.8200\n",
            "Epoch 99/100\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.7066 - accuracy: 0.7731 - val_loss: 0.6160 - val_accuracy: 0.8150\n",
            "Epoch 100/100\n",
            "400/400 [==============================] - 17s 43ms/step - loss: 0.7061 - accuracy: 0.7588 - val_loss: 0.6143 - val_accuracy: 0.8175\n",
            "CPU times: user 30min 27s, sys: 1min 28s, total: 31min 55s\n",
            "Wall time: 27min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "xWl_7y366xwa",
        "outputId": "fa68fe2e-ad9f-4eae-9246-e85cdab7dfdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyaco8PX6xwa",
        "outputId": "871bfb5b-33cb-4a36-e5c8-a75321452dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model400.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights400.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model400.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvfgL7s6xwa",
        "outputId": "9d703eec-d1c1-43aa-c4b1-09dfe9b1f9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OawPRgGx6xwa"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model400.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXO9OH8I6xwa",
        "outputId": "23a897c3-bf82-4a5a-8167-a087a561ded8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 832ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI5Wh3Zf6xwa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADJHYNuPqN5g"
      },
      "source": [
        "#5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr-3S9EUqN5l",
        "outputId": "826b8bf7-1219-41b5-8dd5-93353ade16e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  5e-07\n"
          ]
        }
      ],
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 500\n",
        "batch_size = 8\n",
        "num_of_classes = 4\n",
        "num_of_train_samples = 1600\n",
        "num_of_valid_samples = 400\n",
        "\n",
        "lr = 1e-3\n",
        "if epochs > 180:\n",
        "    lr *= 0.5e-3\n",
        "elif epochs > 160:\n",
        "    lr *= 1e-3\n",
        "elif epochs > 120:\n",
        "    lr *= 1e-2\n",
        "elif epochs > 80:\n",
        "    lr *= 1e-1\n",
        "print('Learning rate: ', lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalisasi"
      ],
      "metadata": {
        "id": "b5UJot53KOiU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfhmZHsRqN5m",
        "outputId": "0951a3b3-b4d7-40a1-ca3d-44fb2b2cb872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=train_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)\n",
        "\n",
        "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory=valid_directory, \n",
        "                                                                         class_mode='categorical', \n",
        "                                                                         batch_size=batch_size,\n",
        "                                                                         target_size=(img_rows, img_cols),\n",
        "                                                                         color_mode=\"rgb\",\n",
        "                                                                         shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9w0okseqN5m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def getResNet50Model(lastFourTrainable=False):\n",
        "  resnet_model = ResNet50(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "  \n",
        "  # Make all layers non-trainable\n",
        "  for layer in resnet_model.layers[:]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Add fully connected layer which have 1024 neuron to ResNet-50 model\n",
        "  output = resnet_model.get_layer('avg_pool').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  resnet_model = Model(resnet_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    resnet_model.get_layer('conv5_block3_2_bn').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_conv').trainable = True\n",
        "    resnet_model.get_layer('conv5_block3_3_bn').trainable = True\n",
        "    resnet_model.get_layer('new_fc').trainable = True\n",
        "  \n",
        "  # Compile ResNet-50 model\n",
        "  resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  resnet_model.summary()\n",
        "\n",
        "\n",
        "  return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XetPQmgqN5m",
        "outputId": "3642e7ff-2800-4939-d9d7-b7f4e2828c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 2s 0us/step\n",
            "102981632/102967424 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " new_flatten (Flatten)          (None, 2048)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " new_fc (Dense)                 (None, 1024)         2098176     ['new_flatten[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            4100        ['new_fc[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,689,988\n",
            "Trainable params: 3,158,020\n",
            "Non-trainable params: 22,531,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get ResNet-50 Model with lastFourTrainable=False\n",
        "resnet_model = getResNet50Model(lastFourTrainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl7hJVquqN5m",
        "outputId": "0cb03ed5-d7ac-4356-8637-03e61036644c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "200/200 [==============================] - 1396s 7s/step - loss: 1.5151 - accuracy: 0.2037 - val_loss: 1.4943 - val_accuracy: 0.2475\n",
            "Epoch 2/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.3918 - accuracy: 0.2950 - val_loss: 1.3644 - val_accuracy: 0.3525\n",
            "Epoch 3/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.3268 - accuracy: 0.4131 - val_loss: 1.2954 - val_accuracy: 0.4475\n",
            "Epoch 4/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.2923 - accuracy: 0.4431 - val_loss: 1.2634 - val_accuracy: 0.4775\n",
            "Epoch 5/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 1.2748 - accuracy: 0.4406 - val_loss: 1.2411 - val_accuracy: 0.4800\n",
            "Epoch 6/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.2549 - accuracy: 0.4613 - val_loss: 1.2225 - val_accuracy: 0.4900\n",
            "Epoch 7/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.2352 - accuracy: 0.4650 - val_loss: 1.2056 - val_accuracy: 0.5075\n",
            "Epoch 8/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.2204 - accuracy: 0.4969 - val_loss: 1.1902 - val_accuracy: 0.5150\n",
            "Epoch 9/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.2191 - accuracy: 0.4888 - val_loss: 1.1768 - val_accuracy: 0.5275\n",
            "Epoch 10/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.2056 - accuracy: 0.4906 - val_loss: 1.1626 - val_accuracy: 0.5325\n",
            "Epoch 11/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.1927 - accuracy: 0.5081 - val_loss: 1.1512 - val_accuracy: 0.5375\n",
            "Epoch 12/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1780 - accuracy: 0.5056 - val_loss: 1.1392 - val_accuracy: 0.5525\n",
            "Epoch 13/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1667 - accuracy: 0.5275 - val_loss: 1.1279 - val_accuracy: 0.5625\n",
            "Epoch 14/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 1.1674 - accuracy: 0.5069 - val_loss: 1.1171 - val_accuracy: 0.5675\n",
            "Epoch 15/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1550 - accuracy: 0.5150 - val_loss: 1.1076 - val_accuracy: 0.5650\n",
            "Epoch 16/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.1485 - accuracy: 0.5231 - val_loss: 1.0964 - val_accuracy: 0.5675\n",
            "Epoch 17/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1363 - accuracy: 0.5294 - val_loss: 1.0875 - val_accuracy: 0.5775\n",
            "Epoch 18/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1225 - accuracy: 0.5437 - val_loss: 1.0771 - val_accuracy: 0.5775\n",
            "Epoch 19/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1191 - accuracy: 0.5369 - val_loss: 1.0686 - val_accuracy: 0.5875\n",
            "Epoch 20/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.1150 - accuracy: 0.5425 - val_loss: 1.0595 - val_accuracy: 0.5875\n",
            "Epoch 21/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.1022 - accuracy: 0.5494 - val_loss: 1.0499 - val_accuracy: 0.5850\n",
            "Epoch 22/500\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 1.0967 - accuracy: 0.5675 - val_loss: 1.0429 - val_accuracy: 0.5900\n",
            "Epoch 23/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0870 - accuracy: 0.5537 - val_loss: 1.0320 - val_accuracy: 0.5950\n",
            "Epoch 24/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0834 - accuracy: 0.5606 - val_loss: 1.0260 - val_accuracy: 0.6000\n",
            "Epoch 25/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 1.0717 - accuracy: 0.5719 - val_loss: 1.0175 - val_accuracy: 0.6075\n",
            "Epoch 26/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0691 - accuracy: 0.5844 - val_loss: 1.0088 - val_accuracy: 0.6125\n",
            "Epoch 27/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0605 - accuracy: 0.5806 - val_loss: 1.0002 - val_accuracy: 0.6250\n",
            "Epoch 28/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.0498 - accuracy: 0.5938 - val_loss: 0.9936 - val_accuracy: 0.6350\n",
            "Epoch 29/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.0469 - accuracy: 0.6025 - val_loss: 0.9858 - val_accuracy: 0.6375\n",
            "Epoch 30/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.0370 - accuracy: 0.5850 - val_loss: 0.9785 - val_accuracy: 0.6425\n",
            "Epoch 31/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0320 - accuracy: 0.6012 - val_loss: 0.9700 - val_accuracy: 0.6550\n",
            "Epoch 32/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0273 - accuracy: 0.5981 - val_loss: 0.9636 - val_accuracy: 0.6525\n",
            "Epoch 33/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.0204 - accuracy: 0.6050 - val_loss: 0.9560 - val_accuracy: 0.6650\n",
            "Epoch 34/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.0081 - accuracy: 0.6162 - val_loss: 0.9498 - val_accuracy: 0.6600\n",
            "Epoch 35/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.0085 - accuracy: 0.6150 - val_loss: 0.9414 - val_accuracy: 0.6625\n",
            "Epoch 36/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9965 - accuracy: 0.6150 - val_loss: 0.9367 - val_accuracy: 0.6750\n",
            "Epoch 37/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9972 - accuracy: 0.6250 - val_loss: 0.9309 - val_accuracy: 0.6750\n",
            "Epoch 38/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.9810 - accuracy: 0.6356 - val_loss: 0.9232 - val_accuracy: 0.6825\n",
            "Epoch 39/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9781 - accuracy: 0.6381 - val_loss: 0.9167 - val_accuracy: 0.6850\n",
            "Epoch 40/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9803 - accuracy: 0.6269 - val_loss: 0.9113 - val_accuracy: 0.6925\n",
            "Epoch 41/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9649 - accuracy: 0.6450 - val_loss: 0.9038 - val_accuracy: 0.6950\n",
            "Epoch 42/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9637 - accuracy: 0.6469 - val_loss: 0.8995 - val_accuracy: 0.6975\n",
            "Epoch 43/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9564 - accuracy: 0.6662 - val_loss: 0.8934 - val_accuracy: 0.6950\n",
            "Epoch 44/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.9587 - accuracy: 0.6463 - val_loss: 0.8870 - val_accuracy: 0.7050\n",
            "Epoch 45/500\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.9432 - accuracy: 0.6625 - val_loss: 0.8807 - val_accuracy: 0.7100\n",
            "Epoch 46/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9443 - accuracy: 0.6519 - val_loss: 0.8757 - val_accuracy: 0.7150\n",
            "Epoch 47/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9315 - accuracy: 0.6681 - val_loss: 0.8719 - val_accuracy: 0.7125\n",
            "Epoch 48/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9339 - accuracy: 0.6687 - val_loss: 0.8657 - val_accuracy: 0.7150\n",
            "Epoch 49/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.9359 - accuracy: 0.6669 - val_loss: 0.8616 - val_accuracy: 0.7225\n",
            "Epoch 50/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9193 - accuracy: 0.6687 - val_loss: 0.8574 - val_accuracy: 0.7275\n",
            "Epoch 51/500\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.9136 - accuracy: 0.6631 - val_loss: 0.8500 - val_accuracy: 0.7275\n",
            "Epoch 52/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9119 - accuracy: 0.6694 - val_loss: 0.8450 - val_accuracy: 0.7325\n",
            "Epoch 53/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.9051 - accuracy: 0.6694 - val_loss: 0.8414 - val_accuracy: 0.7325\n",
            "Epoch 54/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.9012 - accuracy: 0.6825 - val_loss: 0.8375 - val_accuracy: 0.7350\n",
            "Epoch 55/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8912 - accuracy: 0.6919 - val_loss: 0.8313 - val_accuracy: 0.7475\n",
            "Epoch 56/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8919 - accuracy: 0.6975 - val_loss: 0.8264 - val_accuracy: 0.7525\n",
            "Epoch 57/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8908 - accuracy: 0.6994 - val_loss: 0.8229 - val_accuracy: 0.7475\n",
            "Epoch 58/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8759 - accuracy: 0.6988 - val_loss: 0.8177 - val_accuracy: 0.7525\n",
            "Epoch 59/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.8756 - accuracy: 0.7044 - val_loss: 0.8147 - val_accuracy: 0.7475\n",
            "Epoch 60/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8705 - accuracy: 0.7063 - val_loss: 0.8084 - val_accuracy: 0.7500\n",
            "Epoch 61/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.8714 - accuracy: 0.6994 - val_loss: 0.8044 - val_accuracy: 0.7525\n",
            "Epoch 62/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8636 - accuracy: 0.7150 - val_loss: 0.7993 - val_accuracy: 0.7525\n",
            "Epoch 63/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8613 - accuracy: 0.7119 - val_loss: 0.7968 - val_accuracy: 0.7550\n",
            "Epoch 64/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.8584 - accuracy: 0.7006 - val_loss: 0.7922 - val_accuracy: 0.7625\n",
            "Epoch 65/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8497 - accuracy: 0.7188 - val_loss: 0.7871 - val_accuracy: 0.7575\n",
            "Epoch 66/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8511 - accuracy: 0.7100 - val_loss: 0.7846 - val_accuracy: 0.7625\n",
            "Epoch 67/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8384 - accuracy: 0.7231 - val_loss: 0.7793 - val_accuracy: 0.7675\n",
            "Epoch 68/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.8507 - accuracy: 0.7088 - val_loss: 0.7757 - val_accuracy: 0.7700\n",
            "Epoch 69/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.8311 - accuracy: 0.7231 - val_loss: 0.7727 - val_accuracy: 0.7700\n",
            "Epoch 70/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8268 - accuracy: 0.7244 - val_loss: 0.7677 - val_accuracy: 0.7700\n",
            "Epoch 71/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8351 - accuracy: 0.7212 - val_loss: 0.7648 - val_accuracy: 0.7750\n",
            "Epoch 72/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8294 - accuracy: 0.7212 - val_loss: 0.7601 - val_accuracy: 0.7825\n",
            "Epoch 73/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8295 - accuracy: 0.7294 - val_loss: 0.7570 - val_accuracy: 0.7825\n",
            "Epoch 74/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8184 - accuracy: 0.7319 - val_loss: 0.7533 - val_accuracy: 0.7800\n",
            "Epoch 75/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8039 - accuracy: 0.7356 - val_loss: 0.7501 - val_accuracy: 0.7850\n",
            "Epoch 76/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8120 - accuracy: 0.7356 - val_loss: 0.7465 - val_accuracy: 0.7900\n",
            "Epoch 77/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.8137 - accuracy: 0.7262 - val_loss: 0.7413 - val_accuracy: 0.7925\n",
            "Epoch 78/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.8006 - accuracy: 0.7356 - val_loss: 0.7385 - val_accuracy: 0.7900\n",
            "Epoch 79/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.8008 - accuracy: 0.7456 - val_loss: 0.7357 - val_accuracy: 0.7950\n",
            "Epoch 80/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7945 - accuracy: 0.7362 - val_loss: 0.7336 - val_accuracy: 0.7950\n",
            "Epoch 81/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7967 - accuracy: 0.7406 - val_loss: 0.7284 - val_accuracy: 0.7925\n",
            "Epoch 82/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7934 - accuracy: 0.7412 - val_loss: 0.7218 - val_accuracy: 0.7925\n",
            "Epoch 83/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.7914 - accuracy: 0.7437 - val_loss: 0.7224 - val_accuracy: 0.7950\n",
            "Epoch 84/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7784 - accuracy: 0.7569 - val_loss: 0.7179 - val_accuracy: 0.7950\n",
            "Epoch 85/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7911 - accuracy: 0.7350 - val_loss: 0.7147 - val_accuracy: 0.7975\n",
            "Epoch 86/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7785 - accuracy: 0.7406 - val_loss: 0.7122 - val_accuracy: 0.7975\n",
            "Epoch 87/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7754 - accuracy: 0.7494 - val_loss: 0.7084 - val_accuracy: 0.7950\n",
            "Epoch 88/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.7708 - accuracy: 0.7475 - val_loss: 0.7061 - val_accuracy: 0.7950\n",
            "Epoch 89/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.7557 - accuracy: 0.7638 - val_loss: 0.7030 - val_accuracy: 0.7950\n",
            "Epoch 90/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7665 - accuracy: 0.7513 - val_loss: 0.7005 - val_accuracy: 0.7975\n",
            "Epoch 91/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7611 - accuracy: 0.7638 - val_loss: 0.6978 - val_accuracy: 0.7975\n",
            "Epoch 92/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7583 - accuracy: 0.7644 - val_loss: 0.6936 - val_accuracy: 0.8000\n",
            "Epoch 93/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.7539 - accuracy: 0.7606 - val_loss: 0.6922 - val_accuracy: 0.8050\n",
            "Epoch 94/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7372 - accuracy: 0.7613 - val_loss: 0.6885 - val_accuracy: 0.8025\n",
            "Epoch 95/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7498 - accuracy: 0.7613 - val_loss: 0.6879 - val_accuracy: 0.8025\n",
            "Epoch 96/500\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.7560 - accuracy: 0.7519 - val_loss: 0.6842 - val_accuracy: 0.8025\n",
            "Epoch 97/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7450 - accuracy: 0.7644 - val_loss: 0.6809 - val_accuracy: 0.8025\n",
            "Epoch 98/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.7348 - accuracy: 0.7700 - val_loss: 0.6779 - val_accuracy: 0.8075\n",
            "Epoch 99/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.7399 - accuracy: 0.7625 - val_loss: 0.6764 - val_accuracy: 0.8050\n",
            "Epoch 100/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7325 - accuracy: 0.7606 - val_loss: 0.6737 - val_accuracy: 0.8100\n",
            "Epoch 101/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7315 - accuracy: 0.7744 - val_loss: 0.6693 - val_accuracy: 0.8075\n",
            "Epoch 102/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7284 - accuracy: 0.7706 - val_loss: 0.6682 - val_accuracy: 0.8100\n",
            "Epoch 103/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.7283 - accuracy: 0.7750 - val_loss: 0.6662 - val_accuracy: 0.8125\n",
            "Epoch 104/500\n",
            "200/200 [==============================] - 18s 89ms/step - loss: 0.7139 - accuracy: 0.7844 - val_loss: 0.6635 - val_accuracy: 0.8075\n",
            "Epoch 105/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7177 - accuracy: 0.7744 - val_loss: 0.6608 - val_accuracy: 0.8100\n",
            "Epoch 106/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7167 - accuracy: 0.7800 - val_loss: 0.6581 - val_accuracy: 0.8100\n",
            "Epoch 107/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7018 - accuracy: 0.7919 - val_loss: 0.6552 - val_accuracy: 0.8100\n",
            "Epoch 108/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.7128 - accuracy: 0.7700 - val_loss: 0.6541 - val_accuracy: 0.8100\n",
            "Epoch 109/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6941 - accuracy: 0.7819 - val_loss: 0.6504 - val_accuracy: 0.8100\n",
            "Epoch 110/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7014 - accuracy: 0.7794 - val_loss: 0.6489 - val_accuracy: 0.8125\n",
            "Epoch 111/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.7070 - accuracy: 0.7812 - val_loss: 0.6447 - val_accuracy: 0.8100\n",
            "Epoch 112/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6952 - accuracy: 0.7831 - val_loss: 0.6440 - val_accuracy: 0.8125\n",
            "Epoch 113/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.6864 - accuracy: 0.7894 - val_loss: 0.6400 - val_accuracy: 0.8150\n",
            "Epoch 114/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.6914 - accuracy: 0.7862 - val_loss: 0.6376 - val_accuracy: 0.8125\n",
            "Epoch 115/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6792 - accuracy: 0.7956 - val_loss: 0.6359 - val_accuracy: 0.8175\n",
            "Epoch 116/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6956 - accuracy: 0.7781 - val_loss: 0.6338 - val_accuracy: 0.8150\n",
            "Epoch 117/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6897 - accuracy: 0.7931 - val_loss: 0.6304 - val_accuracy: 0.8125\n",
            "Epoch 118/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6810 - accuracy: 0.7900 - val_loss: 0.6279 - val_accuracy: 0.8150\n",
            "Epoch 119/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6839 - accuracy: 0.7875 - val_loss: 0.6269 - val_accuracy: 0.8150\n",
            "Epoch 120/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6822 - accuracy: 0.7844 - val_loss: 0.6245 - val_accuracy: 0.8175\n",
            "Epoch 121/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6744 - accuracy: 0.7944 - val_loss: 0.6208 - val_accuracy: 0.8150\n",
            "Epoch 122/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6809 - accuracy: 0.7875 - val_loss: 0.6184 - val_accuracy: 0.8175\n",
            "Epoch 123/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.6702 - accuracy: 0.7975 - val_loss: 0.6177 - val_accuracy: 0.8175\n",
            "Epoch 124/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.6612 - accuracy: 0.8000 - val_loss: 0.6160 - val_accuracy: 0.8200\n",
            "Epoch 125/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6688 - accuracy: 0.7900 - val_loss: 0.6134 - val_accuracy: 0.8225\n",
            "Epoch 126/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6613 - accuracy: 0.8012 - val_loss: 0.6115 - val_accuracy: 0.8225\n",
            "Epoch 127/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6531 - accuracy: 0.7912 - val_loss: 0.6100 - val_accuracy: 0.8200\n",
            "Epoch 128/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6588 - accuracy: 0.8012 - val_loss: 0.6083 - val_accuracy: 0.8225\n",
            "Epoch 129/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6610 - accuracy: 0.7875 - val_loss: 0.6062 - val_accuracy: 0.8250\n",
            "Epoch 130/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6588 - accuracy: 0.8025 - val_loss: 0.6031 - val_accuracy: 0.8275\n",
            "Epoch 131/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6696 - accuracy: 0.7881 - val_loss: 0.6017 - val_accuracy: 0.8225\n",
            "Epoch 132/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6582 - accuracy: 0.7844 - val_loss: 0.5991 - val_accuracy: 0.8250\n",
            "Epoch 133/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6499 - accuracy: 0.8012 - val_loss: 0.5977 - val_accuracy: 0.8300\n",
            "Epoch 134/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6541 - accuracy: 0.7987 - val_loss: 0.5962 - val_accuracy: 0.8300\n",
            "Epoch 135/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6364 - accuracy: 0.8156 - val_loss: 0.5944 - val_accuracy: 0.8275\n",
            "Epoch 136/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6475 - accuracy: 0.7912 - val_loss: 0.5908 - val_accuracy: 0.8300\n",
            "Epoch 137/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6315 - accuracy: 0.8125 - val_loss: 0.5913 - val_accuracy: 0.8300\n",
            "Epoch 138/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.6391 - accuracy: 0.8062 - val_loss: 0.5891 - val_accuracy: 0.8300\n",
            "Epoch 139/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6255 - accuracy: 0.8138 - val_loss: 0.5848 - val_accuracy: 0.8300\n",
            "Epoch 140/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6385 - accuracy: 0.7962 - val_loss: 0.5834 - val_accuracy: 0.8300\n",
            "Epoch 141/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6356 - accuracy: 0.8100 - val_loss: 0.5819 - val_accuracy: 0.8350\n",
            "Epoch 142/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6308 - accuracy: 0.8056 - val_loss: 0.5797 - val_accuracy: 0.8350\n",
            "Epoch 143/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6304 - accuracy: 0.8075 - val_loss: 0.5788 - val_accuracy: 0.8325\n",
            "Epoch 144/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6260 - accuracy: 0.8144 - val_loss: 0.5759 - val_accuracy: 0.8325\n",
            "Epoch 145/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6197 - accuracy: 0.8125 - val_loss: 0.5736 - val_accuracy: 0.8350\n",
            "Epoch 146/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6257 - accuracy: 0.8081 - val_loss: 0.5726 - val_accuracy: 0.8350\n",
            "Epoch 147/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6134 - accuracy: 0.8156 - val_loss: 0.5697 - val_accuracy: 0.8325\n",
            "Epoch 148/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6147 - accuracy: 0.8225 - val_loss: 0.5707 - val_accuracy: 0.8375\n",
            "Epoch 149/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.6211 - accuracy: 0.8144 - val_loss: 0.5668 - val_accuracy: 0.8375\n",
            "Epoch 150/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6110 - accuracy: 0.8150 - val_loss: 0.5648 - val_accuracy: 0.8400\n",
            "Epoch 151/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6137 - accuracy: 0.8100 - val_loss: 0.5646 - val_accuracy: 0.8375\n",
            "Epoch 152/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.6130 - accuracy: 0.8119 - val_loss: 0.5624 - val_accuracy: 0.8375\n",
            "Epoch 153/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6031 - accuracy: 0.8231 - val_loss: 0.5621 - val_accuracy: 0.8450\n",
            "Epoch 154/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.6088 - accuracy: 0.8031 - val_loss: 0.5579 - val_accuracy: 0.8450\n",
            "Epoch 155/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6018 - accuracy: 0.8244 - val_loss: 0.5583 - val_accuracy: 0.8375\n",
            "Epoch 156/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5991 - accuracy: 0.8138 - val_loss: 0.5555 - val_accuracy: 0.8400\n",
            "Epoch 157/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.6120 - accuracy: 0.8119 - val_loss: 0.5544 - val_accuracy: 0.8400\n",
            "Epoch 158/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6078 - accuracy: 0.8106 - val_loss: 0.5537 - val_accuracy: 0.8400\n",
            "Epoch 159/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.5929 - accuracy: 0.8231 - val_loss: 0.5512 - val_accuracy: 0.8450\n",
            "Epoch 160/500\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 0.5952 - accuracy: 0.8163 - val_loss: 0.5496 - val_accuracy: 0.8425\n",
            "Epoch 161/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5800 - accuracy: 0.8294 - val_loss: 0.5474 - val_accuracy: 0.8400\n",
            "Epoch 162/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5915 - accuracy: 0.8119 - val_loss: 0.5459 - val_accuracy: 0.8475\n",
            "Epoch 163/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5824 - accuracy: 0.8300 - val_loss: 0.5447 - val_accuracy: 0.8450\n",
            "Epoch 164/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.6014 - accuracy: 0.8087 - val_loss: 0.5423 - val_accuracy: 0.8450\n",
            "Epoch 165/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5758 - accuracy: 0.8256 - val_loss: 0.5405 - val_accuracy: 0.8475\n",
            "Epoch 166/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5731 - accuracy: 0.8200 - val_loss: 0.5388 - val_accuracy: 0.8475\n",
            "Epoch 167/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.5775 - accuracy: 0.8325 - val_loss: 0.5371 - val_accuracy: 0.8450\n",
            "Epoch 168/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5760 - accuracy: 0.8306 - val_loss: 0.5374 - val_accuracy: 0.8475\n",
            "Epoch 169/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.5732 - accuracy: 0.8331 - val_loss: 0.5358 - val_accuracy: 0.8450\n",
            "Epoch 170/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5633 - accuracy: 0.8444 - val_loss: 0.5330 - val_accuracy: 0.8525\n",
            "Epoch 171/500\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.5746 - accuracy: 0.8281 - val_loss: 0.5323 - val_accuracy: 0.8525\n",
            "Epoch 172/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5685 - accuracy: 0.8306 - val_loss: 0.5289 - val_accuracy: 0.8550\n",
            "Epoch 173/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5722 - accuracy: 0.8331 - val_loss: 0.5277 - val_accuracy: 0.8575\n",
            "Epoch 174/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.5718 - accuracy: 0.8250 - val_loss: 0.5264 - val_accuracy: 0.8525\n",
            "Epoch 175/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5692 - accuracy: 0.8250 - val_loss: 0.5245 - val_accuracy: 0.8550\n",
            "Epoch 176/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5611 - accuracy: 0.8300 - val_loss: 0.5245 - val_accuracy: 0.8525\n",
            "Epoch 177/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5754 - accuracy: 0.8281 - val_loss: 0.5243 - val_accuracy: 0.8550\n",
            "Epoch 178/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5767 - accuracy: 0.8200 - val_loss: 0.5210 - val_accuracy: 0.8575\n",
            "Epoch 179/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.5488 - accuracy: 0.8438 - val_loss: 0.5198 - val_accuracy: 0.8550\n",
            "Epoch 180/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5540 - accuracy: 0.8363 - val_loss: 0.5188 - val_accuracy: 0.8550\n",
            "Epoch 181/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5651 - accuracy: 0.8294 - val_loss: 0.5151 - val_accuracy: 0.8600\n",
            "Epoch 182/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5630 - accuracy: 0.8313 - val_loss: 0.5148 - val_accuracy: 0.8525\n",
            "Epoch 183/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5470 - accuracy: 0.8281 - val_loss: 0.5145 - val_accuracy: 0.8575\n",
            "Epoch 184/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5488 - accuracy: 0.8344 - val_loss: 0.5118 - val_accuracy: 0.8575\n",
            "Epoch 185/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.5455 - accuracy: 0.8363 - val_loss: 0.5113 - val_accuracy: 0.8600\n",
            "Epoch 186/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5515 - accuracy: 0.8381 - val_loss: 0.5100 - val_accuracy: 0.8600\n",
            "Epoch 187/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5503 - accuracy: 0.8388 - val_loss: 0.5084 - val_accuracy: 0.8550\n",
            "Epoch 188/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5473 - accuracy: 0.8400 - val_loss: 0.5064 - val_accuracy: 0.8550\n",
            "Epoch 189/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5592 - accuracy: 0.8319 - val_loss: 0.5057 - val_accuracy: 0.8575\n",
            "Epoch 190/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.5432 - accuracy: 0.8419 - val_loss: 0.5028 - val_accuracy: 0.8550\n",
            "Epoch 191/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5305 - accuracy: 0.8413 - val_loss: 0.5011 - val_accuracy: 0.8575\n",
            "Epoch 192/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5368 - accuracy: 0.8400 - val_loss: 0.5014 - val_accuracy: 0.8550\n",
            "Epoch 193/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5416 - accuracy: 0.8425 - val_loss: 0.4999 - val_accuracy: 0.8600\n",
            "Epoch 194/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5390 - accuracy: 0.8375 - val_loss: 0.4978 - val_accuracy: 0.8600\n",
            "Epoch 195/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.5384 - accuracy: 0.8331 - val_loss: 0.4969 - val_accuracy: 0.8600\n",
            "Epoch 196/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5391 - accuracy: 0.8431 - val_loss: 0.4940 - val_accuracy: 0.8600\n",
            "Epoch 197/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5402 - accuracy: 0.8344 - val_loss: 0.4928 - val_accuracy: 0.8600\n",
            "Epoch 198/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5301 - accuracy: 0.8456 - val_loss: 0.4918 - val_accuracy: 0.8600\n",
            "Epoch 199/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5259 - accuracy: 0.8500 - val_loss: 0.4926 - val_accuracy: 0.8600\n",
            "Epoch 200/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.5230 - accuracy: 0.8462 - val_loss: 0.4902 - val_accuracy: 0.8600\n",
            "Epoch 201/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5154 - accuracy: 0.8537 - val_loss: 0.4896 - val_accuracy: 0.8600\n",
            "Epoch 202/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5331 - accuracy: 0.8350 - val_loss: 0.4890 - val_accuracy: 0.8575\n",
            "Epoch 203/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5181 - accuracy: 0.8525 - val_loss: 0.4875 - val_accuracy: 0.8600\n",
            "Epoch 204/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5239 - accuracy: 0.8444 - val_loss: 0.4857 - val_accuracy: 0.8600\n",
            "Epoch 205/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.5240 - accuracy: 0.8469 - val_loss: 0.4854 - val_accuracy: 0.8600\n",
            "Epoch 206/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5270 - accuracy: 0.8319 - val_loss: 0.4821 - val_accuracy: 0.8625\n",
            "Epoch 207/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5110 - accuracy: 0.8469 - val_loss: 0.4798 - val_accuracy: 0.8600\n",
            "Epoch 208/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5315 - accuracy: 0.8331 - val_loss: 0.4796 - val_accuracy: 0.8625\n",
            "Epoch 209/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5206 - accuracy: 0.8425 - val_loss: 0.4802 - val_accuracy: 0.8625\n",
            "Epoch 210/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4961 - accuracy: 0.8500 - val_loss: 0.4777 - val_accuracy: 0.8625\n",
            "Epoch 211/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.5181 - accuracy: 0.8506 - val_loss: 0.4765 - val_accuracy: 0.8625\n",
            "Epoch 212/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5073 - accuracy: 0.8494 - val_loss: 0.4739 - val_accuracy: 0.8600\n",
            "Epoch 213/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5069 - accuracy: 0.8556 - val_loss: 0.4740 - val_accuracy: 0.8600\n",
            "Epoch 214/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.5181 - accuracy: 0.8425 - val_loss: 0.4730 - val_accuracy: 0.8625\n",
            "Epoch 215/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5038 - accuracy: 0.8481 - val_loss: 0.4709 - val_accuracy: 0.8625\n",
            "Epoch 216/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.5108 - accuracy: 0.8456 - val_loss: 0.4699 - val_accuracy: 0.8625\n",
            "Epoch 217/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5034 - accuracy: 0.8413 - val_loss: 0.4689 - val_accuracy: 0.8625\n",
            "Epoch 218/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5070 - accuracy: 0.8537 - val_loss: 0.4669 - val_accuracy: 0.8650\n",
            "Epoch 219/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5021 - accuracy: 0.8481 - val_loss: 0.4664 - val_accuracy: 0.8625\n",
            "Epoch 220/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.5040 - accuracy: 0.8456 - val_loss: 0.4659 - val_accuracy: 0.8625\n",
            "Epoch 221/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.5112 - accuracy: 0.8444 - val_loss: 0.4647 - val_accuracy: 0.8625\n",
            "Epoch 222/500\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.5026 - accuracy: 0.8487 - val_loss: 0.4647 - val_accuracy: 0.8650\n",
            "Epoch 223/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4907 - accuracy: 0.8587 - val_loss: 0.4618 - val_accuracy: 0.8675\n",
            "Epoch 224/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4971 - accuracy: 0.8594 - val_loss: 0.4606 - val_accuracy: 0.8700\n",
            "Epoch 225/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4998 - accuracy: 0.8475 - val_loss: 0.4619 - val_accuracy: 0.8675\n",
            "Epoch 226/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4860 - accuracy: 0.8587 - val_loss: 0.4594 - val_accuracy: 0.8675\n",
            "Epoch 227/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4944 - accuracy: 0.8569 - val_loss: 0.4571 - val_accuracy: 0.8675\n",
            "Epoch 228/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4919 - accuracy: 0.8450 - val_loss: 0.4578 - val_accuracy: 0.8650\n",
            "Epoch 229/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4837 - accuracy: 0.8581 - val_loss: 0.4555 - val_accuracy: 0.8700\n",
            "Epoch 230/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4783 - accuracy: 0.8637 - val_loss: 0.4551 - val_accuracy: 0.8675\n",
            "Epoch 231/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4930 - accuracy: 0.8500 - val_loss: 0.4546 - val_accuracy: 0.8650\n",
            "Epoch 232/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4847 - accuracy: 0.8681 - val_loss: 0.4529 - val_accuracy: 0.8675\n",
            "Epoch 233/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4821 - accuracy: 0.8481 - val_loss: 0.4523 - val_accuracy: 0.8675\n",
            "Epoch 234/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4739 - accuracy: 0.8494 - val_loss: 0.4507 - val_accuracy: 0.8675\n",
            "Epoch 235/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4812 - accuracy: 0.8587 - val_loss: 0.4495 - val_accuracy: 0.8700\n",
            "Epoch 236/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4765 - accuracy: 0.8619 - val_loss: 0.4481 - val_accuracy: 0.8700\n",
            "Epoch 237/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4749 - accuracy: 0.8612 - val_loss: 0.4481 - val_accuracy: 0.8700\n",
            "Epoch 238/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4694 - accuracy: 0.8550 - val_loss: 0.4474 - val_accuracy: 0.8700\n",
            "Epoch 239/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4752 - accuracy: 0.8506 - val_loss: 0.4472 - val_accuracy: 0.8700\n",
            "Epoch 240/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4753 - accuracy: 0.8550 - val_loss: 0.4465 - val_accuracy: 0.8725\n",
            "Epoch 241/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4784 - accuracy: 0.8662 - val_loss: 0.4443 - val_accuracy: 0.8725\n",
            "Epoch 242/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4754 - accuracy: 0.8662 - val_loss: 0.4434 - val_accuracy: 0.8750\n",
            "Epoch 243/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4559 - accuracy: 0.8712 - val_loss: 0.4404 - val_accuracy: 0.8775\n",
            "Epoch 244/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4825 - accuracy: 0.8487 - val_loss: 0.4406 - val_accuracy: 0.8750\n",
            "Epoch 245/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4711 - accuracy: 0.8612 - val_loss: 0.4393 - val_accuracy: 0.8750\n",
            "Epoch 246/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4619 - accuracy: 0.8612 - val_loss: 0.4372 - val_accuracy: 0.8775\n",
            "Epoch 247/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4624 - accuracy: 0.8550 - val_loss: 0.4373 - val_accuracy: 0.8775\n",
            "Epoch 248/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4608 - accuracy: 0.8662 - val_loss: 0.4359 - val_accuracy: 0.8750\n",
            "Epoch 249/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4547 - accuracy: 0.8712 - val_loss: 0.4344 - val_accuracy: 0.8750\n",
            "Epoch 250/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4612 - accuracy: 0.8731 - val_loss: 0.4349 - val_accuracy: 0.8825\n",
            "Epoch 251/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4575 - accuracy: 0.8644 - val_loss: 0.4346 - val_accuracy: 0.8775\n",
            "Epoch 252/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4635 - accuracy: 0.8650 - val_loss: 0.4330 - val_accuracy: 0.8750\n",
            "Epoch 253/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4653 - accuracy: 0.8631 - val_loss: 0.4324 - val_accuracy: 0.8725\n",
            "Epoch 254/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.4566 - accuracy: 0.8650 - val_loss: 0.4304 - val_accuracy: 0.8800\n",
            "Epoch 255/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4388 - accuracy: 0.8744 - val_loss: 0.4294 - val_accuracy: 0.8750\n",
            "Epoch 256/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4580 - accuracy: 0.8562 - val_loss: 0.4290 - val_accuracy: 0.8825\n",
            "Epoch 257/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4471 - accuracy: 0.8712 - val_loss: 0.4273 - val_accuracy: 0.8825\n",
            "Epoch 258/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.4487 - accuracy: 0.8562 - val_loss: 0.4275 - val_accuracy: 0.8800\n",
            "Epoch 259/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4507 - accuracy: 0.8625 - val_loss: 0.4254 - val_accuracy: 0.8825\n",
            "Epoch 260/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4372 - accuracy: 0.8756 - val_loss: 0.4254 - val_accuracy: 0.8850\n",
            "Epoch 261/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4341 - accuracy: 0.8719 - val_loss: 0.4229 - val_accuracy: 0.8825\n",
            "Epoch 262/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4439 - accuracy: 0.8619 - val_loss: 0.4231 - val_accuracy: 0.8825\n",
            "Epoch 263/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.4376 - accuracy: 0.8813 - val_loss: 0.4221 - val_accuracy: 0.8850\n",
            "Epoch 264/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4405 - accuracy: 0.8737 - val_loss: 0.4209 - val_accuracy: 0.8800\n",
            "Epoch 265/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4361 - accuracy: 0.8788 - val_loss: 0.4199 - val_accuracy: 0.8800\n",
            "Epoch 266/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4340 - accuracy: 0.8806 - val_loss: 0.4175 - val_accuracy: 0.8825\n",
            "Epoch 267/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4451 - accuracy: 0.8681 - val_loss: 0.4181 - val_accuracy: 0.8825\n",
            "Epoch 268/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4305 - accuracy: 0.8769 - val_loss: 0.4170 - val_accuracy: 0.8800\n",
            "Epoch 269/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.4416 - accuracy: 0.8706 - val_loss: 0.4156 - val_accuracy: 0.8875\n",
            "Epoch 270/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4315 - accuracy: 0.8687 - val_loss: 0.4150 - val_accuracy: 0.8900\n",
            "Epoch 271/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4337 - accuracy: 0.8763 - val_loss: 0.4142 - val_accuracy: 0.8825\n",
            "Epoch 272/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4428 - accuracy: 0.8687 - val_loss: 0.4140 - val_accuracy: 0.8825\n",
            "Epoch 273/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4303 - accuracy: 0.8650 - val_loss: 0.4126 - val_accuracy: 0.8825\n",
            "Epoch 274/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.4450 - accuracy: 0.8669 - val_loss: 0.4125 - val_accuracy: 0.8800\n",
            "Epoch 275/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4277 - accuracy: 0.8744 - val_loss: 0.4120 - val_accuracy: 0.8825\n",
            "Epoch 276/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4268 - accuracy: 0.8744 - val_loss: 0.4099 - val_accuracy: 0.8925\n",
            "Epoch 277/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4379 - accuracy: 0.8694 - val_loss: 0.4093 - val_accuracy: 0.8875\n",
            "Epoch 278/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4248 - accuracy: 0.8687 - val_loss: 0.4078 - val_accuracy: 0.8900\n",
            "Epoch 279/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.4356 - accuracy: 0.8737 - val_loss: 0.4077 - val_accuracy: 0.8925\n",
            "Epoch 280/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4161 - accuracy: 0.8825 - val_loss: 0.4052 - val_accuracy: 0.8900\n",
            "Epoch 281/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.4382 - accuracy: 0.8619 - val_loss: 0.4069 - val_accuracy: 0.8925\n",
            "Epoch 282/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4290 - accuracy: 0.8681 - val_loss: 0.4050 - val_accuracy: 0.8900\n",
            "Epoch 283/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4222 - accuracy: 0.8725 - val_loss: 0.4042 - val_accuracy: 0.8900\n",
            "Epoch 284/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.4122 - accuracy: 0.8850 - val_loss: 0.4031 - val_accuracy: 0.8875\n",
            "Epoch 285/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4187 - accuracy: 0.8788 - val_loss: 0.4035 - val_accuracy: 0.8900\n",
            "Epoch 286/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4254 - accuracy: 0.8694 - val_loss: 0.4041 - val_accuracy: 0.8875\n",
            "Epoch 287/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4069 - accuracy: 0.8875 - val_loss: 0.4034 - val_accuracy: 0.8925\n",
            "Epoch 288/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4156 - accuracy: 0.8800 - val_loss: 0.3990 - val_accuracy: 0.8950\n",
            "Epoch 289/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4224 - accuracy: 0.8794 - val_loss: 0.3990 - val_accuracy: 0.8875\n",
            "Epoch 290/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.4067 - accuracy: 0.8856 - val_loss: 0.3981 - val_accuracy: 0.8900\n",
            "Epoch 291/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3996 - accuracy: 0.8925 - val_loss: 0.3971 - val_accuracy: 0.8875\n",
            "Epoch 292/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4004 - accuracy: 0.8888 - val_loss: 0.3956 - val_accuracy: 0.8950\n",
            "Epoch 293/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4124 - accuracy: 0.8794 - val_loss: 0.3949 - val_accuracy: 0.8850\n",
            "Epoch 294/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.4242 - accuracy: 0.8788 - val_loss: 0.3942 - val_accuracy: 0.8925\n",
            "Epoch 295/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4027 - accuracy: 0.8844 - val_loss: 0.3936 - val_accuracy: 0.8925\n",
            "Epoch 296/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4103 - accuracy: 0.8725 - val_loss: 0.3944 - val_accuracy: 0.8850\n",
            "Epoch 297/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.4022 - accuracy: 0.8863 - val_loss: 0.3933 - val_accuracy: 0.8875\n",
            "Epoch 298/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3996 - accuracy: 0.8869 - val_loss: 0.3915 - val_accuracy: 0.8950\n",
            "Epoch 299/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4048 - accuracy: 0.8875 - val_loss: 0.3941 - val_accuracy: 0.8900\n",
            "Epoch 300/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.4077 - accuracy: 0.8794 - val_loss: 0.3913 - val_accuracy: 0.8875\n",
            "Epoch 301/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4026 - accuracy: 0.8800 - val_loss: 0.3897 - val_accuracy: 0.8950\n",
            "Epoch 302/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3982 - accuracy: 0.8813 - val_loss: 0.3894 - val_accuracy: 0.8950\n",
            "Epoch 303/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4006 - accuracy: 0.8806 - val_loss: 0.3883 - val_accuracy: 0.8950\n",
            "Epoch 304/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.4069 - accuracy: 0.8863 - val_loss: 0.3867 - val_accuracy: 0.8950\n",
            "Epoch 305/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.4037 - accuracy: 0.8806 - val_loss: 0.3863 - val_accuracy: 0.8975\n",
            "Epoch 306/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.4054 - accuracy: 0.8844 - val_loss: 0.3862 - val_accuracy: 0.8975\n",
            "Epoch 307/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3884 - accuracy: 0.8850 - val_loss: 0.3865 - val_accuracy: 0.9000\n",
            "Epoch 308/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3985 - accuracy: 0.8863 - val_loss: 0.3862 - val_accuracy: 0.8975\n",
            "Epoch 309/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3928 - accuracy: 0.8788 - val_loss: 0.3843 - val_accuracy: 0.8925\n",
            "Epoch 310/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3897 - accuracy: 0.8900 - val_loss: 0.3827 - val_accuracy: 0.8975\n",
            "Epoch 311/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3942 - accuracy: 0.8781 - val_loss: 0.3824 - val_accuracy: 0.8950\n",
            "Epoch 312/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3842 - accuracy: 0.8944 - val_loss: 0.3811 - val_accuracy: 0.8950\n",
            "Epoch 313/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3939 - accuracy: 0.8869 - val_loss: 0.3824 - val_accuracy: 0.8975\n",
            "Epoch 314/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.3977 - accuracy: 0.8888 - val_loss: 0.3815 - val_accuracy: 0.8950\n",
            "Epoch 315/500\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.3913 - accuracy: 0.8806 - val_loss: 0.3810 - val_accuracy: 0.8975\n",
            "Epoch 316/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3911 - accuracy: 0.8925 - val_loss: 0.3789 - val_accuracy: 0.8950\n",
            "Epoch 317/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3995 - accuracy: 0.8919 - val_loss: 0.3782 - val_accuracy: 0.8925\n",
            "Epoch 318/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3914 - accuracy: 0.8831 - val_loss: 0.3783 - val_accuracy: 0.9000\n",
            "Epoch 319/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3952 - accuracy: 0.8850 - val_loss: 0.3772 - val_accuracy: 0.8975\n",
            "Epoch 320/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3880 - accuracy: 0.8875 - val_loss: 0.3763 - val_accuracy: 0.8950\n",
            "Epoch 321/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3944 - accuracy: 0.8775 - val_loss: 0.3768 - val_accuracy: 0.9000\n",
            "Epoch 322/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3946 - accuracy: 0.8819 - val_loss: 0.3756 - val_accuracy: 0.9000\n",
            "Epoch 323/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3847 - accuracy: 0.8856 - val_loss: 0.3757 - val_accuracy: 0.9000\n",
            "Epoch 324/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3758 - accuracy: 0.8913 - val_loss: 0.3740 - val_accuracy: 0.9000\n",
            "Epoch 325/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3913 - accuracy: 0.8875 - val_loss: 0.3726 - val_accuracy: 0.8975\n",
            "Epoch 326/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3810 - accuracy: 0.8900 - val_loss: 0.3731 - val_accuracy: 0.9000\n",
            "Epoch 327/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.3859 - accuracy: 0.8838 - val_loss: 0.3715 - val_accuracy: 0.9000\n",
            "Epoch 328/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3852 - accuracy: 0.8881 - val_loss: 0.3713 - val_accuracy: 0.8975\n",
            "Epoch 329/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3817 - accuracy: 0.8850 - val_loss: 0.3698 - val_accuracy: 0.8975\n",
            "Epoch 330/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3696 - accuracy: 0.9006 - val_loss: 0.3688 - val_accuracy: 0.8975\n",
            "Epoch 331/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3816 - accuracy: 0.8875 - val_loss: 0.3693 - val_accuracy: 0.9000\n",
            "Epoch 332/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3773 - accuracy: 0.8869 - val_loss: 0.3690 - val_accuracy: 0.9000\n",
            "Epoch 333/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3757 - accuracy: 0.8956 - val_loss: 0.3686 - val_accuracy: 0.9000\n",
            "Epoch 334/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3731 - accuracy: 0.8838 - val_loss: 0.3670 - val_accuracy: 0.8975\n",
            "Epoch 335/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3797 - accuracy: 0.8838 - val_loss: 0.3673 - val_accuracy: 0.9000\n",
            "Epoch 336/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3813 - accuracy: 0.8881 - val_loss: 0.3657 - val_accuracy: 0.9000\n",
            "Epoch 337/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3703 - accuracy: 0.9013 - val_loss: 0.3659 - val_accuracy: 0.9000\n",
            "Epoch 338/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3717 - accuracy: 0.8956 - val_loss: 0.3637 - val_accuracy: 0.8975\n",
            "Epoch 339/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3696 - accuracy: 0.8963 - val_loss: 0.3618 - val_accuracy: 0.9000\n",
            "Epoch 340/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3832 - accuracy: 0.8813 - val_loss: 0.3617 - val_accuracy: 0.9050\n",
            "Epoch 341/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3645 - accuracy: 0.9013 - val_loss: 0.3614 - val_accuracy: 0.9000\n",
            "Epoch 342/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3678 - accuracy: 0.8988 - val_loss: 0.3617 - val_accuracy: 0.9000\n",
            "Epoch 343/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3813 - accuracy: 0.8850 - val_loss: 0.3600 - val_accuracy: 0.9000\n",
            "Epoch 344/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3665 - accuracy: 0.8975 - val_loss: 0.3611 - val_accuracy: 0.9025\n",
            "Epoch 345/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3637 - accuracy: 0.8994 - val_loss: 0.3606 - val_accuracy: 0.9025\n",
            "Epoch 346/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3646 - accuracy: 0.9025 - val_loss: 0.3596 - val_accuracy: 0.9025\n",
            "Epoch 347/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3695 - accuracy: 0.8906 - val_loss: 0.3588 - val_accuracy: 0.9025\n",
            "Epoch 348/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3672 - accuracy: 0.8944 - val_loss: 0.3584 - val_accuracy: 0.9025\n",
            "Epoch 349/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3562 - accuracy: 0.8944 - val_loss: 0.3585 - val_accuracy: 0.8975\n",
            "Epoch 350/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3673 - accuracy: 0.8850 - val_loss: 0.3572 - val_accuracy: 0.9000\n",
            "Epoch 351/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3601 - accuracy: 0.8931 - val_loss: 0.3574 - val_accuracy: 0.9000\n",
            "Epoch 352/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3701 - accuracy: 0.8838 - val_loss: 0.3570 - val_accuracy: 0.9025\n",
            "Epoch 353/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3647 - accuracy: 0.8856 - val_loss: 0.3552 - val_accuracy: 0.9025\n",
            "Epoch 354/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3592 - accuracy: 0.8994 - val_loss: 0.3554 - val_accuracy: 0.9000\n",
            "Epoch 355/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3616 - accuracy: 0.8944 - val_loss: 0.3536 - val_accuracy: 0.8975\n",
            "Epoch 356/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3547 - accuracy: 0.8969 - val_loss: 0.3530 - val_accuracy: 0.9025\n",
            "Epoch 357/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3621 - accuracy: 0.8931 - val_loss: 0.3529 - val_accuracy: 0.9025\n",
            "Epoch 358/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3604 - accuracy: 0.8913 - val_loss: 0.3525 - val_accuracy: 0.9025\n",
            "Epoch 359/500\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3555 - accuracy: 0.9000 - val_loss: 0.3524 - val_accuracy: 0.9025\n",
            "Epoch 360/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3510 - accuracy: 0.8931 - val_loss: 0.3514 - val_accuracy: 0.9025\n",
            "Epoch 361/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3489 - accuracy: 0.8988 - val_loss: 0.3516 - val_accuracy: 0.9025\n",
            "Epoch 362/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3633 - accuracy: 0.8969 - val_loss: 0.3500 - val_accuracy: 0.9025\n",
            "Epoch 363/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3613 - accuracy: 0.8913 - val_loss: 0.3490 - val_accuracy: 0.9025\n",
            "Epoch 364/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3526 - accuracy: 0.8988 - val_loss: 0.3481 - val_accuracy: 0.9000\n",
            "Epoch 365/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.3570 - accuracy: 0.8850 - val_loss: 0.3474 - val_accuracy: 0.9025\n",
            "Epoch 366/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3598 - accuracy: 0.8950 - val_loss: 0.3487 - val_accuracy: 0.9025\n",
            "Epoch 367/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3463 - accuracy: 0.9031 - val_loss: 0.3476 - val_accuracy: 0.9075\n",
            "Epoch 368/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3512 - accuracy: 0.9013 - val_loss: 0.3469 - val_accuracy: 0.9025\n",
            "Epoch 369/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3497 - accuracy: 0.8969 - val_loss: 0.3465 - val_accuracy: 0.9025\n",
            "Epoch 370/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3645 - accuracy: 0.9038 - val_loss: 0.3473 - val_accuracy: 0.9050\n",
            "Epoch 371/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3361 - accuracy: 0.9069 - val_loss: 0.3469 - val_accuracy: 0.9050\n",
            "Epoch 372/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3481 - accuracy: 0.8994 - val_loss: 0.3438 - val_accuracy: 0.9075\n",
            "Epoch 373/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3506 - accuracy: 0.8988 - val_loss: 0.3434 - val_accuracy: 0.9025\n",
            "Epoch 374/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3455 - accuracy: 0.9031 - val_loss: 0.3436 - val_accuracy: 0.9075\n",
            "Epoch 375/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3489 - accuracy: 0.8981 - val_loss: 0.3424 - val_accuracy: 0.9075\n",
            "Epoch 376/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3483 - accuracy: 0.8894 - val_loss: 0.3426 - val_accuracy: 0.9075\n",
            "Epoch 377/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3427 - accuracy: 0.9031 - val_loss: 0.3423 - val_accuracy: 0.9050\n",
            "Epoch 378/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3338 - accuracy: 0.9069 - val_loss: 0.3421 - val_accuracy: 0.9075\n",
            "Epoch 379/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3366 - accuracy: 0.9100 - val_loss: 0.3416 - val_accuracy: 0.9075\n",
            "Epoch 380/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3454 - accuracy: 0.8975 - val_loss: 0.3400 - val_accuracy: 0.9100\n",
            "Epoch 381/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3304 - accuracy: 0.8975 - val_loss: 0.3387 - val_accuracy: 0.9075\n",
            "Epoch 382/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3417 - accuracy: 0.9013 - val_loss: 0.3380 - val_accuracy: 0.9075\n",
            "Epoch 383/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3312 - accuracy: 0.9081 - val_loss: 0.3375 - val_accuracy: 0.9075\n",
            "Epoch 384/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3419 - accuracy: 0.8988 - val_loss: 0.3378 - val_accuracy: 0.9075\n",
            "Epoch 385/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3422 - accuracy: 0.8975 - val_loss: 0.3381 - val_accuracy: 0.9100\n",
            "Epoch 386/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3518 - accuracy: 0.8944 - val_loss: 0.3365 - val_accuracy: 0.9100\n",
            "Epoch 387/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3377 - accuracy: 0.9006 - val_loss: 0.3382 - val_accuracy: 0.9100\n",
            "Epoch 388/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3300 - accuracy: 0.8963 - val_loss: 0.3349 - val_accuracy: 0.9100\n",
            "Epoch 389/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3309 - accuracy: 0.9013 - val_loss: 0.3343 - val_accuracy: 0.9075\n",
            "Epoch 390/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3436 - accuracy: 0.8944 - val_loss: 0.3341 - val_accuracy: 0.9100\n",
            "Epoch 391/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3365 - accuracy: 0.9038 - val_loss: 0.3347 - val_accuracy: 0.9075\n",
            "Epoch 392/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3385 - accuracy: 0.9069 - val_loss: 0.3329 - val_accuracy: 0.9100\n",
            "Epoch 393/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3375 - accuracy: 0.9081 - val_loss: 0.3322 - val_accuracy: 0.9075\n",
            "Epoch 394/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3275 - accuracy: 0.9056 - val_loss: 0.3319 - val_accuracy: 0.9075\n",
            "Epoch 395/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3305 - accuracy: 0.9044 - val_loss: 0.3324 - val_accuracy: 0.9050\n",
            "Epoch 396/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3300 - accuracy: 0.9044 - val_loss: 0.3316 - val_accuracy: 0.9075\n",
            "Epoch 397/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3260 - accuracy: 0.9125 - val_loss: 0.3308 - val_accuracy: 0.9100\n",
            "Epoch 398/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3359 - accuracy: 0.9069 - val_loss: 0.3299 - val_accuracy: 0.9100\n",
            "Epoch 399/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3268 - accuracy: 0.9150 - val_loss: 0.3286 - val_accuracy: 0.9075\n",
            "Epoch 400/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3328 - accuracy: 0.9069 - val_loss: 0.3301 - val_accuracy: 0.9025\n",
            "Epoch 401/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3255 - accuracy: 0.9075 - val_loss: 0.3289 - val_accuracy: 0.9100\n",
            "Epoch 402/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3244 - accuracy: 0.9169 - val_loss: 0.3293 - val_accuracy: 0.9100\n",
            "Epoch 403/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3243 - accuracy: 0.9094 - val_loss: 0.3280 - val_accuracy: 0.9075\n",
            "Epoch 404/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3239 - accuracy: 0.9119 - val_loss: 0.3267 - val_accuracy: 0.9100\n",
            "Epoch 405/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3286 - accuracy: 0.9169 - val_loss: 0.3269 - val_accuracy: 0.9100\n",
            "Epoch 406/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3224 - accuracy: 0.9081 - val_loss: 0.3269 - val_accuracy: 0.9125\n",
            "Epoch 407/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3233 - accuracy: 0.9062 - val_loss: 0.3244 - val_accuracy: 0.9075\n",
            "Epoch 408/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3208 - accuracy: 0.9069 - val_loss: 0.3240 - val_accuracy: 0.9075\n",
            "Epoch 409/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3172 - accuracy: 0.9094 - val_loss: 0.3236 - val_accuracy: 0.9075\n",
            "Epoch 410/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3288 - accuracy: 0.9131 - val_loss: 0.3236 - val_accuracy: 0.9050\n",
            "Epoch 411/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3298 - accuracy: 0.9062 - val_loss: 0.3232 - val_accuracy: 0.9050\n",
            "Epoch 412/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3233 - accuracy: 0.9106 - val_loss: 0.3228 - val_accuracy: 0.9100\n",
            "Epoch 413/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3070 - accuracy: 0.9175 - val_loss: 0.3228 - val_accuracy: 0.9100\n",
            "Epoch 414/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3031 - accuracy: 0.9175 - val_loss: 0.3218 - val_accuracy: 0.9100\n",
            "Epoch 415/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3159 - accuracy: 0.9187 - val_loss: 0.3216 - val_accuracy: 0.9100\n",
            "Epoch 416/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3153 - accuracy: 0.9062 - val_loss: 0.3219 - val_accuracy: 0.9100\n",
            "Epoch 417/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3177 - accuracy: 0.9112 - val_loss: 0.3207 - val_accuracy: 0.9075\n",
            "Epoch 418/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3144 - accuracy: 0.9119 - val_loss: 0.3191 - val_accuracy: 0.9075\n",
            "Epoch 419/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3223 - accuracy: 0.9131 - val_loss: 0.3208 - val_accuracy: 0.9100\n",
            "Epoch 420/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.3253 - accuracy: 0.9025 - val_loss: 0.3187 - val_accuracy: 0.9100\n",
            "Epoch 421/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3220 - accuracy: 0.9006 - val_loss: 0.3189 - val_accuracy: 0.9125\n",
            "Epoch 422/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3216 - accuracy: 0.8994 - val_loss: 0.3184 - val_accuracy: 0.9075\n",
            "Epoch 423/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3018 - accuracy: 0.9162 - val_loss: 0.3187 - val_accuracy: 0.9125\n",
            "Epoch 424/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3161 - accuracy: 0.9100 - val_loss: 0.3174 - val_accuracy: 0.9125\n",
            "Epoch 425/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3148 - accuracy: 0.9075 - val_loss: 0.3170 - val_accuracy: 0.9100\n",
            "Epoch 426/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3166 - accuracy: 0.9069 - val_loss: 0.3163 - val_accuracy: 0.9100\n",
            "Epoch 427/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3066 - accuracy: 0.9162 - val_loss: 0.3164 - val_accuracy: 0.9125\n",
            "Epoch 428/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3103 - accuracy: 0.9081 - val_loss: 0.3151 - val_accuracy: 0.9100\n",
            "Epoch 429/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3183 - accuracy: 0.9075 - val_loss: 0.3142 - val_accuracy: 0.9075\n",
            "Epoch 430/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3026 - accuracy: 0.9175 - val_loss: 0.3142 - val_accuracy: 0.9100\n",
            "Epoch 431/500\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.3117 - accuracy: 0.9112 - val_loss: 0.3139 - val_accuracy: 0.9150\n",
            "Epoch 432/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3138 - accuracy: 0.9131 - val_loss: 0.3130 - val_accuracy: 0.9150\n",
            "Epoch 433/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3034 - accuracy: 0.9150 - val_loss: 0.3129 - val_accuracy: 0.9125\n",
            "Epoch 434/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2871 - accuracy: 0.9262 - val_loss: 0.3117 - val_accuracy: 0.9125\n",
            "Epoch 435/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2944 - accuracy: 0.9219 - val_loss: 0.3116 - val_accuracy: 0.9125\n",
            "Epoch 436/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3016 - accuracy: 0.9137 - val_loss: 0.3109 - val_accuracy: 0.9100\n",
            "Epoch 437/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.2986 - accuracy: 0.9181 - val_loss: 0.3111 - val_accuracy: 0.9125\n",
            "Epoch 438/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3081 - accuracy: 0.9094 - val_loss: 0.3102 - val_accuracy: 0.9125\n",
            "Epoch 439/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3052 - accuracy: 0.9106 - val_loss: 0.3104 - val_accuracy: 0.9100\n",
            "Epoch 440/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3084 - accuracy: 0.9112 - val_loss: 0.3098 - val_accuracy: 0.9125\n",
            "Epoch 441/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2923 - accuracy: 0.9256 - val_loss: 0.3089 - val_accuracy: 0.9100\n",
            "Epoch 442/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2989 - accuracy: 0.9169 - val_loss: 0.3081 - val_accuracy: 0.9100\n",
            "Epoch 443/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.3058 - accuracy: 0.9106 - val_loss: 0.3086 - val_accuracy: 0.9100\n",
            "Epoch 444/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2943 - accuracy: 0.9194 - val_loss: 0.3072 - val_accuracy: 0.9100\n",
            "Epoch 445/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2961 - accuracy: 0.9169 - val_loss: 0.3074 - val_accuracy: 0.9075\n",
            "Epoch 446/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2973 - accuracy: 0.9150 - val_loss: 0.3067 - val_accuracy: 0.9100\n",
            "Epoch 447/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2961 - accuracy: 0.9131 - val_loss: 0.3076 - val_accuracy: 0.9150\n",
            "Epoch 448/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.3062 - accuracy: 0.9075 - val_loss: 0.3070 - val_accuracy: 0.9125\n",
            "Epoch 449/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.3054 - accuracy: 0.9162 - val_loss: 0.3058 - val_accuracy: 0.9125\n",
            "Epoch 450/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3001 - accuracy: 0.9150 - val_loss: 0.3051 - val_accuracy: 0.9150\n",
            "Epoch 451/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2976 - accuracy: 0.9250 - val_loss: 0.3055 - val_accuracy: 0.9150\n",
            "Epoch 452/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2958 - accuracy: 0.9150 - val_loss: 0.3043 - val_accuracy: 0.9150\n",
            "Epoch 453/500\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.2966 - accuracy: 0.9094 - val_loss: 0.3034 - val_accuracy: 0.9125\n",
            "Epoch 454/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.3051 - accuracy: 0.9081 - val_loss: 0.3041 - val_accuracy: 0.9150\n",
            "Epoch 455/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3008 - accuracy: 0.9144 - val_loss: 0.3036 - val_accuracy: 0.9125\n",
            "Epoch 456/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3015 - accuracy: 0.9137 - val_loss: 0.3032 - val_accuracy: 0.9150\n",
            "Epoch 457/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2957 - accuracy: 0.9137 - val_loss: 0.3025 - val_accuracy: 0.9125\n",
            "Epoch 458/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2914 - accuracy: 0.9181 - val_loss: 0.3020 - val_accuracy: 0.9125\n",
            "Epoch 459/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2865 - accuracy: 0.9169 - val_loss: 0.3008 - val_accuracy: 0.9150\n",
            "Epoch 460/500\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.2928 - accuracy: 0.9144 - val_loss: 0.3008 - val_accuracy: 0.9150\n",
            "Epoch 461/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2795 - accuracy: 0.9237 - val_loss: 0.3009 - val_accuracy: 0.9125\n",
            "Epoch 462/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2883 - accuracy: 0.9206 - val_loss: 0.3001 - val_accuracy: 0.9150\n",
            "Epoch 463/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.3007 - accuracy: 0.9087 - val_loss: 0.2999 - val_accuracy: 0.9125\n",
            "Epoch 464/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2901 - accuracy: 0.9131 - val_loss: 0.2994 - val_accuracy: 0.9150\n",
            "Epoch 465/500\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.2949 - accuracy: 0.9175 - val_loss: 0.2989 - val_accuracy: 0.9125\n",
            "Epoch 466/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2927 - accuracy: 0.9169 - val_loss: 0.2990 - val_accuracy: 0.9150\n",
            "Epoch 467/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2783 - accuracy: 0.9256 - val_loss: 0.2974 - val_accuracy: 0.9150\n",
            "Epoch 468/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2975 - accuracy: 0.9150 - val_loss: 0.2973 - val_accuracy: 0.9150\n",
            "Epoch 469/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2913 - accuracy: 0.9225 - val_loss: 0.2980 - val_accuracy: 0.9150\n",
            "Epoch 470/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2804 - accuracy: 0.9225 - val_loss: 0.2983 - val_accuracy: 0.9150\n",
            "Epoch 471/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.2807 - accuracy: 0.9231 - val_loss: 0.2966 - val_accuracy: 0.9150\n",
            "Epoch 472/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2818 - accuracy: 0.9256 - val_loss: 0.2961 - val_accuracy: 0.9150\n",
            "Epoch 473/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2880 - accuracy: 0.9181 - val_loss: 0.2963 - val_accuracy: 0.9150\n",
            "Epoch 474/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2873 - accuracy: 0.9125 - val_loss: 0.2966 - val_accuracy: 0.9150\n",
            "Epoch 475/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2793 - accuracy: 0.9225 - val_loss: 0.2937 - val_accuracy: 0.9125\n",
            "Epoch 476/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2881 - accuracy: 0.9144 - val_loss: 0.2944 - val_accuracy: 0.9150\n",
            "Epoch 477/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.2950 - accuracy: 0.9175 - val_loss: 0.2947 - val_accuracy: 0.9150\n",
            "Epoch 478/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2818 - accuracy: 0.9231 - val_loss: 0.2947 - val_accuracy: 0.9150\n",
            "Epoch 479/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2901 - accuracy: 0.9144 - val_loss: 0.2944 - val_accuracy: 0.9150\n",
            "Epoch 480/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2889 - accuracy: 0.9175 - val_loss: 0.2925 - val_accuracy: 0.9150\n",
            "Epoch 481/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2887 - accuracy: 0.9219 - val_loss: 0.2933 - val_accuracy: 0.9175\n",
            "Epoch 482/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2836 - accuracy: 0.9212 - val_loss: 0.2927 - val_accuracy: 0.9175\n",
            "Epoch 483/500\n",
            "200/200 [==============================] - 17s 87ms/step - loss: 0.2903 - accuracy: 0.9194 - val_loss: 0.2924 - val_accuracy: 0.9150\n",
            "Epoch 484/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2828 - accuracy: 0.9106 - val_loss: 0.2918 - val_accuracy: 0.9175\n",
            "Epoch 485/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2793 - accuracy: 0.9250 - val_loss: 0.2913 - val_accuracy: 0.9150\n",
            "Epoch 486/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2848 - accuracy: 0.9244 - val_loss: 0.2906 - val_accuracy: 0.9175\n",
            "Epoch 487/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2858 - accuracy: 0.9169 - val_loss: 0.2913 - val_accuracy: 0.9175\n",
            "Epoch 488/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.2743 - accuracy: 0.9225 - val_loss: 0.2896 - val_accuracy: 0.9150\n",
            "Epoch 489/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2751 - accuracy: 0.9294 - val_loss: 0.2896 - val_accuracy: 0.9175\n",
            "Epoch 490/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2726 - accuracy: 0.9237 - val_loss: 0.2895 - val_accuracy: 0.9125\n",
            "Epoch 491/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2764 - accuracy: 0.9244 - val_loss: 0.2888 - val_accuracy: 0.9175\n",
            "Epoch 492/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 0.2877 - val_accuracy: 0.9150\n",
            "Epoch 493/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2900 - accuracy: 0.9200 - val_loss: 0.2872 - val_accuracy: 0.9150\n",
            "Epoch 494/500\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 0.2659 - accuracy: 0.9331 - val_loss: 0.2875 - val_accuracy: 0.9175\n",
            "Epoch 495/500\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.2744 - accuracy: 0.9262 - val_loss: 0.2872 - val_accuracy: 0.9150\n",
            "Epoch 496/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2815 - accuracy: 0.9181 - val_loss: 0.2865 - val_accuracy: 0.9175\n",
            "Epoch 497/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2717 - accuracy: 0.9237 - val_loss: 0.2853 - val_accuracy: 0.9150\n",
            "Epoch 498/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2746 - accuracy: 0.9125 - val_loss: 0.2856 - val_accuracy: 0.9150\n",
            "Epoch 499/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2647 - accuracy: 0.9350 - val_loss: 0.2856 - val_accuracy: 0.9175\n",
            "Epoch 500/500\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.2740 - accuracy: 0.9225 - val_loss: 0.2847 - val_accuracy: 0.9175\n",
            "CPU times: user 2h 12min 7s, sys: 6min 21s, total: 2h 18min 29s\n",
            "Wall time: 2h 39min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = resnet_model.fit_generator(train_generator,\n",
        "                                     epochs=epochs,\n",
        "                                     steps_per_epoch=num_of_train_samples// batch_size,\n",
        "                                     validation_data=valid_generator,\n",
        "                                     validation_steps=num_of_valid_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Wt64vWbtqN5n",
        "outputId": "07151840-98fd-46bb-a4a5-aa2a3566b76c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Loss Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Akurasi Training dan Validasi')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-zXgYB8qN5n",
        "outputId": "c57b5655-d1c6-4781-9301-a5aa90e7d098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "classifier_json=resnet_model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Models/model500.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "    resnet_model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Models/my_model_weights500.h5\")\n",
        "    resnet_model.save(\"/content/drive/MyDrive/Colab Notebooks/Models/model500.h5\")\n",
        "    print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCxfCn1-qN5n",
        "outputId": "b9ef23a2-4fee-47cd-e17e-50e7f7f694da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pa Lulun Pao': 0, 'Pa Somba': 1, 'Pa Tangke Lumu': 2, 'Pa Tumuru': 3}\n"
          ]
        }
      ],
      "source": [
        "labels = (train_generator.class_indices)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd361UlQqN5n"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/Models/model500.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F5v1PFUqN5n",
        "outputId": "58a430b6-5c8c-49f0-e604-867e0632ead1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report Training :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n",
            "Report Testing :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(valid_generator)\n",
        "# Evaluation matrix\n",
        "y_pred_train = resnet_model.predict(X_train)\n",
        "y_pred_train_argmax = np.argmax(y_pred_train, axis=1)\n",
        "y_train_argmax = np.argmax(y_train, axis=1)\n",
        "y_pred_test = resnet_model.predict(X_test)\n",
        "y_pred_test_argmax = np.argmax(y_pred_test, axis=1)\n",
        "y_test_argmax = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Report Training :\")\n",
        "print(classification_report(y_train_argmax, y_pred_train_argmax))\n",
        "print(\"Report Testing :\")\n",
        "print(classification_report(y_test_argmax, y_pred_test_argmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9JsbY9rqN5n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X28D3J_RbEra",
        "tPyE3oIybIRp",
        "3_FfNBWpRLmF",
        "Hj8Jt5GHoChz",
        "cqBILCXU6xwT",
        "ADJHYNuPqN5g"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}